labs(x = "",
y = "Total WEMWBS Scores")
library(patchwork)
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
library(lsr)
library(scales)
library(qqplotr)
library(car)
library(pwr)
library(rcompanion)
data_ballou <- read_csv("data/data_ballou_reduced.csv")
data_wemwbs <- data_ballou %>%
pivot_longer(cols = wemwbs_1:wemwbs_14, names_to = "Questions", values_to = "Scores") %>%
group_by(pid) %>%
summarise(wemwbs_sum = sum(Scores))
data_ballou <- data_ballou %>%
mutate(gender = factor(gender,
levels = c("Woman", "Man", "Non-binary")),
eduLevel = factor(eduLevel,
levels = c("Completed Secondary School", "Some University but no degree", "University Bachelors Degree", "Vocational or Similar", "Graduate or professional degree (MA, MS, MBA, PhD, etc)"))) %>%
left_join(data_wemwbs)
chi_square <- data_ballou %>%
select(pid, gender, eduLevel)
chi_square_frequency <- chi_square %>%
count(gender, eduLevel) %>%
pivot_wider(names_from = eduLevel, values_from = n)
chi_square_frequency
ggplot(chi_square, aes(x = eduLevel, fill = gender)) +
geom_bar(position = "dodge") +
scale_fill_viridis_d(name = "Gender") +
scale_x_discrete(name = "Level of Education",
labels = label_wrap(12)) +
scale_y_continuous(name = "Count") +
theme_classic()
chi_square_df <- as.data.frame(chi_square)
associationTest(formula = ~ eduLevel + gender, data = chi_square_df)
one_sample <- data_ballou %>%
select(pid, wemwbs_sum)
descriptives <- one_sample %>%
summarise(mean_wemwbs = mean(wemwbs_sum),
sd = sd(wemwbs_sum))
descriptives
ggplot(one_sample, aes(x = "", y = wemwbs_sum)) +
geom_violin(fill = "#FB8D61", alpha = 0.4) + # alpha for opacity, fill for adding colour
geom_boxplot(fill = "#FB8D61", width = 0.5) + # change width of the boxes
geom_point() +
theme_classic() +
labs(x = "",
y = "Total WEMWBS Scores")
ggplot(one_sample, aes(x = "", y = wemwbs_sum)) +
geom_violin(fill = "#FB8D61", alpha = 0.4) + # alpha for opacity, fill for adding colour
geom_boxplot(fill = "#FB8D61", width = 0.5) + # change width of the boxes
geom_jitter() +
theme_classic() +
labs(x = "",
y = "Total WEMWBS Scores")
ggplot(one_sample, aes(x = "", y = wemwbs_sum)) +
geom_violin(fill = "#FB8D61", alpha = 0.4) + # alpha for opacity, fill for adding colour
geom_boxplot(fill = "#FB8D61", width = 0.5) + # change width of the boxes
geom_jitter(width = 0.5) +
theme_classic() +
labs(x = "",
y = "Total WEMWBS Scores")
ggplot(one_sample, aes(x = "", y = wemwbs_sum)) +
geom_violin(fill = "#FB8D61", alpha = 0.4) + # alpha for opacity, fill for adding colour
geom_boxplot(fill = "#FB8D61", width = 0.5) + # change width of the boxes
geom_jitter(width = 0.1) +
theme_classic() +
labs(x = "",
y = "Total WEMWBS Scores")
ggplot(one_sample, aes(x = "", y = wemwbs_sum)) +
geom_violin(fill = "#FB8D61", alpha = 0.4) + # alpha for opacity, fill for adding colour
geom_boxplot(fill = "#FB8D61", width = 0.5) + # change width of the boxes
theme_classic() +
labs(x = "",
y = "Total WEMWBS Scores")
ggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.4) +
scale_fill_viridis_d()
ggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.4, alpha = 0.8) +
scale_fill_viridis_d()
ggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.4, alpha = 0.8) +
scale_fill_viridis_d() +
theme_classic()
ggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.4, alpha = 0.8) +
scale_fill_viridis_d(guide = "none") +
theme_classic()
ggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.4, alpha = 0.8) +
scale_fill_viridis_d(guide = "none") +
theme_classic() +
labs(x = "Similarity", y = "Simon effect")
wilcox.test(simon_effect ~ education, data = simon_effect)
test <- simon_effect %>%
filter(education %in% c("High school", "Graduate degree (Master's, Doctorate, etc.)"))
wilcox.test(simon_effect ~ education, data = test)
leveneTest(simon_effect ~ group, data = simon_effect)
leveneTest(simon_effect ~ similarity, data = simon_effect)
leveneTest(simon_effect ~ similarity, data = simon_effect)
ggplot(simon_effect, aes(x = simon_effect)) +
geom_density(fill = "magenta") +
facet_wrap(~similarity)
## same group
same <- simon_effect %>%
filter(similarity == "same")
shapiro.test(same$similarity)
View(same)
shapiro.test(same$simon_effect)
shapiro.test(different$simon_effect)
## different group
different <- simon_effect %>%
filter(similarity == "different")
shapiro.test(different$simon_effect)
ggplot(simon_effect, aes(sample = simon_effect)) +
stat_qq_band(fill = "#FB8D61", alpha = 0.4) +
stat_qq_line(colour = "#FB8D61") +
stat_qq_point() +
facet_wrap(~similarity)
## same group
same <- simon_effect %>%
filter(similarity == "same")
shapiro.test(same$simon_effect)
## different group
different <- simon_effect %>%
filter(similarity == "different")
shapiro.test(different$simon_effect)
t.test(simon_effect ~ similarity, data = simon_effect)
t.test(simon_effect ~ similarity, data = simon_effect, var.qual = TRUE)
t.test(simon_effect ~ similarity, data = simon_effect, paired = TRUE)
t.test(simon_effect ~ similarity, data = my_data, paired = TRUE)
test <- zwaan_data %>%
pivot_longer(cols = session1_congruent:session2_incongruent, names_to = "col_headings", values_to = "RT") %>%
separate(col_headings, into = c("Session_number", "congruency"), sep = "_") %>%
group_by(participant, similarity, congruency) %>%
summarise(mean_RT = mean(RT)) %>%
ungroup()
View(test)
t.test(simon_effect ~ mean_RT, data = test, paired = TRUE)
library(rstatix)
install.packages("rstatix")
library(rstatix)
## different group
different <- simon_effect %>%
filter(similarity == "different")
t_test(data = simon_effect, formula = simon_effect ~ similarity)
t_test(data = simon_effect, formula = simon_effect ~ similarity, var.equal = FALSE)
t_test(one_sample, wemwbs_sum, mu = 51.0)
View(one_sample)
t_test(one_sample$wemwbs_sum, mu = 51.0)
t_test(one_sample, wemwbs_sum ~ 1, mu = 51.0)
t.test(one_sample$wemwbs_sum, mu = 51.0)
t_test(one_sample, wemwbs_sum ~ 1, mu = 51.0)
t_test(data = simon_effect, formula = simon_effect ~ similarity, var.equal = FALSE)
t_test(data = simon_effect, formula = simon_effect ~ similarity, var.equal = FALSE, paired = TRUE)
t_test(data = simon_effect, formula = simon_effect ~ similarity, var.equal = FALSE, paired = FALSE)
t_test(data = simon_effect,
formula = simon_effect ~ similarity, paired = FALSE, var.equal = FALSE, detailed = TRUE)
t_test(data = simon_effect,
formula = simon_effect ~ similarity, paired = TRUE, var.equal = FALSE, detailed = TRUE)
t_test(data = simon_effect,
formula = simon_effect ~ similarity,
paired = TRUE,
var.equal = TRUE,
detailed = TRUE)
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = FALSE) # set this to true for more detail
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = FALSE) # set this to true for more detail
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
32.85-35.99
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = TRUE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = TRUE, # for an independent t-test
var.equal = TRUE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = TRUE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = TRUE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
View(test)
t_test(data = test,
formula = simon_effect ~ congruency, # DV ~ IV
paired = TRUE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = test,
formula = mean_RT ~ congruency, # DV ~ IV
paired = TRUE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = test,
formula = mean_RT ~ congruency, # DV ~ IV
paired = FALSE, # for an independent t-test
var.equal = TRUE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = test,
formula = mean_RT ~ congruency, # DV ~ IV
paired = FALSE, # for an independent t-test
var.equal = FALSE, # for a Welch t-test
detailed = TRUE) # set this to true for more detail
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test (default)
var.equal = FALSE, # for a Welch t-test (default)
alternative = "two.sided", # default - the alternative hypothesis is tested in both directions
detailed = TRUE) # set this to true for more detail (FALSE is default)
cohensD(simon_effect ~ similarity, data = simon_effect)
cohensD(simon_effect ~ similarity, data = simon_effect, method = "paired")
cohensD(mean_RT ~ congruency, data = test, method = "paired")
cohensD(congruent, incongruent, data = simon_effect)
cohensD(congruent, incongruent, data = simon_effect, method = "paired")
cohensD(simon_effect$congruent, simon_effect$incongruent, method = "paired")
cohensD(simon_effect ~ similarity, data = simon_effect)
pwr.t.test(n = 80, sig.level = 0.05, power = 0.8, type = "two.sample")
pwr.t.test(d = 0.1451628, sig.level = 0.05, power = 0.8, type = "two.sample")
pwr.t.test(d = 0.15, sig.level = 0.05, power = 0.8, type = "two.sample")
pwr.t.test(d = 0.14, sig.level = 0.05, power = 0.8, type = "two.sample")
pwr.t.test(d = 0.145, sig.level = 0.05, power = 0.8, type = "two.sample")
748*2
pwr.t.test(d = 0.1451, sig.level = 0.05, power = 0.8, type = "two.sample")
pwr.t.test(d = 0.145, sig.level = 0.05, power = 0.8, type = "two.sample")
a <- t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test (default)
var.equal = FALSE, # for a Welch t-test (default)
alternative = "two.sided", # default - the alternative hypothesis is tested in both directions
detailed = TRUE) # set this to true for more detail (FALSE is default)
View(a)
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test (default)
var.equal = FALSE, # for a Welch t-test (default)
alternative = "two.sided", # default - the alternative hypothesis is tested in both directions
detailed = TRUE)$p # set this to true for more detail (FALSE is default)
round(t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test (default)
var.equal = FALSE, # for a Welch t-test (default)
alternative = "two.sided", # default - the alternative hypothesis is tested in both directions
detailed = TRUE)$p, 4) # set this to true for more detail (FALSE is default)
t_test(data = simon_effect,
formula = simon_effect ~ similarity, # DV ~ IV
paired = FALSE, # for an independent t-test (default)
var.equal = FALSE, # for a Welch t-test (default)
alternative = "two.sided", # default - the alternative hypothesis is tested in both directions
detailed = TRUE) # set this to true for more detail (FALSE is default)
t.test(data = simon_effect,
formula = simon_effect ~ similarity)
t.test(simon_effect ~ similarity, data = simon_effect)
wilcox.test(simon_effect ~ education, data = test)
test2 <- simon_effect %>%
filter(education %in% c("High school", "Graduate degree (Master's, Doctorate, etc.)"))
wilcox.test(simon_effect ~ education, data = test2)
View(test2)
t.test(simon_effect ~ similarity, data = simon_effect)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal = TRUE)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal = TRUE, paired = TRUE)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal = TRUE)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal = FALSE)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal = TRUE)
t.test(simon_effect ~ similarity, data = simon_effect, var.equal = FALSE)
wilcox.test(simon_effect ~ similarity, data = simon_effect)
wilcox.test(simon_effect ~ similarity, data = simon_effect)
wilcox.test(simon_effect ~ similarity, data = simon_effect)
wilcox.test(simon_effect ~ similarity, data = simon_effect, exact = FALSE)
wilcox.test(simon_effect ~ similarity, data = simon_effect)
wilcox.test(simon_effect ~ similarity, data = simon_effect)
summary(simon_effect)
simon_effect %>% group_by(similarity) %>%
summarise(count = n(), median = median(simon_effect))
simon_effect %>% group_by(similarity) %>%
summarise(median = median(simon_effect))
34.44134	- 35.68470
wilcox.test(simon_effect ~ similarity, data = simon_effect)
wilcox_test(simon_effect, simon_effect ~ similarity)
wilcox.test(simon_effect ~ similarity, data = simon_effect)
wilcox_effsize(data = one_sample, wemwbs_sum~ 1, mu = 53.0)
wilcox_effsize(data = one_sample, wemwbs_sum, mu = 53.0)
wilcox_effsize(data = simon_effect, formula = simon_effect ~ similarity)
wilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)
wilcox_effsize(data = one_sample, formula = wemwbs_sum ~ 1)
wilcox_effsize(data = one_sample, formula = wemwbs_sum ~ 1, mu = 53.0)
wilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
data_prp <- read_csv("data/prp_data_reduced.csv")
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
data_prp <- read_csv("data/prp_data_reduced.csv")
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age), # mean age
sd_age = sd(Age)) # standard deviation of age
demo_total
age_distinct <- data_prp %>%
distinct(Age)
age_distinct
age_distinct
data_prp <- data_prp %>%
mutate(Age = parse_number(Age))
typeof(data_prp$Age) # fixed
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age, na.rm = TRUE), # mean age
sd_age = sd(Age, na.rm = TRUE)) # standard deviation of age
demo_total
demo_by_gender <- data_prp %>%
group_by(Gender) %>% # split data up into groups (here Gender)
summarise(n = n(), # participant number
mean_age = mean(Age, na.rm = TRUE), # mean age
sd_age = sd(Age, na.rm = TRUE)) %>%  # standard deviation of age
ungroup()
demo_by_gender
demo_by_gender <- data_prp %>%
group_by(Gender) %>%
summarise(n = n(),
# n from the line above divided by n from demo_total *100
percentage = n/demo_total$n *100,
mean_age = mean(Age, na.rm = TRUE),
sd_age = sd(Age, na.rm = TRUE)) %>%
ungroup()
demo_by_gender
demo_by_gender <- data_prp %>%
group_by(Gender) %>%
summarise(n = n(),
percentage = round(n/demo_total$n *100, 2), # percentage with 2 decimal places
mean_age = round(mean(Age, na.rm = TRUE), 1), # mean Age with 1 decimal place
sd_age = round(sd(Age, na.rm = TRUE), 3)) %>% # sd Age with 3 decimal places
ungroup()
demo_by_gender
qrp_t1 <- data_prp %>%
#Step 1
select(Code, QRPs_1_Time1:QRPs_11_Time1) %>%
# Step 2
pivot_longer(cols = -Code, names_to = "Items", values_to = "Scores") %>%
# Step 3
group_by(Code) %>% # grouping py participant id
summarise(QRPs_Acceptance_Time1_mean = mean(Scores)) %>% # calculating the average Score
ungroup() # just make it a habit
qrp_step1 <- data_prp %>%
select(Code, QRPs_1_Time1:QRPs_11_Time1)
# show first 5 rows of qrp_step1
head(qrp_step1, n = 5)
qrp_step2 <- qrp_step1 %>%
pivot_longer(cols = -Code, names_to = "Items", values_to = "Scores")
# show first 15 rows of qrp_step2
head(qrp_step2, n = 15)
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
data_prp <- read_csv("data/prp_data_reduced.csv")
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age), # mean age
sd_age = sd(Age)) # standard deviation of age
demo_total
age_distinct <- data_prp %>%
distinct(Age)
age_distinct
age_distinct
data_prp <- data_prp %>%
mutate(Age = parse_number(Age))
typeof(data_prp$Age) # fixed
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age), # mean age
sd_age = sd(Age)) # standard deviation of age
demo_total
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age), # mean age
sd_age = sd(Age)) # standard deviation of age
demo_total
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
data_prp <- read_csv("data/prp_data_reduced.csv")
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age), # mean age
sd_age = sd(Age)) # standard deviation of age
demo_total
age_distinct <- data_prp %>%
distinct(Age)
age_distinct
age_distinct
data_prp <- data_prp %>%
mutate(Age = parse_number(Age))
typeof(data_prp$Age) # fixed
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age), # mean age
sd_age = sd(Age)) # standard deviation of age
demo_total
demo_total <- data_prp %>%
summarise(n = n(), # participant number
mean_age = mean(Age, na.rm = TRUE), # mean age
sd_age = sd(Age, na.rm = TRUE)) # standard deviation of age
demo_total
demo_by_gender <- data_prp %>%
group_by(Gender) %>% # split data up into groups (here Gender)
summarise(n = n(), # participant number
mean_age = mean(Age, na.rm = TRUE), # mean age
sd_age = sd(Age, na.rm = TRUE)) %>%  # standard deviation of age
ungroup()
demo_by_gender
demo_by_gender <- data_prp %>%
group_by(Gender) %>%
summarise(n = n(),
# n from the line above divided by n from demo_total *100
percentage = n/demo_total$n *100,
mean_age = mean(Age, na.rm = TRUE),
sd_age = sd(Age, na.rm = TRUE)) %>%
ungroup()
demo_by_gender
demo_by_gender <- data_prp %>%
group_by(Gender) %>%
summarise(n = n(),
percentage = round(n/demo_total$n *100, 2), # percentage with 2 decimal places
mean_age = round(mean(Age, na.rm = TRUE), 1), # mean Age with 1 decimal place
sd_age = round(sd(Age, na.rm = TRUE), 3)) %>% # sd Age with 3 decimal places
ungroup()
demo_by_gender
qrp_t1 <- data_prp %>%
#Step 1
select(Code, QRPs_1_Time1:QRPs_11_Time1) %>%
# Step 2
pivot_longer(cols = -Code, names_to = "Items", values_to = "Scores") %>%
# Step 3
group_by(Code) %>% # grouping py participant id
summarise(QRPs_Acceptance_Time1_mean = mean(Scores)) %>% # calculating the average Score
ungroup() # just make it a habit
qrp_step1 <- data_prp %>%
select(Code, QRPs_1_Time1:QRPs_11_Time1)
# show first 5 rows of qrp_step1
head(qrp_step1, n = 5)
qrp_step2 <- qrp_step1 %>%
pivot_longer(cols = -Code, names_to = "Items", values_to = "Scores")
# show first 15 rows of qrp_step2
head(qrp_step2, n = 15)
write_csv(data_prp, "data_prp.csv")
write_csv(qrp_t1, "qrp_t1.csv")
data_prp <- read_csv("data/prp_data_reduced.csv")
qrp_t1 <- read_csv("ddata/qrp_t1.csv")
qrp_t1 <- read_csv("data/qrp_t1.csv")
View(qrp_t1)
View(data_prp)
View(data_prp)
knitr::include_graphics("images/default_highlighted.png")
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
data_prp <- read_csv("data/prp_data_reduced.csv")
glimpse(data_prp)
spec(data_prp)
typeof(1)
typeof(1L)
typeof("1")
typeof("text")
1+1
"1"+"1" # ERROR
data_quiz <- data_prp %>%
select(Code, Age, Gender, Ethnicity, Secondyeargrade, QRP_item = QRPs_3_Time1, QRPs_mean = QRPs_Acceptance_Time2_mean, Understanding_item = Understanding_OS_1_Time1) %>%
mutate(Gender = factor(Gender),
Secondyeargrade = factor(Secondyeargrade,
levels = c(1, 2, 3, 4, 5),
labels = c("≥ 70% (1st class grade)", "60-69% (2:1 grade)", "50-59% (2:2 grade)", "40-49% (3rd class)", "< 40%")),
`QRP_item > 4` = case_when(
QRP_item > 4 ~ TRUE,
.default = FALSE))
# the `head()` function shows the first n number of rows of a dataset (here 5)
head(data_quiz, n = 5)
glimpse(data_quiz)
# variable type
con <- c(answer = "continuous", x = "nominal", x = "ordinal")
nom <- c(x = "continuous", answer = "nominal", x = "ordinal")
ord <- c(x = "continuous", x = "nominal", answer = "ordinal")
# data type
num <- c(answer = "numeric", x = "character", x = "logical", x = "factor")
chr <- c(x = "numeric", answer = "character", x = "logical", x = "factor")
log <- c(x = "numeric", x = "character", answer = "logical", x = "factor")
fctr <- c(x = "numeric", x = "character", x = "logical", answer = "factor")
data_prp <- read_csv("data/prp_data_reduced.csv")
View(data_prp)
