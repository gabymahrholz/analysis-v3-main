{
  "hash": "0f8c74d90a3b9ca30aa0eaaf646715c7",
  "result": {
    "markdown": "# Two-sample t-test {#sec-independent}\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n-   a\n-   b\n-   c\n\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n## Activity 1: Setup & download the data\n\n* create a new project and name it something meaningful (e.g., \"2A_chapter7\", or \"07_independent_ttest\"). See @sec-project if you need some guidance.\n* create a new Rmd file and save it to your project folder. See @sec-rmd if you get stuck. \n* delete everything after the setup code chunk (e.g., line 12 and below)\n* download a reduced dataset here: [data_ch7.zip](data/data_ch7.zip \"download\"). You'll see the Codebook, a demographics file, a file containing the mean response times, and a docx file of Supplementary Materials with extra information about the Simon Task, the results, etc. We also provided the raw data file for you to see what experimental data looks like when it hasn't been pre-processed yet.\n* Extract the data files from the zip folder and place them in your project folder. If you need help, see @sec-download_data_ch1.\n\n\n**Citation**\n\n> Zwaan, R. A., Pecher, D., Paolacci, G., Bouwmeester, S., Verkoeijen, P., Dijkstra, K., & Zeelenberg, R. (2018). Participant nonnaiveté and the reproducibility of cognitive psychology. *Psychonomic Bulletin & Review, 25*, 1968-1972. [https://doi.org/10.3758/s13423-017-1348-y](https://doi.org/10.3758/s13423-017-1348-y){target=\"_blank\"}\n\nThe data and supplementary materials are available on OSF: [https://osf.io/ghv6m/](https://osf.io/ghv6m/){target=\"_blank\"}\n\n**Abstract**\n\n> Many argue that there is a reproducibility crisis in psychology. We investigated nine well-known effects from the cognitive psychology literature—three each from the domains of perception/action, memory, and language, respectively—and found that they are highly reproducible. Not only can they be reproduced in online environments, but they also can be reproduced with nonnaïve participants with no reduction of effect size. Apparently, some cognitive tasks are so constraining that they encapsulate behavior from external influences, such as testing situation and prior recent experience with the experiment to yield highly robust effects.\n\n\n\n**Changes made to the dataset**\n\n* We reduced the dataset, demographic information, and Supplementary Materials to only include information about the Simon Task. The full dataset including the other 8 tasks can be found on OSF.\n* No other changes were made.\n\n\n## Activity 2: Library and data for today\n\nToday, we'll need the following packages `rstatix`, `tidyverse`, `car`, `lsr`, `pwr`. Make sure the rstatix package is read in before tidyverse, otherwise, it will mask the filter function in dplyr. *ETC*. We also need to read in the data from `MeansSimonTask.csv` and the demographics information from `DemoSimonTask.csv`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load in the packages\n???\n\n# read in the data\nzwaan_data <- ???\nzwaan_demo <- ???\n```\n:::\n\n\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load in the packages\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(car)\nlibrary(lsr)\nlibrary(pwr)\n\n# read in the data\nzwaan_data <- read_csv(\"MeansSimonTask.csv\")\nzwaan_demo <- read_csv(\"DemoSimonTask.csv\")\n```\n:::\n\n\n:::\n\n## Activity 3: Familiarise yourself with the data\n\nAs usual, familiarise yourself with the data before starting on the between-subjects t-test. Also, more importantly, have a look at the Supplementary Materials in which the Simon effect is explained in more depth.\n\nIn general, **the Simon effect** refers to the observation that participants have shorter response times when the stimulus appears on the same side of the screen as the button they need to press (i.e., a congruent condition). In contrast, when the stimulus appears on the opposite side of the screen from the button they are supposed to press (i.e., an incongruent condition), their response times are longer. \n\nIn this experiment, all participants completed 2 sessions of trials. Half of the participants received the same stimulus set across sessions 1 and 2, whereas for the other half the stimulus set they received in session 2 differed from the one already encountered in session 1. \n\n\n* Potential research question: “Is there a significant difference in the Simon effect between participants who received the same stimuli in both sessions compared to those who received different stimuli?”\n* Null Hypothesis (H~0~): \"There is no significant difference in the Simon effect between participants who received the same stimuli in both sessions and those who received different stimuli.\"\n* Alternative Hypothesis (H~1~): \"There is a significant difference in the Simon effect between participants who received the same stimuli in both sessions and those who received different stimuli.\"\n\n\n\n## Activity 4: Preparing the dataframe\n\nThe data is already in a very good shape, however, we do have some wrangling to do to compute this Simon effect.\n\n\nTo calculate the Simon effect, we need \n\n1. one mean response time (RT) value for congruent and one for incongruent trials per participant, and then\n2. subtract the mean RT of congruent trials from the mean RT of incongruent trials.\n\nAnd to have all data in one place, we should join this output with the demographics.\n\nBasically, we want to create a tibble that has the following content. *[Note that I re-arranged the columns and re-labelled some of them in a final step, so your column names and/or order might be slightly different, but content should match.]*\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|participant |gender | age|education          |similarity | congruent| incongruent| simon_effect|\n|:-----------|:------|---:|:------------------|:----------|---------:|-----------:|------------:|\n|T1          |Female |  50|High school        |same       |  475.0032|    508.2835|     33.28029|\n|T10         |Male   |  45|Associate's degree |same       |  420.1515|    401.5800|    -18.57148|\n|T109        |Male   |  33|Bachelor's degree  |same       |  339.5343|    375.7152|     36.18085|\n|T11         |Female |  71|High school        |same       |  516.9722|    542.3111|     25.33889|\n|T111        |Female |  34|High school        |same       |  373.5778|    394.0665|     20.48874|\n\n</div>\n:::\n:::\n\n\nObviously, there are various ways of doing this, so feel free to come up with your own way. However, we will provide step-by-step instructions for one of those ways that will get you the output:\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n* **Step 1**: the data is currently in wide format but would be better if it were in long format (so that all RT values are in 1 column; each participant has now 4 rows)\n* **Step 2**: there should be a column now that contained the previous column headings with information on session number and congruency. It would be best if that was separated into 2 columns instead.\n* **Step 3**: now we can calculate the mean RT for each `participant`, `similarity`, and `congruency`\n* **Step 4**: pivot the data again, this time into wide format so that congruent and incongruent values are in 2 columns \n* **Step 5**: create a new column called the `simon_effect` that subtracts congruent from incongruent values \n* **Step 6**: join this together with the demographic information\n* **Step 7**: feel free to rearrange the order of columns and/or rename them to match your output with ours (not strictly necessary tbh)\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution to the steps outlined above\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimon_effect <- zwaan_data %>% \n  pivot_longer(cols = session1_congruent:session2_incongruent, names_to = \"col_headings\", values_to = \"RT\") %>% \n  separate(col_headings, into = c(\"Session_number\", \"congruency\"), sep = \"_\") %>% \n  group_by(participant, similarity, congruency) %>% \n  summarise(mean_RT = mean(RT)) %>% \n  ungroup() %>% \n  pivot_wider(names_from = congruency, values_from = mean_RT) %>% \n  mutate(simon_effect = incongruent - congruent) %>% \n  full_join(zwaan_demo, by = join_by(participant == twosubjectnumber)) %>% \n  select(participant, gender = gender_response, age = age_response, education = education_response, similarity:simon_effect)\n```\n:::\n\n\n:::\n\n:::\n\n\n## Activity 4: Compute descriptives\n\nWe want to compute means and standard deviations for each group of our variable of interest, i.e., the mean RT and sd for our variable `simon_effect` for the `same` and the `different` group.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescriptives <- simon_effect %>% \n  group_by(similarity) %>% \n  summarise(mean_RT = mean(simon_effect),\n            sd_RT = sd(simon_effect))\n\ndescriptives\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|similarity |  mean_RT|    sd_RT|\n|:----------|--------:|--------:|\n|different  | 32.85726| 20.79313|\n|same       | 35.99415| 22.39601|\n\n</div>\n:::\n:::\n\n\n:::\n\n\n## Activity 5: Create an appropriate plot\n\nWhich plot would you choose to represent the data appropriately? Create an appropriate plot, then compare with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.4, alpha = 0.8) +\n  scale_fill_viridis_d(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"Similarity\", y = \"Simon effect\")\n```\n\n::: {.cell-output-display}\n![](07-independent_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n## Activity 6: Check assumptions\n\n#### Assumption 1: Continuous DV {.unnumbered}\n\nThe dependent variable needs to be measured at interval or ratio level. We can confirm that by looking at `simon_effect`. \n\n\n#### Assumption 2: Data are independent {.unnumbered}\n\nThere is no relationship between the observations. The scores in one condition/observation can’t influence the scores in another. We assume this assumption holds for our data.\n\n\n\n#### Assumption 3: Homoskedasticity (homogeneity of variance) {.unnumbered}\n\nIf the variances between the 2 groups are similar/equal, we have homoskedasticity.\nIf the variances between the 2 groups are dissimilar/unequal, we have heteroskedasticity.\n\nWe can test this with a **Levene’s Test for Equality of Variance**. The Levene's test is part of the package `car`. The first argument is a formula, and it's structured as `DV ~ IV`. In our data, the DV would be our continuous `simon_effect` variable, and the IV is the grouping variable `similarity`. Separate those 2 variables with a tilde. The second argument is the data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nleveneTest(simon_effect ~ similarity, data = simon_effect)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n:::\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|      |  Df|   F value|    Pr(>F)|\n|:-----|---:|---------:|---------:|\n|group |   1| 0.7263221| 0.3953679|\n|      | 158|        NA|        NA|\n\n</div>\n:::\n:::\n\n\nThe warning message tells us that the grouping variable was converted into a factor. Oops, I guess we forgot to turn the variables into a factor during data wrangling.\n\nFrom the above result, we see that p-value is greater than .05. That means, we do have not enough evidence to reject the null hypothesis. So the variance across the 2 groups are assumed equal. \n\nYou would report this in APA style: A Levene's test of homogeneity of variances was used to compare the variances of the same and the different groups. It indicated that the variances were homogenous, $F(1,158) = 0.73, p = .395$.\n\n::: {.callout-important}\n\nOne other thing to note is the t-test we are conducting is a **Welch t-test** by default. Welch gives similar results to a Student's t-test when variances are equal, but is to be favoured when variances are not equal. \n\nSo even if Levene's returns a significant p-value indicating groups have unequal variances, we can still use the Welch t-test.\n\n:::\n\n\n\n#### Assumption 4: DV should be approximately normally distributed {.unnumbered}\n\nHere, we need to pay attention that this means **normally distributed in each group**.\n\nWe can either use our eyeballs again on the violin-boxplot we created earlier (or use a qqplot, density plot, or histogram instead), OR compute a statistic like the Shapiro-Wilk's test we already mentioned for the one-sample t-test. However, might still have the issue of large sample sizes (i.e. ca 80 participants in each group).\n\nVisual inspection would tell us that both groups look pretty normally distributed - the \"same\" group slightly more so than the \"different\" group because of the peak in the lower tail. But it still looks pretty normal for real-life data.\n\n::: {.callout-tip} \n\nIf you wanted to use a histogram, density plot or qqplot (the ones created with the `ggplot2` and `qqplotr` packages), you could just add a `facet_wrap()` function to display the figures separate for each group. \n\nIf you used the Q-Q plot function from the `car` package, you would need to create different data objects with the filtered data for each group first before you can create the Q-Q plots for both groups separately.\n\n:::\n\nYou can still use computational methods, like the **Shapiro-Wilk's test** we mentioned in the last chapter. The function does not allow for a formula, which means we would have to use different objects for the 2 different groups first. I guess this is a good way of practicing the filter function.\n\nTask: Create separate data object for the same and different group and then run the Shapiro-Wilk test on them. What do you conclude from the results?\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## same group\nsame <- simon_effect %>% \n  filter(similarity == \"same\")\n\nshapiro.test(same$simon_effect)\n\n## different group\ndifferent <- simon_effect %>% \n  filter(similarity == \"different\")\n\nshapiro.test(different$simon_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  same$simon_effect\nW = 0.98921, p-value = 0.7447\n\n\n\tShapiro-Wilk normality test\n\ndata:  different$simon_effect\nW = 0.96949, p-value = 0.05262\n```\n:::\n:::\n\n\nShapiro-Wilk's test also showed the data for both groups, \"same\" and \"different\", are normally distributed as all p-values are above .05. Again, if you used this method in your report, you would have to write up the results in APA style (see one-sample t-test).\n\n:::\n\n\n\n::: {.callout-important}\n\nIf you have read the Delacre et al. (2017) paper ([https://rips-irsp.com/articles/10.5334/irsp.82](https://rips-irsp.com/articles/10.5334/irsp.82){target=\"_blank\"}), you might be aware that the normality assumption is not overly important for the Welch t-test.\n\nSo whether you judge both groups as \"normally distributed\" or interpret one as deviating slightly from normality, the Welch t-test should still be ok to use for this dataset.\n\n:::\n\nAfter checking all of these assumptions, we decided that all of them held, and we will compute a **Welch two-sample t-test**.\n\n\n\n\n\n## Activity 7: Compute a Two-sample t-test and effect size\n\nThe `t.test()` function we used for the one-sample t-test can be used here, however, we can use it in a slightly different way. It does allow for a formula option. So instead of having to wrangle the data again and having to use `$` to access columns, we can use the formula `DV ~ IV`. The `t.test()` function expects the following arguments:\n\n* The first argument in the formula with the pattern `DV ~ IV`\n* The second argument is the data\n* The third argument is specifying whether variances are equal between the groups. By default is is `var.equal = FALSE` which means a **Welch t-test** is getting conducted. If you were to set `var.equal` to `TRUE`, you would conduct a Student t-test.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(simon_effect ~ similarity, data = simon_effect, var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  simon_effect by similarity\nt = -0.91809, df = 157.14, p-value = 0.36\nalternative hypothesis: true difference in means between group different and group same is not equal to 0\n95 percent confidence interval:\n -9.885574  3.611799\nsample estimates:\nmean in group different      mean in group same \n               32.85726                35.99415 \n```\n:::\n:::\n\nThe output tells us:\n\n* the test that was conducted (here Welch)\n* the variables that were tested (here simon_effect by similarity), \n* the t value, degrees of freedom, and p,\n* the alternative hypothesis, \n* a 95% confidence interval,\n* and the mean of both groups (which again match with our descriptives)\n\nThe `t.test()` function does not give us an **effect size**, so we have to compute it once again. We can use the `CohensD()` function from the `lsr` package as we did for the one-sample t-test. We can use the formula approach here as well.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncohensD(simon_effect ~ similarity, data = simon_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1451628\n```\n:::\n:::\n\n\n\n## Activity 8: Sensitivity power analysis\n\nNext up is the sensitivity power analysis to determine the minimum effect size that we could have reliably detected with the number of participants that took part, the alpha level at 0.05, and an assumed power of 0.8. \n\nThe function we need to compute this is `pwr.t.test()` which is part of the `pwr` package. The arguments in the formula are the same as for the one-sample t-test; we just need to adjust the number of participants (which is the number of observations per sample) and setting the type to \"two.sample\".\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npwr.t.test(n = 80, sig.level = 0.05, power = 0.8, type = \"two.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 80\n              d = 0.445672\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\nSo the smallest effect size we can detect with a sample size of 80 participants in each group, an alpha level of 0.05, and power of 0.8 is 0.45. This is a larger value than the actual effect size we calculated with the `CohensD` function above (i.e., 0.14) which means our analysis is underpowered to detect this extremely small effect.\n\nJust out of curiosity, if we were to replicate this study, and we wanted to be able to detect an effect size that small, how many participants would we need to recruit? We run the `pwr.t.test()` function again, but replacing n with the effect size d. Ooft; we would need ca 1500 participants in total. To be honest, 0.145 would not be a meaningful effect size.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npwr.t.test(d = 0.145, sig.level = 0.05, power = 0.8, type = \"two.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 747.5833\n              d = 0.145\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n## Activity 9: The write-up\n\nWe hypothesised that there would be a significant difference in the Simon effect between participants who received the same stimuli in both sessions $(N = 80, M = 35.99 msec, SD = 22.40 msec)$ and those who received different stimuli $(N = 80, M = 32.86 msec, SD = 20.79 msec)$. Using a two-sample Welch t-test, the effect was found to be non-significant and of a small magnitude, $t(157.14) = 0.92, p = .360, d = 0.15$. The overall mean difference between groups was small $(M_{diff} = 3.14 msec)$. Therefore, we fail to reject the null hypothesis.\n\n\n\n## Activity 10: Non-parametric alternative {#sec-alternative_two_sample}\n\nThe **Mann-Whitney U-test** is the non-parametric equivalent to the independent two-sample t-test. The test can be used for any situation requiring a test to compare the median of two samples. \n\nAccording to the paper by Delacre et al. (2017), the Mann-Whitney U-test can cope with normality issues, but it remains sensitive to heteroscedasticity. Here, we won't have a problem, since the variances in the two groups were equal, but perhaps be mindful in other datasets when assessing assumptions and drawing conclusions from them.\n\n\nFirst, let's start of by computing the median for each group\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimon_effect %>% group_by(similarity) %>% \n  summarise(n = n(), \n            median = median(simon_effect))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|similarity |  n|   median|\n|:----------|--:|--------:|\n|different  | 80| 34.44134|\n|same       | 80| 35.68470|\n\n</div>\n:::\n:::\n\n\n\nTo conduct a Mann-Whitney U-test, use the function `wilcox.test()`. This time, use the formula approach `DV ~ IV` - again, this is the same code structure we just used for the independent t-test.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox.test(simon_effect ~ similarity, data = simon_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  simon_effect by similarity\nW = 3001, p-value = 0.4981\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nThe **effect size** for the Mann-Whitney U-test is r. To compute r, we'd need the standardised test statistic z and divide that the square-root of the number of pairs n: $r = \\frac{|z|}{\\sqrt n}$. Or we could just use the `wilcox_effsize()` function from the `rstatix` package.\n\nThe arguments are in a slightly different order, but exactly the same as in the Wilcox test we used above.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox_effsize(data = simon_effect, formula = simon_effect ~ similarity)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.y.          |group1    |group2 |   effsize| n1| n2|magnitude |\n|:------------|:---------|:------|---------:|--:|--:|:---------|\n|simon_effect |different |same   | 0.0536884| 80| 80|small     |\n\n</div>\n:::\n:::\n\n\nThis is once again considered a small effect. Anyway, we do have all the numbers now to write up the results:\n\n\nA Mann-Whitney U-test was conducted to determine whether there was a significant difference in the Simon effect between participants who received the same stimuli in both sessions $(N = 80, MdnRT = 35.68 msec)$ and those who received different stimuli $(N = 80, Mdn RT = 34.44 msec)$. The results indicate that the median difference was non-significant and of a small magnitude, $W = 3001, p = .498, r = .054$. Therefore, we fail to reject the null hypothesis.\n\n\n## [Pair-coding in the lab]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n",
    "supporting": [
      "07-independent_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}