{
  "hash": "f0e76f6af34c7146d99ee54c3a66ca3c",
  "result": {
    "markdown": "# Data wrangling {#sec-wrangling}\n\n## Intended Learning Outcomes {.unnumbered}\n\nIn this chapter, we are building upon the skills from level 1, bringing together all of the functions you already encountered (and probably forgotten over the summer break) with perhaps introducing 2 or 3 new functions. It's as much a revision chapter as well as providing an opportunity to apply the functions to a novel dataset.\n\nBy the end of this chapter you should be able to:\n\n-   apply familiar data wrangling functions to novel datasets\n-   read and interpret error messages\n-   realise there are several ways of getting to the results \n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\nThe main purpose of this chapter is to wrangle your data into shape for data visualisation (@sec-dataviz and @sec-dataviz2). Here, we will: \n\n1. calculate demographics\n2. tidy 3 different questionnaires with varying degree of complexity\n3. solve an error mode problem\n4. join all data objects together\n\n\nBut first, we need to set up some things.\n\n## Activity 1: Setup\n\n* We will be working on the **dataset by Pownall et al. (2023)** again, which means we can still use the project we created last week. The data files will already be there, so no need to download them again.\n* To **open the project** in RStudio, go to the folder in which you stored the project and the data last time, and double click on the project icon.\n* **Create a new Rmd** for chapter 2 and save it to your project folder. Name it something meaningful (e.g., “chapter_02”, “02_data_wrangling.Rmd”). See @sec-rmd if you need some guidance.\n* In your newly created Rmd file, delete everything below line 12 (after the set-up code chunk).\n\n\n## Activity 2: Load in the libraries and read in the data\n\nWe will use `tidyverse` today, and we want to create a data object `data_prp` that stores the data from the file `prp_data_reduced.csv`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hint\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(???)\ndata_prp <- read_csv(\"???\")\n```\n:::\n\n\n\n\n:::\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata_prp <- read_csv(\"prp_data_reduced.csv\")\n```\n:::\n\n\n:::\n\nIf you need a quick reminder what the dataset was about, have a look at the abstract in @sec-download_data_ch1. We also addressed the changes we made to the dataset there.\n\nAnd remember to have a quick `glimpse()` at your data. \n\n\n\n## Activity 3: Calculating demographics \n\n\nLet’s start with some simple data wrangling steps to compute demographics for our original dataset, `data_prp`. First, we want to determine how many participants took part in the study by Pownall et al. (2023) and compute the mean age and the standard deviation of age for the sample.\n\n### ... for the full sample using `summarise()`\n\nThe `summarise()` function is part of the **\"Wickham 6\"** alongside `group_by()`, `select()`, `filter()`, `mutate()`, and `arrange()`. You used them plenty of times last year.\n\nWithin `summarise()`, we can use the `n()` function, which calculates the number of rows in the dataset. Since each row corresponds to a unique participant, this gives us the total number of participants.\n\nTo calculate the mean age and the standard deviation of age, we need to use the functions `mean()` and `sd()` on the column `Age` respectively.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_total <- data_prp %>% \n  summarise(n = n(), # participant number\n            mean_age = mean(Age), # mean age\n            sd_age = sd(Age)) # standard deviation of age\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `mean_age = mean(Age)`.\nCaused by warning in `mean.default()`:\n! argument is not numeric or logical: returning NA\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n```\n:::\n\n```{.r .cell-code}\ndemo_total\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|  n| mean_age| sd_age|\n|--:|--------:|------:|\n| 89|       NA|     NA|\n\n</div>\n:::\n:::\n\n\nR did not give us an error message per se, but the output is not quite as expected either. There are `NA` values in the `mean_age` and `sd_age` columns. Looking at the warning message and at `Age`, can you explain what happened?\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Answer\n\nThe warning message says: `argument is not numeric or logical: returning NA` If we look at the `Age` column more closely, we can see that it's a character data type.\n\n:::\n\n#### Fixing `Age` {.unnumbered}\n\nMight be wise to look at the unique answers in column `Age` to determine what is wrong. We can do that with the function `distinct()`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nage_distinct <- data_prp %>% \n  distinct(Age)\n\nage_distinct\n```\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Show the unique values of `Age`.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Age      |\n|:--------|\n|22       |\n|20       |\n|26       |\n|21       |\n|29       |\n|23       |\n|39       |\n|NA       |\n|24       |\n|43       |\n|31       |\n|25 years |\n\n</div>\n:::\n:::\n\n\n:::\n\n::: {.columns}\n\n::: {.column}\n\nOne cell has the string \"years\" added to their number 25, which has converted the entire column into a character column. \n\nWe can easily fix this by extracting only the numbers from the column and converting it into a numeric data type. The `parse_number()` function, which is part of the `tidyverse` package, handles both steps in one go (so there’s no need to load additional packages)\n\nWe will combine this with the `mutate()` function to create a new column called `Age` (containing those numeric values), effectively replacing the old `Age` column (which had the character values).\n\n:::\n\n\n::: {.column}\n\n![parse_number() illustration by Allison Horst (see [https://allisonhorst.com/r-packages-functions](https://allisonhorst.com/r-packages-functions){target=\"_blank\"})](images/parse_number.png){width=\"95%\"}\n\n:::\n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_prp <- data_prp %>% \n  mutate(Age = parse_number(Age))\n\ntypeof(data_prp$Age) # fixed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"double\"\n```\n:::\n:::\n\n#### Computing summary stats {.unnumbered}\n\nNow we can try calculating the demographics for the total sample again. However, we also saw that `age_distinct` that `Age` contains some missing values (`NA`). We need R to ignore those for the calculations, so we add the extra argument `na.rm = TRUE` to the `mean()` and `sd()` functions. If we don't, we'd be back at `NA` values for those 2 columns.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_total <- data_prp %>% \n  summarise(n = n(), # participant number\n            mean_age = mean(Age, na.rm = TRUE), # mean age\n            sd_age = sd(Age, na.rm = TRUE)) # standard deviation of age\n\ndemo_total\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|  n| mean_age|   sd_age|\n|--:|--------:|--------:|\n| 89| 21.88506| 3.485603|\n\n</div>\n:::\n:::\n\n\n\n### ... per gender using `summarise()` and `group_by()`\n\nNow we want to compute the summary statistics for each gender. The code inside the `summarise()` function remains unchanged; we just need to use the `group_by()` function beforehand to tell R that we want to compute the summary statistics for each group separately. It’s also a good practice to use `ungroup()` afterward, so you are not taking groupings forward unintentionally.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_by_gender <- data_prp %>% \n  group_by(Gender) %>% # split data up into groups (here Gender)\n  summarise(n = n(), # participant number \n            mean_age = mean(Age, na.rm = TRUE), # mean age \n            sd_age = sd(Age, na.rm = TRUE)) %>%  # standard deviation of age\n  ungroup()\n\ndemo_by_gender\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Gender|  n| mean_age|   sd_age|\n|------:|--:|--------:|--------:|\n|      1| 17| 23.31250| 5.770254|\n|      2| 69| 21.57353| 2.738973|\n|      3|  3| 21.33333| 1.154700|\n\n</div>\n:::\n:::\n\n\n\n### Adding percentages \n\nSometimes, it may be useful to calculate percentages, such as for the gender split. You can do this by adding a line within the `summarise()` function to perform the calculation. All we need to do is take the number of female, male, and non-binary participants (stored in the `n` column of `demo_by_gender`), divide it by the total number of participants (stored in the `n` column of `demo_total`), and multiply by 100. Let's add `percentage` to the `summarise()` function of `demo_by_gender`. Make sure that the code for `percentages` is placed after the value for `n` has been computed. \n\nAccessing `n` for the different gender categories is straightforward because can refer back to it. However, since the total number of participants is in a different data object, we need to use some baseR functionality to access it - namely via the `$` operator. You just have to name the data object (here `demo_total`), then use the `$` (straight after, without any spaces), and then name the column you want to access (here `n`).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_by_gender <- data_prp %>% \n  group_by(Gender) %>% \n  summarise(n = n(), \n            # n from the line above divided by n from demo_total *100\n            percentage = n/demo_total$n *100, \n            mean_age = mean(Age, na.rm = TRUE), \n            sd_age = sd(Age, na.rm = TRUE)) %>% \n  ungroup()\n\ndemo_by_gender\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Gender|  n| percentage| mean_age|   sd_age|\n|------:|--:|----------:|--------:|--------:|\n|      1| 17|  19.101124| 23.31250| 5.770254|\n|      2| 69|  77.528090| 21.57353| 2.738973|\n|      3|  3|   3.370786| 21.33333| 1.154700|\n\n</div>\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n\n## Tip for decimal places - use `round()`\n\nNot super important, because you could round the values by yourself when writing up your reports, but if you wanted to tidy up the decimal places in the output, you can do that using the `round()` function. You would need to \"wrap\" it around your computations and specify how many decimal places you want to display (for example `mean(Age)` would turn into `round(mean(Age), 1)`). It may look odd for `percentage`, just make sure the number that specifies the decimal places is placed **within** the round function. The default value is 0 (meaning no decimal spaces).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_by_gender <- data_prp %>% \n  group_by(Gender) %>% \n  summarise(n = n(), \n            percentage = round(n/demo_total$n *100, 2), # percentage with 2 decimal places\n            mean_age = round(mean(Age, na.rm = TRUE), 1), # mean Age with 1 decimal place\n            sd_age = round(sd(Age, na.rm = TRUE), 3)) %>% # sd Age with 3 decimal places\n  ungroup()\n\ndemo_by_gender\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Gender|  n| percentage| mean_age| sd_age|\n|------:|--:|----------:|--------:|------:|\n|      1| 17|      19.10|     23.3|  5.770|\n|      2| 69|      77.53|     21.6|  2.739|\n|      3|  3|       3.37|     21.3|  1.155|\n\n</div>\n:::\n:::\n\n\n:::\n\n\n## Activity 4: Questionable Research Practices (QRPs) {#sec-ch2_act4}\n\n#### The main goal is to compute the mean QRP score per participant for time point 1. {.unnumbered}\n\nLooking at the QRP data at time point 1, you determine that\n\n* individual item columns are <select class='webex-select'><option value='blank'></option><option value='answer'>numeric</option><option value='x'>character</option></select>, and \n* according to the codebook, there are <select class='webex-select'><option value='blank'></option><option value='answer'>no</option><option value='x'>some</option></select> reverse-coded items in this questionnaire. \n\nSo we just have to **compute an average score for items 1 to 11** as items 12 to 15 are distractor items. Seems quite straightforward.\n\nThe downside is that individual items are each in a separate column, i.e., in **wide format**, and everything would be easier if the items were arranged in **long format**.\n\nSo let's tackle this problem in steps. Best would be to create a separate data object for that. If we wanted to compute this within `data_prp`, it would turn into a nightmare.\n\n* **Step 1**: select the relevant columns `Code`, and `QRPs_1_Time1` to `QRPs_1_Time1` and store them in an object called `qrp_t1`\n* **Step 2**: pivot the data from wide format to long format using `pivot_longer()` so we can calculate the average score more easily (in step 3)\n* **Step 3**: calculate the average QRP score (`QRPs_Acceptance_Time1_mean`) per participant using `group_by()` and `summarise()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqrp_t1 <- data_prp %>% \n  #Step 1\n  select(Code, QRPs_1_Time1:QRPs_11_Time1) %>%\n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Scores\") %>% \n  # Step 3\n  group_by(Code) %>% # grouping py participant id\n  summarise(QRPs_Acceptance_Time1_mean = mean(Scores)) %>% # calculating the average Score\n  ungroup() # just make it a habit\n```\n:::\n\n\n\n::: {.callout-caution icon=\"false\" collapse=\"true\"} \n\n## Explain the individual functions\n\n::: {.panel-tabset}\n## `select ()`\n\nThe select function allows to include or exclude certain variables (columns). Here we want to focus on the participant id column (i.e., `Code`) and the QRP items at time point 1. We can either list them all individually, i.e., Code, QRPs_1_Time1, QRPs_2_Time1, QRPs_3_Time1, and so forth (you get the gist), but that would take forever to type. \n\nA short cut would to use the colon operator `:`. It allows us to select all columns that fall within the range of `first_column_name` to `last_column_name`. We can use this here since QRP items 1 to 11 are sequentially listed in `data_prp`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqrp_step1 <- data_prp %>% \n  select(Code, QRPs_1_Time1:QRPs_11_Time1)\n\n# show first 5 rows of qrp_step1\nhead(qrp_step1, n = 5)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Code | QRPs_1_Time1| QRPs_2_Time1| QRPs_3_Time1| QRPs_4_Time1| QRPs_5_Time1| QRPs_6_Time1| QRPs_7_Time1| QRPs_8_Time1| QRPs_9_Time1| QRPs_10_Time1| QRPs_11_Time1|\n|:----|------------:|------------:|------------:|------------:|------------:|------------:|------------:|------------:|------------:|-------------:|-------------:|\n|Tr10 |            7|            7|            5|            7|            3|            4|            5|            7|            6|             7|             7|\n|Bi07 |            7|            7|            2|            7|            3|            7|            7|            7|            7|             6|             7|\n|SK03 |            7|            7|            6|            6|            7|            6|            7|            7|            7|             5|             7|\n|SM95 |            7|            7|            2|            6|            7|            5|            7|            7|            4|             2|             4|\n|St01 |            7|            7|            6|            7|            2|            7|            7|            7|            7|             5|             7|\n\n</div>\n:::\n:::\n\n\nHow many rows/observations and columns/variables do we have in `qrp_step1`?\n\n* rows/observations: <input class='webex-solveme nospaces' size='2' data-answer='[\"89\"]'/>\n* columns/variables: <input class='webex-solveme nospaces' size='2' data-answer='[\"12\"]'/>\n\n\n## `pivot_longer()`\n\nAs you can see, the table we got from step 1 is in wide format. To get it into wide format, we need to define:\n\n* the columns that need to be reshuffled from wide into long format (`col` argument). Here we selected \"everything except the `Code` column\", as indicated by `-Code` [minus `Code`]. However, `QRPs_1_Time1:QRPs_11_Time1` would also work and give you the exact same result.\n* the `names_to` argument. R is creating a new column in which all the column names from the columns you selected in `col` will be stored in. Here we are naming this column \"Items\" but you could pick something equally sensible if you like.\n* the `values_to` argument. R creates this second column to store all responses the participants gave to the individual questions, i.e., all the numbers in this case. We named it \"Scores\" here, but you could have called it something different, like \"Responses\"\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqrp_step2 <- qrp_step1 %>% \n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Scores\")\n\n# show first 15 rows of qrp_step2\nhead(qrp_step2, n = 15)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Code |Items         | Scores|\n|:----|:-------------|------:|\n|Tr10 |QRPs_1_Time1  |      7|\n|Tr10 |QRPs_2_Time1  |      7|\n|Tr10 |QRPs_3_Time1  |      5|\n|Tr10 |QRPs_4_Time1  |      7|\n|Tr10 |QRPs_5_Time1  |      3|\n|Tr10 |QRPs_6_Time1  |      4|\n|Tr10 |QRPs_7_Time1  |      5|\n|Tr10 |QRPs_8_Time1  |      7|\n|Tr10 |QRPs_9_Time1  |      6|\n|Tr10 |QRPs_10_Time1 |      7|\n|Tr10 |QRPs_11_Time1 |      7|\n|Bi07 |QRPs_1_Time1  |      7|\n|Bi07 |QRPs_2_Time1  |      7|\n|Bi07 |QRPs_3_Time1  |      2|\n|Bi07 |QRPs_4_Time1  |      7|\n\n</div>\n:::\n:::\n\n\nNow, have a look at `qrp_step2`. In total, we now have <input class='webex-solveme nospaces' size='3' data-answer='[\"979\"]'/> rows/observations, <input class='webex-solveme nospaces' size='2' data-answer='[\"11\"]'/> per participant, and <input class='webex-solveme nospaces' size='1' data-answer='[\"3\"]'/> columns/variables.\n\n\n## `group_by()` and `summarise()`\n\nIt's exactly the same sequence we did when calculating the descriptive stats per gender above. The only difference is, we are now grouping the data by participant's `Code` rather than `Gender`.\n\n`summarise()` works exactly the same way: \n`summarise(new_column_name = function_to_calculate_something(column_name_of_numeric_values))`\n\nThe `function_to_calculate_something` can be `mean()`, `sd()` or `sum()` for mean scores, standard deviations, or summed up scores respectively. You could also use `min()` or `max()` if you wanted to determine the lowest or the highest score for each participant.\n\n:::\n\n:::\n\n\n\n## Activity 5: Confidence in understanding Open Science practices\n\n#### The main goal is to compute the mean Understanding score per participant. {.unnumbered}\n\nAgain, we only have to compute that for time point 1 because the mean Understanding score for time point 2 was already calculated (column `Time2_Understanding_OS`).\n\nLooking at the Understanding data at time point 1, you determine that\n\n* individual item columns are <select class='webex-select'><option value='blank'></option><option value='x'>numeric</option><option value='answer'>character</option></select>, and \n* according to the codebook, there are <select class='webex-select'><option value='blank'></option><option value='answer'>no</option><option value='x'>some</option></select> reverse-coded items in this questionnaire. \n\nSo the steps are fairly similar to QRP, but we add an extra step, namely turning the character labels into numbers.\n\nAgain, let's do this step by step:\n\n* **Step 1**: select the relevant columns `Code`, and every Understanding column from time point 1 (e.g., from `Understanding_OS_1_Time1` to `Understanding_OS_12_Time1`) and store them in an object called `understanding_t1`\n* **Step 2**: pivot the data from wide format to long format using `pivot_longer()` so we can recode the labels into values (step 3) and calculate the average score (in step 4) more easily\n* **Step 3**: Recode the values \"Not at all confident\" as 1 and \"Entirely confident\" as 7. All other values are already numbers. We can use functions `mutate()` in combination with `case_match()` for that\n* **Step 4**: calculate the average QRP score (`QRPs_Acceptance_Time1_mean`) per participant using `group_by()` and `summarise()`\n\n#### Steps 1 and 2 {.unnumbered}\n\nHow about you try the first 2 steps yourself using the code from Activity 4 (@sec-ch2_act4) as a template?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1 <- data_prp %>% \n  select(???) %>% # Step 1\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\") # Step 2\n```\n:::\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution for steps 1 and 2\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1 <- data_prp %>% \n  # Step 1\n  select(Code, Understanding_OS_1_Time1:Understanding_OS_12_Time1) %>% \n  # Step 2 - I picked different column labels this time for some variety\n  pivot_longer(cols = Understanding_OS_1_Time1:Understanding_OS_12_Time1, names_to = \"Understanding_Qs\", values_to = \"Responses\") \n```\n:::\n\n:::\n\n#### Step 3 {.unnumbered}\n\nOK, we now want to recode the values in the `Responses` column (or whatever name you picked for your column that has some of the numbers in it) so that \"Not at all confident\" = 1 and \"Entirely confident\" = 7. We want to keep all other values as they are (2-6 look already quite \"numeric\"). \n\nLet's create a new column `Responses_corrected` that stores the new values with `mutate()`. Then we can combine that with the `case_match()` function.\n\n* The first argument in `case_match()` is the column name of the variable you want to recode.\n* Then you can start recoding the values in the way of `CurrentValue ~ NewValue` (~ is a tilde). Make sure you use the `~` and not `=`.\n* The `.default` argument tells R what to do with values that are neither \"Not at all confident\" nor \"Entirely confident\". Here, we want to replace them with the original value of the `Responses` column. In other datasets, you may want to set the default to `NA` for missing values, a character string or a number, and `case_match()` is happy to oblige.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = Responses # all other values taken from column Responses\n  ))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `mutate()`:\nℹ In argument: `Responses_corrected = case_match(...)`.\nCaused by error in `case_match()`:\n! Can't combine `..1 (right)` <double> and `.default` <character>.\n```\n:::\n:::\n\n\n::: {.callout-important collapse=\"true\"}\n\n## Error!!! Can you explain what is happening here?\n\nHave a look at the error message. It's pretty helpful this time. It says `Can't combine ..1 (right) <double> and .default <character>.` It means that the replacement values are expected to be character data type since the original column type was a character.\n\n:::\n\n**So how do we fix this?** Actually, there are several ways how this could be done. Click on the tabs below to check out 3 possible solutions.\n\n::: {.panel-tabset group=\"layers\"}\n\n## Fix option 1\n\nOne option is to modify the `.default` argument `Responses` so that the values are copied over from the original column, but as a number rather than a character value. The function `as.numeric()` does the conversion. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1_step3_v1 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  ))\n```\n:::\n\n\n## Fix option 2\n\nChange the numeric values on the right side of the `~` to character. Then in a second step, we would need to turn the character column into a numeric type. Again, we have several options to do so. We could either use the `parse_number()` function we encountered earlier during the demographics wrangling or the `as.numeric()` function.\n\n* V1: `Responses_corrected = parse_number(Responses_corrected)`\n* V2: `Responses_corrected = as.numeric(Responses_corrected)`\n\nJust pay attention that you are still working *within* the `mutate()` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1_step3_v2 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ \"1\",\n                                          \"Entirely confident\" ~ \"7\",\n                                          .default = Responses # all other values taken from column Responses (character)\n  ),\n  Responses_corrected = parse_number(Responses_corrected)) # turning Responses_corrected into a numeric column\n```\n:::\n\n\n\n## Fix option 3\n\nIf you recode all of the labels into numbers (e.g., \"2\" into a 2, \"3\" into a 3, etc.), you would not have to convert anything at the end.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1_step3_v2 <- understanding_t1 %>% \n  mutate(Responses_recoded = case_match(Responses, # column of the values to recode\n                                        \"Not at all confident\" ~ 1, # recode all of them\n                                        \"2\" ~ 2,\n                                        \"3\" ~ 3,\n                                        \"4\" ~ 4,\n                                        \"5\" ~ 5,\n                                        \"6\" ~ 6,\n                                        \"Entirely confident\" ~ 7))\n```\n:::\n\n\n:::\n\n\n::: {.callout-note icon=\"false\"}\n\n## Your Turn\n\nPick whichever option you prefer and modify the code above that didn't work. You should now be able to calculate the **mean Understanding Score per participant**. Store the average scores in a variable called `Time1_Understanding_OS`.\n\n::: {.callout-caution icon=\"false\" collapse=\"true\"}\n\n## One solution for Steps 3 and 4\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  )) %>% \n  # Step 4: calculating averages per participant\n  group_by(Code) %>%\n  summarise(Time1_Understanding_OS = mean(Responses_corrected)) %>%\n  ungroup()\n```\n:::\n\n:::\n\n:::\n\n\nOf course, this could have been written up as a single pipe.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Single pipe of activity 5\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunderstanding_t1 <- data_prp %>% \n  # Step 1\n  select(Code, Understanding_OS_1_Time1:Understanding_OS_12_Time1) %>% \n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Understanding_Qs\", values_to = \"Responses\") %>% \n  # Step 3\n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  )) %>% \n  # Step 4\n  group_by(Code) %>%\n  summarise(Time1_Understanding_OS = mean(Responses_corrected)) %>%\n  ungroup()\n```\n:::\n\n:::\n\n\n\n\n## Activity 6: Survey of Attitudes Toward Statistics (SATS-28)\n\n#### The main goal is to compute the mean SATS-28 score for each of the 4 subscales per participant for time point 1. {.unnumbered}\n\nLooking at the SATS data at time point 1, you determine that\n\n* individual item columns are <select class='webex-select'><option value='blank'></option><option value='answer'>numeric</option><option value='x'>character</option></select>, and\n* according to the codebook, there are <select class='webex-select'><option value='blank'></option><option value='x'>no</option><option value='answer'>some</option></select> reverse-coded items in this questionnaire.\n* Additionally, we are looking to compute the means for the 4 different subscales of the SAT-28 which are <input class='webex-solveme nospaces ignorecase' size='6' data-answer='[\"Affect\"]'/>, <input class='webex-solveme nospaces ignorecase' size='20' data-answer='[\"Cognitive Competence\"]'/>, <input class='webex-solveme nospaces ignorecase' size='5' data-answer='[\"Value\"]'/>, and <input class='webex-solveme nospaces ignorecase' size='10' data-answer='[\"Difficulty\"]'/>.\n\nSo this scenario is slightly more tricky than the previous ones because of the reverse-coding and the 4 subscales. So let's tackle this step by step again:\n\n* **Step 1**: select the relevant columns `Code`, and every SATS28 column from time point 1 (e.g., from `SATS28_1_Affect_Time1` to `SATS28_28_Difficulty_Time1`) and store them in an object called `sats_t1`\n* **Step 2**: pivot the data from wide format to long format using `pivot_longer()` so we can recode the labels into values (step 3) and calculate the average score (in step 4) more easily\n* **Step 3**: We need to know which items belong to which subscale - fortunately, we have that information in the variable name and can use the `separate()` function to access it.\n* **Step 4**: We need to know which items are reverse-coded and then reverse-code them - unfortunately, the info is only in the codebook and we need to find a work-around. `case_when()` can help identify and re-score the reverse-coded items.\n* **Step 5**: calculate the average SATS score per participant and subscale using `group_by()` and `summarise()`\n* **Step 6**: use `pivot_wider()` to spread out the dataframe into wide format and `rename()` to tidy up the datanames\n\n#### Steps 1 and 2 {.unnumbered}\n\nThe selecting and pivoting are exactly the same way as we already practiced in the other 2 tasks. Apply them here to this questionnaire.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"} \n\n## Hint\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- data_prp %>% \n  select(???) %>% # Step 1\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\") # Step 2\n```\n:::\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution for steps 1 and 2\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- data_prp %>% \n  select(Code, SATS28_1_Affect_Time1:SATS28_28_Difficulty_Time1) %>% # Step 1\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Response\") # Step 2\n```\n:::\n\n:::\n\n:::\n\n\n#### Step 3: separate Subscale information {.unnumbered}\n\nIf you look at the the `Items` column more closely, you can see that there is information on the `Questionnaire`, the `Item_number`, the `Subscale`, and the `Timepoint` the data was collected at.\n\nWe can separate the information into separate columns using the `separate()` function. The function's first argument is the column to separate, then define `into` which columns you want the original column split up, and lastly, define the separator `sep` (here an underscore). For our example, we would write\n\n* V1: `separate(Items, into = c(\"SATS\", \"Item_number\", \"Subscale\", \"Time\"), sep = \"_\")`\n\nHowever, we don't need all of those columns, so we could just drop the ones we are not interested in by replacing them with `NA`.\n\n* V2: `separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\")`\n\nWe might also add an extra argument of `convert = TRUE` to have numeric columns (i.e., `Item_number`) converted to numeric as opposed to keeping them as character. Saves us typing a few quotation marks later in Step 4.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  # Step 3\n  separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\", convert = TRUE)\n```\n:::\n\n\n\n#### Step 4: identifying reverse-coded items and then correct them {.unnumbered}\n\nWe can use `case_when()` within the `mutate()` function here to create a new column `FW_RV` that stores information on whether the item is a reverse-coded item or not.\n\n`case_when()` works in a similar way to `case_match()`, but `case_match()` only allows to \"recode\" values (i.e. replace one value with another), whereas `case_when()` lets you use **conditional statements** on the left side of the tilde which is useful when you only want to change *some* of the data based on specific conditions.\n\nLooking at in the codebook, it seems that items 2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28 are reverse-coded items. The rest are forward-coded.\n\nWe want to tell R now, that \n\n* **if** the `Item_number` is any of those numbers listed above, R should write \"Reverse\" into the new column `FW_RV` we are creating. Since we have a few possible matches for `Item_number`, we need the Boolean expression `%in%` rather than `==`. \n* **if** `Item_number` is none of those numbers, then we would like the word \"Forward\" in the `FW_RV` column to appear. We can achieve that by specifying a `.default` argument again, but this time we want a \"word\" rather than a value from another column.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  mutate(FW_RV = case_when(\n    Item_number %in% c(2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28) ~ \"Reverse\",\n    .default = \"Forward\"\n  ))\n```\n:::\n\n\n\nOnto the actual correcting of the scores. Again, we can use `case_when ()` within the `mutate()` function for another **conditional statement**. This time, the condition is:\n\n* **if** `FW_RV` column has a value of \"Reverse\" then we would like to turn all 1 into 7, 2 into 6, etc.\n* **if** `FW_RV` column has a value of \"Forward\" then we would like keep the score from the `Response` column\n\nThere is a quick way and a not so quick way to achieve the actual **reverse-coding**.\n\n* Option 1 (quick): The easiest way to reverse-code scores is by taking the maximum value of the scale, add 1 unit and then subtract the original value. For example, on a 5-point Likert scale, it would be 6 minus the Response; for a 7-point Likert scale, 8-Response, etc. (see tab Option 1).\n* Option 2 (not so quick): This includes the use of 2 conditional statements (see tab Option 2).\n\n\nUse the one you find more intuitive.\n\n::: {.panel-tabset}\n\n\n## Option 1\n\nHere we are using the Boolean expression to determine if there is a string \"Reverse\" in the `FW_RV` column. And if that conditional statement is `TRUE` then the value in new column we are creating `Scores_corrected` should be calculated as 8 minus the value from the `Response` column. If it's not (i.e., the `.default` argument), then the values of the `Response` column should be kept.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  mutate(Scores_corrected = case_when(\n    FW_RV == \"Reverse\" ~ 8-Response,\n    .default = Response\n  ))\n```\n:::\n\n\n## Option 2\n\nAs stated above, the longer version would include 2 conditional statements. The first condition checks if the value in `FW_RV` is \"Reverse\". The second condition checks if the value in `Response` is equal to a specific number. **If both of these conditions are met**, then the value on the right side of the tilde should be placed in the newly created `Scores_corrected_v2` column.\n\nFor example, line 3 would read: if the `FW_RV` value is \"Reverse\" **AND** the value in the Response column is 1, then place a value of 7 into `Scores_corrected_v2`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  mutate(Scores_corrected_v2 = case_when(\n    FW_RV == \"Reverse\" & Response == 1 ~ 7,\n    FW_RV == \"Reverse\" & Response == 2 ~ 6,\n    FW_RV == \"Reverse\" & Response == 3 ~ 5,\n    # no need to recode 4 as 4\n    FW_RV == \"Reverse\" & Response == 5 ~ 3,\n    FW_RV == \"Reverse\" & Response == 6 ~ 2,\n    FW_RV == \"Reverse\" & Response == 7 ~ 1,\n    .default = Response\n  ))\n```\n:::\n\n\nAs you can see now in `sats_t1`, both columns `Scores_corrected` and `Scores_corrected_v2` are identical.\n:::\n\nOne way of **checking whether our reverse-coding worked** is to look at the `distinct` values of the original `Response` column and `Scores_corrected`. We would also need to keep information of the `FW_RV` column. \n\nAnd to see the pattern better, we want to use `arrange()` to sort the values in a more meaningful way. Remember from last year, the default order is ascending, and you would need to add the function `desc()` on your variable to sort values in a descending order.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_coding <- sats_t1 %>% \n  distinct(FW_RV, Response, Scores_corrected) %>% \n  arrange(desc(FW_RV), Response)\n```\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Show `check_coding` output\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_coding\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|FW_RV   | Response| Scores_corrected|\n|:-------|--------:|----------------:|\n|Reverse |        1|                7|\n|Reverse |        2|                6|\n|Reverse |        3|                5|\n|Reverse |        4|                4|\n|Reverse |        5|                3|\n|Reverse |        6|                2|\n|Reverse |        7|                1|\n|Forward |        1|                1|\n|Forward |        2|                2|\n|Forward |        3|                3|\n|Forward |        4|                4|\n|Forward |        5|                5|\n|Forward |        6|                6|\n|Forward |        7|                7|\n\n</div>\n:::\n:::\n\n\n\n:::\n\n#### Step 5 {.unnumbered}\n\nNow that we know everything worked out as intended, we can calculate the mean scores of each subscale for each participant in `sats_t1`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"} \n\n## Hint\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  group_by(???, ???) %>% \n  summarise(mean_score = ???(???)) %>% \n  ungroup()\n```\n:::\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  group_by(Code, Subscale) %>% \n  summarise(mean_score = mean(Scores_corrected)) %>% \n  ungroup()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'Code'. You can override using the\n`.groups` argument.\n```\n:::\n:::\n\n:::\n\n:::\n\n#### Step 6 {.unnumbered}\n\nOne final step is to turn the data back into **wide format** so that each subscale has its own column. That would make joining the data objects easier. The first argument in `pivot_wider()` is `names_from` and you should specify the column here that you want as your new column headings. The second argument is `values_from` and you need to specify the column that you want to get the cell values from\n\nWe should also **rename the column names** to match more with the column names in the codebook. Conveniently, we can use a function called `rename()` that works exactly like `select()` (i.e., `new_name = old_name`) but keeps all the other column names the same (rather than reducing the number of columns)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- sats_t1 %>% \n  pivot_wider(names_from = Subscale, values_from = mean_score) %>% \n  rename(SATS28_Affect_Time1_mean = Affect,\n         SATS28_CognitiveCompetence_Time1_mean = CognitiveCompetence,\n         SATS28_Value_Time1_mean = Value,\n         SATS28_Difficulty_Time1_mean = Difficulty)\n```\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Show final `sats_t1` output\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(sats_t1, n = 5)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Code | SATS28_Affect_Time1_mean| SATS28_CognitiveCompetence_Time1_mean| SATS28_Difficulty_Time1_mean| SATS28_Value_Time1_mean|\n|:----|------------------------:|-------------------------------------:|----------------------------:|-----------------------:|\n|AD03 |                 2.333333|                              3.833333|                     3.428571|                5.555556|\n|AD05 |                 3.500000|                              5.000000|                     2.142857|                4.777778|\n|Ab01 |                 5.166667|                              5.666667|                     4.142857|                5.444444|\n|Al05 |                 2.166667|                              2.666667|                     2.857143|                3.777778|\n|Am05 |                 4.166667|                              5.666667|                     5.571429|                4.888889|\n\n</div>\n:::\n:::\n\n\n:::\n\nAgain, this could have been written up as a single pipe.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Single pipe of activity 6\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsats_t1 <- data_prp %>% \n  # Step 1\n  select(Code, SATS28_1_Affect_Time1:SATS28_28_Difficulty_Time1) %>% \n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Response\") %>% \n  # Step 3\n  separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\", convert = TRUE) %>% \n  # step 4\n  mutate(FW_RV = case_when(\n    Item_number %in% c(2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28) ~ \"Reverse\",\n    .default = \"Forward\"\n  ),\n    Scores_corrected = case_when(\n      FW_RV == \"Reverse\" ~ 8-Response,\n      .default = Response\n  )) %>% \n  # step 5\n  group_by(Code, Subscale) %>% \n  summarise(mean_score = mean(Scores_corrected)) %>% \n  ungroup() %>% \n  # step 6\n  pivot_wider(names_from = Subscale, values_from = mean_score) %>% \n  rename(SATS28_Affect_Time1_mean = Affect,\n         SATS28_CognitiveCompetence_Time1_mean = CognitiveCompetence,\n         SATS28_Value_Time1_mean = Value,\n         SATS28_Difficulty_Time1_mean = Difficulty)\n```\n:::\n\n:::\n\n\n\n## Activity 7 (Error Mode): Perceptions of supervisory support\n\n#### The main goal is to compute the mean score for perceived supervisory support per participant. {.unnumbered}\n\nLooking at the Understanding data at time point 1, you determine that\n\n* individual item columns are <select class='webex-select'><option value='blank'></option><option value='answer'>numeric</option><option value='x'>character</option></select>, and\n* according to the codebook, there are <select class='webex-select'><option value='blank'></option><option value='x'>no</option><option value='answer'>some</option></select> reverse-coded items in this questionnaire.\n\nI have outlined my steps as follows: \n\n* **Step 1**: reverse-code the single column first because that's less hassle than having to do that with conditional statements (`Supervisor_15_R`). `mutate()` is my friend.\n* **Step 2**: I want to filter out everyone who failed the attention check in `Supervisor_7`. I can do this with a Boolean expression within the `filter()` function. The correct response was \"completely disagree\" which is 1.\n* **Step 3**: select their id from time point 2 and all the columns that start with the word \"super\", apart from `Supervisor_7` and the original `Supervisor_15_R` column\n* **Step 4**: pivot into long format so I can calculate the averages better\n* **Step 5**: calculate the average scores per participant\n\n\nI've started coding but there are some errors in my code. Help me find and fix all of them. Try to go through the code line by line and read the error messages.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsuper <- data_ppr %>% \n  mutate(Supervisor_15 = 9-supervisor_15_R) %>% \n  filter(Supervisor_7 = 1) %>% \n  select(Code, starts_with(\"Super\"), -Supervisor_7, -Supervisor_15_R) \npivot_wider(cols = -Code, names_to = \"Item\", values_to = \"Response\") %>% \n  group_by(Time2_Code) %>% \n  summarise(Mean_Supervisor_Support = mean(Score_corrected, na.rm = TRUE)) %>% \n  ungroup()\n```\n:::\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Reveal solution\n\nThere were 8 mistakes in the code. Let's go through them line by line.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsuper <- data_prp %>% # spelling mistake in data object\n  mutate(Supervisor_15 = 8-Supervisor_15_R) %>% # semantic error: 8 minus response for a 7-point scale and supervisor_15_R needs a capital S\n  filter(Supervisor_7 == 1) %>% # needs a Boolean expression == instead of =\n  select(Code, starts_with(\"Super\"), -Supervisor_7, -Supervisor_15_R) %>% # no pipe at the end, the rest is actually legit\n  pivot_longer(cols = -Code, names_to = \"Item\", values_to = \"Response\") %>% # pivot_longer instead of pivot_wider\n  group_by(Code) %>% # Code rather than Time2_Code - the reduced dataset does not contain Time2_Code\n  summarise(Mean_Supervisor_Support = mean(Response, na.rm = TRUE)) %>% # Score_corrected doesn't exist; needs to be Response\n  ungroup()\n```\n:::\n\n\nDid you spot them all? \n\n* Note that the **semantic error** in line 2 did not give you an error message.\n* Were you thrown off by the `starts_with(\"Super\")` expression in line 4? `starts_with()` and `ends_with()` are great alternatives to selecting columns via `:` But, using `select(Code, Supervisor_1:Supervisor_6, Supervisor_8:Supervisor_14)` would have given us the same result.\n\n:::\n\n\n## Activity 8: Joining everything together with `???_join()`\n\nTime to join all of the relevant data files together so we have a single dataframe ready for the next chapter on data visualisation. There are 4 options of joining data together, namely `inner_join()`, `left_join()`, `right_join()`, and `full_join()`. Each of these functions differs in terms of what information is retained from the two data objects being joined. Here is a quick overview:\n\n\n::: {.callout-note collapse=\"true\"} \n\n## Additional info on mutating joins\n\nYou have 4 types of join functions you could make use of. Click on the panels to know more\n\n::: {.panel-tabset}\n\nA mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.\n\n## `inner_join()`\n\n`inner_join()` returns only the rows where the values in the column specified in the `by =` statement match in both tables.\n\n![inner_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/inner-join.gif)\n\n## `left_join()`\n\n`left_join()` retains the complete first (left) table and adds values from the second (right) table that have matching values in the column specified in the `by =` statement. Rows in the left table with no match in the right table will have missing values (`NA`) in the new columns.\n\n![left_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/left-join.gif)\n\n## `right_join()`\n\n`right_join()` retains the complete second (right) table and adds values from the first (left) table that have matching values in the column specified in the `by =` statement. Rows in the right table with no match in the left table will have missing values (`NA`) in the new columns.\n\n![right_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/right-join.gif)\n\n## `full_join()`\n\n`full_join()` returns all rows and all columns from both tables. `NA` values fill unmatched rows.\n\n![full_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/full-join.gif)\n\n:::\n\n:::\n\n\nFrom our data_prp, we would need to select demographics data and all summarised questionnaire data from time point 2. And then we want to join all other aggregated datasets from time point 1 that are currently in separate data objects in our `Global Environment`. \n\nYou already encountered `inner_join` last year, but for the minute, we want to keep all of the data from all the data objects and use a `full_join` instead. You are only able to join a max of 2 data objects together, so there will be quite a bit of piping and joining going on in code chunk.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_prp_final <- data_prp %>% \n  select(Code:Plan_prereg, Other_OS_behav_2:Time2_Understanding_OS) %>% \n  full_join(qrp_t1) %>% \n  full_join(understanding_t1) %>% \n  full_join(sats_t1) %>% \n  full_join(super)\n```\n:::\n\nAnd this is basically the dataset we need for @sec-dataviz and @sec-dataviz2.\n\n\n\n\n\n\n\n## Knitting\n\nas a means to check if the file as a whole is running\n\n\n\n\n\n\n\n\n\n## [Pair-coding in the lab]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n## [Test your knowledge and challenge yourself]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}