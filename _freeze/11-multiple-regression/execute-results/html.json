{
  "hash": "b2ef3c33012046527b394462e27eac12",
  "result": {
    "markdown": "# Multiple regression {#sec-reg_mult}\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n- Apply and interpret multiple linear regression models.\n- Interpret coefficients from individual predictors and interactions.\n- Visualise interactions as model predictions to understand and communicate your findings.\n- Calculate statistical power for a multiple regression model.\n\nIn the previous chapter, we have looked at simple regressions - predicting an outcome variable using one predictor variable. In this chapter, we will expand on that and look at scenarios where we predict an outcome using more than one predictor in the model - hence, multiple regression.\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n## Activity 1: Setup & download the data\n\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\n* **Create a new project** and name it something meaningful (e.g., \"2B_chapter11\", or \"11_multople_regression\"). See @sec-project if you need some guidance.\n* **Create a new `.Rmd` file** and save it to your project folder. See @sec-rmd if you need help. \n* Delete everything after the setup code chunk (e.g., line 12 and below) \n* **Download the new dataset** here: [data_ch11.zip](data/data_ch11.zip \"download\"). The zip folder includes:\n  * the demographics data file (`Przybylski_2017_demographics.csv`)\n  * the screentime data file (`Przybylski_2017_screentime.csv`)\n  * the wellbeing data file (`Przybylski_2017_wellbeing.csv`), and the\n  * the codebook (`Przybylski_2017_Codebook.xlsx`).\n* Extract the data file from the zip folder and place it in your project folder. If you need help, see @sec-download_data_ch1.\n\n\n\n**Citation**\n\n> Przybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. *Psychological Science, 28*(2), 204-215. [https://doi.org/10.1177/0956797616678438](https://doi.org/10.1177/0956797616678438){target=\"_blank\"}\n\n\n\n\n**Abstract**\n\n> Although the time adolescents spend with digital technologies has sparked widespread concerns that their use might be negatively associated with mental well-being, these potential deleterious influences have not been rigorously studied. Using a preregistered plan for analyzing data collected from a representative sample of English adolescents (*n* = 120,115), we obtained evidence that the links between digital-screen time and mental well-being are described by quadratic functions. Further, our results showed that these links vary as a function of when digital technologies are used (i.e., weekday vs. weekend), suggesting that a full understanding of the impact of these recreational activities will require examining their functionality among other daily pursuits. Overall, the evidence indicated that moderate use of digital technology is not intrinsically harmful and may be advantageous in a connected world. The findings inform recommendations for limiting adolescents’ technology use and provide a template for conducting rigorous investigations into the relations between digital technology and children’s and adolescents’ health.\n\nThe data is available on OSF: [https://osf.io/bk7vw/](https://osf.io/bk7vw/){target=\"_blank\"}\n\n\n\n**Changes made to the dataset**\n\n* We converted the SPSS file into a CSV file. There is a CSV file in their OSF folder, however, it does have any labels or values explained. Therefore, we started from the SPSS file that has a bit more information.\n* We reduced the dataset by selecting some of the variables relating to demographics, screentime and wellbeing.\n* Data was separated into 3 files: demographics, screentime, and wellbeing.\n* Screentime values were recoded and display hours according to the codebook.\n* Rows with missing values were excluded in `screentime.csv` and `wellbeing.csv`.\n* We also created a codebook for the variables we selected.\n\n\n\n\n\n\n## Activity 2: Load in the library, read in the data, and familiarise yourself with the data\n\nToday, we will be using the packages `tidyverse`, `sjPlot`, `performance`, and `pwr`, along with the datasets `Alter_2024_data.csv`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n???\n\ndemo <- ???\nscreentime <- ???\nwellbeing <- ???\n```\n:::\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(performance)\nlibrary(pwr)\n\ndemo <- read_csv(\"Przybylski_2017_demographics.csv\")\nscreentime <- read_csv(\"Przybylski_2017_screentime.csv\")\nwellbeing <- read_csv(\"Przybylski_2017_wellbeing.csv\")\n```\n:::\n\n\n:::\n\nAs always, take a moment to familiarise yourself with the data before starting your analysis.\n\nOnce you have explored the data objects and the codebook, try and answer the following questions: \n\n* The variable Gender is located in the object named <select class='webex-select'><option value='blank'></option><option value='answer'>demo</option><option value='x'>wellbeing</option><option value='x'>screentime</option></select>.\n* The wellbeing data is in <select class='webex-select'><option value='blank'></option><option value='x'>long</option><option value='answer'>wide</option></select> format and contains observations from <input class='webex-solveme nospaces' size='10' data-answer='[\"102580\",\"102,580\"]'/> participants. \n* The wellbeing questionnaire has <input class='webex-solveme nospaces' size='2' data-answer='[\"14\"]'/> items.\n* Individual participants in this data set are identified by the variable called <input class='webex-solveme nospaces ignorecase' size='9' data-answer='[\"Serial\"]'/>. This variable will allow us to link information across the three tables.\n* Are there any missing data points? <select class='webex-select'><option value='blank'></option><option value='x'>Yes</option><option value='answer'>No</option></select>\n\n\n#### Potential Research Question & Hypthesis {.unnumbered}\n\nThere is ongoing debate about the impact of smartphones on well-being, particularly among children and teenagers. Hence, we will examine whether smartphone use predicts mental well-being and whether this relationship differs between male and female adolescents.\n\n\n* **Potential research question**: \"Does smartphone use predict mental well-being, and does this relationship differ between male and female adolescents?\"\n* **Null Hypothesis (H~0~)**: \"Smartphone use does not predict mental well-being, and there is no difference in this relationship between male and female adolescents.\"\n* **Alternative Hypothesis (H~1~)**: \"Smartphone use is a significant predictor of mental well-being, and the effect of smartphone use on well-being differs between male and female adolescents.\"\n\n\n\nNote that in this analysis, we have:\n\n* a continuous* DV, well-being;\n* a continuous* predictor, screen time;\n* a categorical predictor, gender.\n\n_* these variables are only quasi-continuous, inasmuch as only discrete values are possible. However, there are a sufficient number of discrete categories that we can treat them as effectively continuous._\n\n## Activity 3: Compute descriptives\n\nToday, we will be dealing with the majority of data wrangling in the following activities. So let's bring Computing descriptives forward\n\n\n### Well-being \n\nWe need to do some initial data wrangling on `wellbeing`. \nFor each participant, compute the total score for the mental health questionnaire. Store the output in a new data object called `wemwbs`. \n\nThe new dataset should have two variables:\n\n* `Serial` - the participant ID.\n* `WEMWBS_sum` - the total WEMWBS score.\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwemwbs <- wellbeing %>%\n  pivot_longer(cols = starts_with(\"WB\"), # -Serial or WBOptimf:WBCheer also work\n               names_to = \"Qs\", \n               values_to = \"Score\") %>%\n  group_by(Serial) %>%\n  summarise(WEMWBS_sum = sum(Score)) %>% \n  ungroup()\n```\n:::\n\n\n:::\n\n\nIn the original paper, Przybylski and Weinstein (2017) reported: \"Scores ranged from 14 to 70 (M = 47.52, SD = 9.55)\". Can you reproduce these values?\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hint\n\nMeans and standard deviations should not be an issue at this stage, but how would you calculate the minimum and the maximum? \n\nWe addressed it briefly in @sec-wrangling and it's more intuitive than you think...\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nYes, you are correct. The functions `min()` and `max()` calculate minimum and maximum values respectively.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwemwbs %>% \n  summarise(mean = mean(WEMWBS_sum),\n            sd = sd(WEMWBS_sum),\n            min = min(WEMWBS_sum),\n            max = max(WEMWBS_sum))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|     mean|       sd| min| max|\n|--------:|--------:|---:|---:|\n| 47.52189| 9.546374|  14|  70|\n\n</div>\n:::\n:::\n\n:::\n\n\n### Screentime\n\nWe want to calculate means and standard deviations of the hours of smartphone use during the week and on the weekend.\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nWe are just computing the information rather than storing it. If you want to save the output as an object to your `Global Environment`, feel free to do so.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscreentime %>% \n  summarise(smart_weekday_mean = mean(Smart_wk),\n            smart_weekday_sd = sd(Smart_wk),\n            smart_weekend_mean = mean(Smart_we),\n            smart_weekend_sd = sd(Smart_we))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| smart_weekday_mean| smart_weekday_sd| smart_weekend_mean| smart_weekend_sd|\n|------------------:|----------------:|------------------:|----------------:|\n|           2.910655|          2.33917|           3.517003|         2.497139|\n\n</div>\n:::\n:::\n\n:::\n\n\n## Activity 4: Recreating the plot from the paper\n\nIf there was a bit of a challenge, this is it. We can wrangle the data to plot the data like the original article (shown below).\n\n![Fig. 1. Mental well-being as a function of daily digital-screen time on weekdays and weekends. Results are shown separately for time spent (a) watching TV and movies, (b) playing video games, (c) using computers, and (d) using smartphones. Error bars denote the 95% confidence intervals for the observed means. (Przybylski & Weinstein, 2017)](images/figure_Przybylski.jpeg)\n\nThe graph shows that smartphone use of more than 1 hour per day is associated with increasingly negative well-being.\n\nWe can plot the relationship between well-being and hours of technology use, split into four categories of technology (video games, computers, smartphones, TV).\n\nThere is some faceting going on and you will not have been introduced to all the functions we need. \n\n::: {.callout-tip icon=\"false\"}\n\n## Observations\n\nLet's start with some observations:\n\nA) We need information on hours of screentime (x-axis) and mental well-being (y-axis), that is currently stored in `screentime` and in `wellbeing`, respectively. That means we have to join the two datasets at some point.\n\nB) Our dataframe needs to be restructured into longformat so that we can use the function `facet_wrap()`. \n\nC) We need to process weekend and weekday data separately. At the moment, it is hidden in the column labels, so we need to think about how we can access the information.\n\nD) The plot shows us average hours and wellbeing scores per weekday/weekend. So we need to compute them.\n\nE) We have to use a lineplot (e.g., `geom_line`) and a scatterplot because we need a line with dots.\n\nF) And it would be nice if the different categories are clearly labelled in the plot rather than having to mention them below the figure\n\n:::\n\nNow it's just figuring out which sequence we need them to be in. There are steps to do (or that easier to do) in the dataframe and then there is plotting. \n\nSooo, let's start with any changes we can apply to the dataframe `screentime`. We should store the new output in an object called `screen_long`.\n\n**Step 1**: Pivot `screentime` into long format.\n\n**Step 2**: To be able to access information on weekday/weekend and on the four categories of technology, we need to separate information in the current column levels. Anything before the separator `_` is category of technology; anything after is related to weekday/weekend (e.g., `Watch_we`, `Smart_wk`). That is easier done when the data is in long format.\n\n**Step 3**: The values `Watch`, `Smart`, `we` or `wk` are not really informative and these will be the labels that are displayed on the facets and legends in the final plot. Tidying a legend label can still be done in the plots, but for facets it's a nightmare, so better do that here. So here we want to relabel values as follows:\n\n* \"Watch\" should become \"Watching TV\",\n* \"Comp\" -> \"Playing Video Games\",\n* \"Comph\" -> \"Using Computers\",\n* \"Smart\" -> \"Using Smartphone\",\n* \"wk\" -> \"Weekdays\", and\n* \"we\" ~ \"Weekends\".\n\n**Step 4**: We have all information for the plot in one place. Join `screen_long` and `wemwbs` together so that participants have values in both dataframes.\n\n**Step 5**: For each technology type and screentime hours, compute averages of well-being for Weekdays and Weekends. Maybe steps 4 and 5 are better stored in a separate data object called `dat_means`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n## Hints\n\n* Step 1: uses `pivot_longer()`\n* Step 2: remember the `separate()` function. It will come in handy here. And the separator needs to be \"_\".\n* Step 3: requires a simple recoding of the values, no conditional statements necessary\n* Step 4: `inner_join()`\n* Step 5: think about what column you need to `group_by()` before you can `summarise()`\n\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nWe are just computing the information rather than storing it. If you want to save it as an object to your `Global Environment`, feel free to do so.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscreen_long <- screentime %>%\n  # Step 1: Pivot into long format\n  pivot_longer(cols = -Serial, names_to = \"headings\", values_to = \"hours\") %>%\n  # Step 2: `separate()`\n  separate(col = headings, into = c(\"technology_type\", \"day\"), sep = \"_\") %>% \n  # Step 3: Recode the values\n  mutate(technology_type = case_match(technology_type,\n                                      \"Watch\" ~ \"Watching TV\",\n                                      \"Comp\" ~ \"Playing Video Games\",\n                                      \"Comph\" ~ \"Using Computers\",\n                                      \"Smart\" ~ \"Using Smartphone\"),\n         day = case_match(day,\n                          \"wk\" ~ \"Weekdays\",\n                          \"we\" ~ \"Weekends\"))\n\ndat_means <- inner_join(wemwbs, screen_long, by = \"Serial\") %>% # Step 4: joining\n  # Step 5: group_by & summarise\n  group_by(technology_type, day, hours) %>%\n  summarise(mean_wellbeing = mean(WEMWBS_sum))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'technology_type', 'day'. You can override\nusing the `.groups` argument.\n```\n:::\n:::\n\n:::\n\nNow we can plot. There are a few new features in relation to line plots and point shapes. Check them out.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(dat_means, aes(x = hours, y = mean_wellbeing, linetype = day, shape = day)) +\n  geom_line() +\n  geom_point() +\n  scale_shape_manual(values=c(15, 16)) +\n  facet_wrap(~ technology_type) + \n  theme_classic() + \n  labs(x = \"Hours of Technology Use\",\n       y = \"Mean Well-Being Score\")\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## More info on plot parameters\n\n* aes `linetype` changes the type of line, e.g., solid or dotty, and here we specified it to be different for each type of day. More on line types can be found here: [https://sape.inf.usi.ch/quick-reference/ggplot2/linetype.html](https://sape.inf.usi.ch/quick-reference/ggplot2/linetype.html){target=\"_blank\"}\n* to change the shape of the points, we specified `shape` in the aes, and we defined that it should depend on line of day. However, the point shapes turned into round dots and triangles. Since the original plot suggests dots and squares, we fixed that by adding the `scale_shape_manual()` function. More on point shapes can be found here: [https://www.sthda.com/english/wiki/ggplot2-point-shapes](https://www.sthda.com/english/wiki/ggplot2-point-shapes){target=\"_blank\"}\n\nIf you are looking really closely, you will notice that the boxes are in a different order and that the x- and y-axes span a bit further. Feel free to fix that yourself.\n\nAlso, using facets rather than individual plots means that we have axes labels that span all plots, rather than individual plots we patch together. Plus, the legend is on the side and not within each square. Ah well. Let's call it a conceptual replication, then, shall we?\n\n:::\n\n\n\n## Activity 5: Dataframe for the regression model\n\n### Final data wrangling steps\n\nCreate a new data object that has the mean number of hours per day of smartphone use for each participant, averaged over weekends/weekdays. Because \nPrzybylski and Weinstein's graph showed that smartphone use of more than 1 hour per day is associated with increasingly negative well-being, we want to filter the data to only include those who use a smart phone for more than one hour per day.\n\nWe have done the legwork above when we created `screen_long`, so we could start from there, or we can go back to our original `screentime` object. Pick the option that makes most sense to you.\n\nWe want to join the wrangled data with well-being, as we did above, but also join with the rest of the participant information, since we need the Gender variable.\n\nStore that output in an object called `data_smartphone`. \n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints Option 1 (using `screen_long`)\n\n* Step 1: Only include smartphone use and not other technologies.\n* Step 2: Using `screen_long`, calculate a mean score of screentime hours for each participant.\n* Step 3: Only include participants who use a smartphone for more than 1 hour per day.\n* Step 4: Join the above output with `wemwbs`, and `demo`, so that only participants data is shown that have values in all 3 data frames.\n* Step 5: Select all variables of interest (i.e., `Serial`, `WEMWBS_sum`, `average_hours`, and `Gender`)\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution Option 1\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_smartphone <- screen_long %>% \n  # Step 1\n  filter(technology_type == \"Using Smartphone\") %>% \n  # Step 2\n  group_by(Serial) %>% \n  summarise(average_hours = mean(hours)) %>% \n  # Step 3\n  filter(average_hours > 1) %>% \n  # Step 4\n  inner_join(wemwbs) %>% \n  inner_join(demo) %>% \n  # Step 5\n  select(Serial, WEMWBS_sum, average_hours, Gender)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Serial)`\nJoining with `by = join_by(Serial)`\n```\n:::\n:::\n\n:::\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints Option 2 (using `screentime`)\n\n* Step 1: Select all variables from `screentime` that you need. \n* Step 2: Calculate a mean score of screentime hours for each participant. You can either do that by pivoting, grouping and summarising (as we usually do), or calculating `(col1 +col2)/2` to get than average score.\n* Step 3: Only include participants who use a smartphone for more than 1 hour per day.\n* Step 4: Join the above output with `wemwbs`, and `demo`, so that only participants data is shown that have values in all 3 data frames.\n* Step 5: Select all variables of interest (i.e., `Serial`, `WEMWBS_sum`, `average_hours`, and `Gender`)\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution Option 2\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_smartphone <- screentime %>% \n  # Step 1\n  select(Serial, Smart_wk, Smart_we) %>% \n  # Step 2 - different approach to computing averages\n  mutate(average_hours = (Smart_wk + Smart_we)/2) %>% \n  # Step 3\n  filter(average_hours > 1) %>% \n  # Step 4\n  inner_join(wemwbs) %>% \n  inner_join(demo) %>% \n  # Step 5\n  select(Serial, WEMWBS_sum, average_hours, Gender)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Serial)`\nJoining with `by = join_by(Serial)`\n```\n:::\n:::\n\n:::\n\n### Mean-centering variables\n\nAs you have seen in the lectures, when you have continuous variables in a regression model, it is often sensible to transform them by **mean centering**. You mean center a predictor `X` by subtracting the mean of the predictor (`X_centered = X - mean(X)`) or you can use the `scale()` function. This has two useful consequences:\n\n- The model intercept represents the predicted value of $Y$ when the predictor variable is at its mean, rather than at zero in the unscaled version.\n\n- When interactions are included in the model, significant effects can be interpreted as the overall effect of a predictor on the outcome (i.e., a main effect) rather than its effect at a specific level of another predictor (i.e., a simple effect).\n\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0). This is also known as deviation coding.\n\nIf we used dummy coding (i.e., leaving the categorical predictor as 0 and 1) instead of deviation coding, the interpretation would change slightly:\n\n* **Dummy-coding interpretation**: The intercept represents the predicted outcome for the reference group (coded as 0), and the coefficient for the categorical predictor represents the difference in the outcome between the two groups.\n* **Deviation-coding interpretation**: The intercept represents the overall mean outcome across both groups, and the coefficient for the categorical predictor represents the average difference between the two groups, centered around zero.\n\n\nUse `mutate()` to add two new variables to `data_smartphone`: \n\n* `average_hours_centered`: calculated as a mean-centered version of the `total_hours` predictor\n* `gender_recoded`: recode Gender .5 for \"Male\" and -.5 for \"Female or unknown\".\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_smartphone <- data_smartphone %>%\n  mutate(average_hours_centered = average_hours - mean(average_hours),\n         #alternative with the scale function: \n         #average_hours_centered = scale(average_hours, scale = FALSE),\n         gender_recoded = case_match(Gender,\n                                     \"Male\"  ~ 0.5,\n                                     \"Female or unknown\" ~ -0.5),\n         gender_recoded = factor(gender_recoded),\n         Gender = factor(Gender))\n```\n:::\n\n:::\n\n\n## Activity 6: Compute the regression, confidence intervals, and effect size\n\nFor the data in `smart_wb`, use the `lm()` function to calculate the multiple regression model:\n\n$Y_i = \\beta_0 + \\beta_1 X_{1i}  + \\beta_2 X_{2i}  + \\beta_3 X_{3i} + e_i$\n\nwhere\n\n- $Y_i$ is the well-being score for participant $i$;\n\n- $X_{1i}$ is the mean-centered smartphone use variable for participant $i$;\n\n- $X_{2i}$ is gender (-.5 = female, .5 = male);\n\n- $X_{3i}$ is the interaction between smartphone use and gender ($= X_{1i} \\times X_{2i}$)\n\nIn R terms, this translate to the following format:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(OutcomeVariable ~ PredictorVariable1 + PredictorVariable2 + Interaction, data)\n```\n:::\n\n\n\n\n::: {.callout-tip}\n\nThe code `lm(OutcomeVariable ~ PredictorVariable1 + PredictorVariable2, data)` will add predictors 1 and 2. This will provide you with the contributions of each predictor to explain the outcome variable, i.e. main effects only.\n\nHowever, if you are also interested in the interaction between the two predictors, then you would: \n\n* use a `*` instead of a `+`: `lm(OutcomeVariable ~ PredictorVariable1 * PredictorVariable2, data)` for the model to include 2 main effects and the interaction. OR\n* use the longer format and add the interaction term manually `lm(OutcomeVariable ~ PredictorVariable1 + PredictorVariable2 + PredictorVariable1:PredictorVariable2, data)`. Notice the colon `:`\n\n:::\n\n::: {.callout-note icon=\"false\"}\n\n## Your Turn\n\n* Save your model to the object `mod`. \n* Run the `summary()` of your model to see the output of the regression. \n* Compute confidence intervals \n* Compute the effect size $f^2$\n\nThese are the exact same functions as last time, except for the model including more variables.\n\nAnswer the following questions:\n\n* The interaction between smartphone use and gender is shown by the variable <select class='webex-select'><option value='blank'></option><option value='x'>average_hours_centered</option><option value='x'>gender_recoded0.5</option><option value='answer'>average_hours_centered:gender_recoded0.5</option></select>, and this interaction was <select class='webex-select'><option value='blank'></option><option value='answer'>significant</option><option value='x'>non-significant</option></select> at the $\\alpha = .05$ level.\n\n* To 2 decimal places, adjusted $R^2$ suggests the overall model explains what percentage of the variance in well-being scores? <input class='webex-solveme nospaces' size='4' data-answer='[\"9.38\"]'/>\n\n* The *p*-value for the overall model fit is `<2e-16`. Is this statistically significant? <select class='webex-select'><option value='blank'></option><option value='answer'>Yes</option><option value=''>No</option></select>. How would you note that p-value in APA style when writing up the results? <input class='webex-solveme nospaces' size='8' data-answer='[\"p<.001\",\"p < .001\"]'/>\n\n* What is the observed effect size (in $f^2$) for the study to 3 decimal places? <input class='webex-solveme nospaces' data-tol='0.001' size='5' data-answer='[\"0.103\",\".103\"]'/> \n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## model\nmod <- lm(formula = WEMWBS_sum ~ average_hours_centered * gender_recoded, \n               data = data_smartphone)\n\n## regression output\nsummary(mod)\n\n## confidence intervals\nconfint(mod)\n\n## effect size\nr_sq_adj <- summary(mod)$adj.r.squared\nf_2 <- r_sq_adj/(1-r_sq_adj)\nf_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = WEMWBS_sum ~ average_hours_centered * gender_recoded, \n    data = data_smartphone)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                                         Estimate Std. Error t value Pr(>|t|)\n(Intercept)                              44.86740    0.04478 1001.87   <2e-16\naverage_hours_centered                   -0.77121    0.02340  -32.96   <2e-16\ngender_recoded0.5                         5.13968    0.07113   72.25   <2e-16\naverage_hours_centered:gender_recoded0.5  0.45205    0.03693   12.24   <2e-16\n                                            \n(Intercept)                              ***\naverage_hours_centered                   ***\ngender_recoded0.5                        ***\naverage_hours_centered:gender_recoded0.5 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,\tAdjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: < 2.2e-16\n\n                                              2.5 %     97.5 %\n(Intercept)                              44.7796275 44.9551788\naverage_hours_centered                   -0.8170719 -0.7253385\ngender_recoded0.5                         5.0002576  5.2791028\naverage_hours_centered:gender_recoded0.5  0.3796615  0.5244376\n[1] 0.1034697\n```\n:::\n:::\n\n\n:::\n\n## Activity 7: Visualising interactions\n\nIt is very difficult to understand an interaction from the coefficient alone, so your best bet is visualising the interaction to help you understand the results and communicate your results to your readers. \n\nThere is a great package called `sjPlot` which takes regression models and helps you plot them in different ways. We will demonstrate plotting interactions, but for further information and options, see the [online documentation](https://strengejacke.github.io/sjPlot/articles/plot_interactions.html){target=\"_blank\"}.\n\nTo plot the interaction, you need the model object (not the summary), specify \"pred\" as the `type` as we want to plot predictions, and add the `terms` you want to plot. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_model(mod, \n           type = \"pred\", \n           terms = c(\"average_hours_centered\", \"gender_recoded\"))\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nWhat is the most reasonable interpretation of the interaction? \n\n<div class='webex-radiogroup' id='radio_QMUVAUHYZL'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QMUVAUHYZL\" value=\"x\"></input> <span>smartphone use harms boys more than girls</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QMUVAUHYZL\" value=\"x\"></input> <span>there is no evidence for gender differences in the relationship between smartphone use and well-being</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QMUVAUHYZL\" value=\"answer\"></input> <span>smartphone use was more negatively associated with wellbeing for girls than for boys</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QMUVAUHYZL\" value=\"x\"></input> <span>smartphone use harms girls more than boys</span></label></div>\n\n\n\n\n::: {.callout-caution} \n\n`plot_model()` uses `ggplot2` in the background. You can add further customisation by adding layers after the initial function. You can also use `ggsave()` to save your plots and insert them into your work. \n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n## Example of a more tidy plot\n\nFor example, we can tidy up the axis labels and remove the title, and set a theme. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_model(mod, \n           type = \"pred\", \n           terms = c(\"average_hours_centered\", \"gender_recoded\")) + \n  labs(x = \"Total Hours Smartphone Use\",\n       y = \"Total Well-Being Score\",\n       title = \"\") + \n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n:::\n\n\n## Activity 8: Check assumptions\n\nNow it's time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity. This is the idea that predictor variables should not be too highly correlated.\n\nAssumptions are:\n\n1. The outcome/DV is a interval/ratio level data, and the predictor variable is interval/ratio or categorical (with two levels).\n2. All values of the outcome variable are independent (i.e., each score should come from a different participant). \n3. The predictors have non-zero variance.\n4. The relationship between outcome and predictor is linear.\n5. The residuals should be normally distributed.\n6. There should be homoscedasticity (homogeneity of variance, but for the residuals).\n7. Multicollinearity: predictor variables should not be too highly correlated.\n\nWe can use the `plot()` function for diagnostic plots or the `check_model()` from the `performance` package. \n\nOne difference from when we used `check_model()` previously is that rather than just letting it run all the tests it wants, we are going to specify which tests to stop it throwing an error. \n\n::: {.callout-important}\n\nA word of warning - these assumption tests will take longer than usual to run because it's such a big data set.\n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_model(mod, \n            check = c(\"vif\", \n                      \"qq\", \n                      \"normality\", \n                      \"linearity\", \n                      \"homogeneity\"))\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n#### Assumptions 1-3 {.unnumbered}\n\nFrom the work we have done so far, we know that we meet assumptions 1-3.\n\n\n#### Assumption 4: Linearity {.unnumbered}\n\nWe already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\n\n#### Assumption 5: Normality of residuals {.unnumbered}\n\nThe residuals look good in both plots and this provides an excellent example of why it's often better to visualise than rely on statistics. With a sample size this large, any statistical diagnostic tests will be highly significant as they are sensitive to sample size.\n\n#### Assumption 6: Homoscedasticity {.unnumbered}\n\nThe plot is missing the reference line. Fun fact, this took us several days of our lives and asking for help on social media to figure out. The reason the line is not there is because the data set is so large that is creates a memory issue. However, if you use the `plot()` version, it does show the reference line.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(mod, which = 3)\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nIt is not perfect, but the reference line is roughly flat to suggest there are no serious issues with homoscedasticity. \n\n#### Assumption 7: Multicollinearity {.unnumbered}\n\nFrom the collinearity plot, we can see that both main effects and the interaction term are in the \"green zone\" which is great. Howeverm we can also test this statistically using `check_collinearity()` to produce VIF (variance inflation factor) and tolerance values.\n\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor is not actually adding any unique variance to the model, it's just really strongly related to other predictors. [You can read more about this online](https://statisticalhorizons.com/multicollinearity){target=\"_blank\"}. Thankfully, VIF is not affected by large samples like other statistical diagnostic tests.\n\nThere are various rules of thumb, but most converge on a **VIF of above 2 - 2.5** for any one predictor to be problematic. Here we are well under 2 for all 3 terms of the model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_collinearity(mod)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Term                                  |      VIF| VIF_CI_low| VIF_CI_high| SE_factor| Tolerance| Tolerance_CI_low| Tolerance_CI_high|\n|:-------------------------------------|--------:|----------:|-----------:|---------:|---------:|----------------:|-----------------:|\n|average_hours_centered                | 1.721968|   1.704219|    1.740165|  1.312238| 0.5807308|        0.5746582|         0.5867789|\n|gender_recoded                        | 1.035552|   1.028488|    1.044369|  1.017621| 0.9656682|        0.9575159|         0.9723014|\n|average_hours_centered:gender_recoded | 1.716349|   1.698683|    1.734463|  1.310095| 0.5826319|        0.5765474|         0.5886915|\n\n</div>\n:::\n:::\n\n\n## Activity 9: Sensitivity power analysis\n\nAs usual, we want to calculate the smallest effect size that our study was able to detect, given our design and sample size.\n\nTo do this, we use the `pwr.f2.test()` function from the `pwr` package. This is the same as in chapter 10 for simple linear regression. Remember the arguments for this function:\n\n\n* `u` = Numerator degrees of freedom. This the number of coefficients you have in your model (minus the intercept)\n* `v` = Denominator degrees of freedom. This is calculated as $v=n-u-1$, where $n$ is the number of participants.\n* `f2` = The effect size. Here we are solving the effect size, so this parameter is left out\n* `sig.level` = The significance level of your study. This is usually set to 0.05 \n* `power` = The power level of your study. This is usually set to 0.8, but let's go for 0.99 this time (just because we have such a large number of participants)\n\n\nRun the sensitivity power analysis and then answer the following questions:\n\n* To 3 decimal places, what is the smallest effect size that this study could reliably detect? <input class='webex-solveme nospaces' data-tol='0.01' size='0.000' data-answer='[\".000\"]'/>\n\nSince the observed effect size from our inferential statistics was <select class='webex-select'><option value='blank'></option><option value='x'>smaller</option><option value='answer'>larger</option></select> than the effect you could reliably detect with this design, the test was <select class='webex-select'><option value='blank'></option><option value='answer'>sufficiently powered</option><option value=''>underpowered</option></select> to detect the observed effect. \n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npwr.f2.test(u = 3, v = 71029, sig.level = 0.05, power = 0.99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n```\n:::\n:::\n\n\nThe study was incredibly sensitive, where they would detect effects of \n$f^2 = .0004$ with 99% power. Needless to say, this study was sufficiently powered.\n:::\n\n## Activity 10: The write-up\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted wellbeing $(F(3, 71029) = 2451, p < .001, R^2_{Adjusted} = .094, f^2 = .103)$, accounting for 9.4% of the variance. Total screen time was a significant negative predictor of wellbeing scores $(\\beta = -0.77, 95\\% CI = [-0.82, -0.73], p < .001$), as was gender $(\\beta = 5.14, p < .001$), with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screen time and gender $(\\beta = 0.45, 95\\% CI = [0.38, 0.52], p < .001$), meaning that smartphone use was more negatively associated with well-being for girls than for boys. \n\n\n## [Pair-coding]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n*to be added*\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n*to be added*\n\n",
    "supporting": [
      "11-multiple-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}