{
  "hash": "d31e62e7d5cb1b1ede3369a425f5403a",
  "result": {
    "markdown": "---\noutput: revealjs\n---\n\n\n# Chi-square and one-sample t-test  {#sec-nhstI}\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n-   compute a Cross-tabulation Chi-square test and report the results\n-   compute a one-sample t-test and report the results\n-   understand when to use a non-parametric equivalent for the one-sample t-test, compute it, and report the results\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n## Overview\n\nWhich test to use depends on what type of variable(s) you have and what your research question is about.\n\n\n* Cross-tabulation chi-Square test (this chapter, @sec-chi_square)\n* One-sample t-test (this chapter, @sec-onesample)\n* Two-sample or independent t-test (between-subjects design, @sec-independent) \n* Paired t-test (within-subjects design, @sec-within)\n* Correlation (@sec-cor)\n* Simple regression (@sec-reg)\n* Multiple regression (@sec-reg_mult)\n* One-way ANOVA (@sec-oneway)\n* Factorial ANOVA (@sec-factorial)\n\n\nMaybe in a flow chart\n\n\n![Simplified flowchart to help select the most appropriate test (created with [drawio](https://draw.io/){target=\"_blank\"}). [View larger version](images/Flowchart_tests_drawio.png){target=\"_blank\"}](images/Flowchart_tests_drawio.png)\n\n\n\n## Activity 1: Setup & download the data\n\n* create a new project and name it something meaningful (e.g., \"2A_chapter6\", or \"06_chi_square_one_sample_t\"). See @sec-project if you need some guidance.\n* create a new Rmd file and save it to your project folder. See @sec-rmd if you get stuck. \n* delete everything after the setup code chunk (e.g., line 12 and below)\n* download a reduced dataset here: [data_ch6.zip](data/data_ch6.zip \"download\"). You'll see one csv file with demographic information and questionnaire data as well as the codebook.\n* Extract the data files from the zip folder and place them in your project folder. If you need help, see @sec-download_data_ch1.\n\n\n**Citation**\n\n> Ballou, N., Vuorre, M., Hakman, T., Magnusson, K., & Przybylski, A. K. (2024, July 12). Perceived value of video games, but not hours played, predicts mental well-being in adult Nintendo players. [https://doi.org/10.31234/osf.io/3srcw](https://doi.org/10.31234/osf.io/3srcw){target=\"_blank\"}\n\n\nAs you can see, the study is a pre-print published on PsyArXiv Preprints. The data and supplementary materials are available on OSF: [https://osf.io/6xkdg/](https://osf.io/6xkdg/){target=\"_blank\"}\n\n\n**Abstract**\n\n> Studies on video games and well-being often rely on self-report measures or data from a single game. Here, we study how 703 US adults’ time spent playing for over 140,000 hours across 150 Nintendo Switch games relates to their life satisfaction, affect, depressive symptoms, and general mental well-being. We replicate previous findings that playtime over the past two weeks does not predict well-being, and extend these findings to a wider range of timescales (one hour to one year). Results suggest that relationships, if present, dissipate within two hours of gameplay. Our non-causal findings suggest substantial confounding would be needed to shift a meaningful true effect to the observed null. Although playtime was not related to well-being, players’ assessments of the value of game time—so called gaming life fit—was. Results emphasise the importance of defining the gaming population of interest, collecting data from more than one game, and focusing on how players integrate gaming into their lives rather than the amount of time spent.\n\n\n\n\n\n\n**Changes made to the dataset**\n\n* We selected demographic variables, such as age, gender, ethnicity, employment, education level, and the Warwick-Edinburgh Mental Wellbeing Scale from the rich dataset.\n* We removed rows with missing values and categorical groupings for which observed frequencies were considered too small for the purpose of this chapter.\n* We won't be looking into any game-related associations, but feel free to download the full dataset to explore further.\n* The original authors had quite strict inclusion criteria for their analysis. We did not, hence we ended up with more participants than the original study\n\n\n## Activity 2: Load in the library, read in the data, and familiarise yourself with the data\n\nToday, we'll need the following packages `tidyverse`, `lsr`, `scales`, `qqplotr`, `car`, `pwr`, and `rcompanion` as well as the data `data_ballou_reduced`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load in the packages\n???\n\n# read in the data\ndata_ballou <- ???\n```\n:::\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load in the packages\nlibrary(tidyverse)\nlibrary(lsr)\nlibrary(scales)\nlibrary(qqplotr)\nlibrary(car)\nlibrary(pwr)\nlibrary(rcompanion)\n\n# read in the data\ndata_ballou <- read_csv(\"data_ballou_reduced.csv\")\n```\n:::\n\n\n:::\n\n\n\n\n## Activity 3: Data wrangling\n\nThe categorical variables look quite tidy, but we need to **convert gender and education level into factors**. Our statistical test requires factors and categories might be sorted more easily when plotting.\n\nWe also have to **calculate the overall score for the Warwick-Edinburgh Mental Wellbeing Scale**. According to the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"}, the scores of the individual items are summed up.\n\n* create a new data object `data_wemwbs` to calculate the summed up scores for the wemwbs.\n* convert gender and education level into factors in the original `data_ballou` object. Feel free to sort them in a meaningful order. \n* join this `data_ballou` with `data_wembs`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"} \n\n## Hints\n\n* We converted categorical variables into factors in @sec-dataviz if you need a refresher \n* Check the `QRPs` questionnaire in @sec-wrangling to see how we approached aggregating scores \n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_wemwbs <- data_ballou %>% \n  pivot_longer(cols = wemwbs_1:wemwbs_14, names_to = \"Questions\", values_to = \"Scores\") %>% \n  group_by(pid) %>% \n  summarise(wemwbs_sum = sum(Scores))\n\ndata_ballou <- data_ballou %>% \n  mutate(gender = factor(gender,\n                         levels = c(\"Woman\", \"Man\", \"Non-binary\")),\n         eduLevel = factor(eduLevel,\n                           levels = c(\"Completed Secondary School\", \"Some University but no degree\", \"University Bachelors Degree\", \"Vocational or Similar\", \"Graduate or professional degree (MA, MS, MBA, PhD, etc)\"))) %>% \n  left_join(data_wemwbs)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(pid)`\n```\n:::\n:::\n\n\n:::\n\n:::\n\n\n## Activity 4: Cross-tabulation Chi-square test {#sec-chi_square}\n\nA Cross-Tabulation Chi-Square Test, also known as a Chi-square test of association/independence, tests how one variable is associated with the distribution of outcomes in another variable.\n\n\nWe will be performing a Chi-Square test using the categorical variables **gender** and **eduLevel**:\n\n* Potential research question: \"Is there an association between gender and level of education in the population?\"\n* Null Hypothesis (H~0~): \"Gender and student status are independent; there is no association between gender and level of education.\"\n* Alternative Hypothesis (H~1~): \"Gender and student status are not independent; there is an association between gender and level of education.\"\n\n\n\n### Task 1: Preparing the dataframe\n\nWe need to select your variables of interest. We don't have missing values in this dataset, but if your future dataframe might contain some, use `drop_na()` before you turn categorical variables into factors.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchi_square <- data_ballou %>% \n  select(pid, gender, eduLevel)\n```\n:::\n\n\n\n### Task 2: Compute descriptives\n\nWe need to calculate counts for each combination of the variables. This is best done in a frequency table. This also allows us to check that we don't have missing values in the cells. The function we are using does not work with missing values.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchi_square_frequency <- chi_square %>% \n  count(gender, eduLevel) %>% \n  pivot_wider(names_from = eduLevel, values_from = n)\n\n\nchi_square_frequency\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gender     | Completed Secondary School| Some University but no degree| University Bachelors Degree| Vocational or Similar| Graduate or professional degree (MA, MS, MBA, PhD, etc)|\n|:----------|--------------------------:|-----------------------------:|---------------------------:|---------------------:|-------------------------------------------------------:|\n|Woman      |                         63|                           118|                         169|                    42|                                                      65|\n|Man        |                         70|                           125|                         250|                    34|                                                      81|\n|Non-binary |                          9|                            23|                          20|                     4|                                                      10|\n\n</div>\n:::\n:::\n\n\nWe should be ok here, even though the count for non-binary/vocational is quite low.\n\n\n### Task 3: Check assumptions\n\n\n#### Assumption 1: categorical data {.unnumbered}\n\nThe two variables should be categorical data measured either at an ordinal or nominal level.\n\nWe can confirm that for our dataset. Gender is <select class='webex-select'><option value='blank'></option><option value='x'>ordinal</option><option value='answer'>nominal</option></select>, and level of education is <select class='webex-select'><option value='blank'></option><option value='answer'>ordinal</option><option value='x'>nominal</option></select>.\n\n\n#### Assumption 2: Independent observartions {.unnumbered}\n\nThe value of one observation in the dataset does not affect the value of any other observation. \n\nAnd we assume as much for our data.\n\n\n#### Assumption 3: Cells in the contingency table are mutually exclusive {.unnumbered}\n\nIndividuals can only belong to one cell in the contingency table. \n\nWe can confirm that by looking at the data and the contingency table.\n\n\n#### Assumption 4: Expected frequencies are sufficiently large {.unnumbered}\n\nNot an assumption that is listed consistently across various sources. When it is, it suggests that expected frequencies are larger than 5 or at least 80% of the the expected frequencies are above 5 and none of them are below 1. However, Danielle Navarro points out that this seems to be a \"somewhat conservative\" criterion and should be taken as \"rough guidelines\" only (see [https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions](https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions){target=\"_blank\"}.\n\nThis is information, we can either compute manually (see lecture slides) or wait till we get the output from the inferential statistics later.\n\n\n### Task 4: Create an appropriate plot\n\nNow we can create the appropriate plot. Which plot would you choose when building one from object `chi_square`? A <select class='webex-select'><option value='blank'></option><option value='answer'>Barchart</option><option value='x'>Histogram</option><option value='x'>Scatterplot</option><option value='x'>Violin-Boxplot</option></select> with geom layer <select class='webex-select'><option value='blank'></option><option value='x'>geom_col</option><option value='answer'>geom_bar</option><option value='x'>geom_histogram</option><option value='x'>geom_point</option><option value='x'>geom_boxplot and geom_violin</option></select>\n\nTry first before looking at the solution. Feel free to practice adding other layers to make the plot pretty.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## One possible solution\n\n... is a grouped bar chart.\n\nI played about with the labels of the x-axis categories since the graduate label is super long. Google was my friend in this instance and showed me a nifty function called `label_wrap()` from the `scales` package which automatically adds line breaks after X characters. Here we chose 12; looked best. (See other options for long labels at [https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/](https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/){target=\"_blank\"}).\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(chi_square, aes(x = eduLevel, fill = gender)) +\n  geom_bar(position = \"dodge\") + \n  scale_fill_viridis_d(name = \"Gender\") +\n  scale_x_discrete(name = \"Level of Education\",\n                   labels = label_wrap(12)) +\n  scale_y_continuous(name = \"Count\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n\n\n\n### Task 5: Compute a chi-square test\n\n\nBefore we can do that, we need to turn our tibble into a dataframe - the `associationTest()` function we are using to compute the Chi-square test does not like tibbles. [*you have nooooo clue how long that took to figure out - let's say the error message was not entirely useful*]\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchi_square_df <- as.data.frame(chi_square)\n```\n:::\n\n\n\nNow we can run the `associationTest()` function from the `lsr` package. The first argument is a formula. It starts with a `~` and then expects the 2 variables we want to associate connected with a `+`. The second argument is the dataframe.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nassociationTest(formula = ~ eduLevel + gender, data = chi_square_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in associationTest(formula = ~eduLevel + gender, data = chi_square_df):\nExpected frequencies too small: chi-squared approximation may be incorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Chi-square test of categorical association\n\nVariables:   eduLevel, gender \n\nHypotheses: \n   null:        variables are independent of one another\n   alternative: some contingency exists between variables\n\nObserved contingency table:\n                                                         gender\neduLevel                                                  Woman Man Non-binary\n  Completed Secondary School                                 63  70          9\n  Some University but no degree                             118 125         23\n  University Bachelors Degree                               169 250         20\n  Vocational or Similar                                      42  34          4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)    65  81         10\n\nExpected contingency table under the null hypothesis:\n                                                         gender\neduLevel                                                  Woman   Man\n  Completed Secondary School                               59.9  73.4\n  Some University but no degree                           112.2 137.5\n  University Bachelors Degree                             185.2 227.0\n  Vocational or Similar                                    33.8  41.4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)  65.8  80.7\n                                                         gender\neduLevel                                                  Non-binary\n  Completed Secondary School                                    8.65\n  Some University but no degree                                16.21\n  University Bachelors Degree                                  26.75\n  Vocational or Similar                                         4.88\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)       9.51\n\nTest results: \n   X-squared statistic:  13.594 \n   degrees of freedom:  8 \n   p-value:  0.093 \n\nOther information: \n   estimated effect size (Cramer's v):  0.079 \n   warning: expected frequencies too small, results may be inaccurate\n```\n:::\n:::\n\n\n\nThe output is quite informative. It gives information about:\n\n* the variables that were tested, \n* the null and alternative hypotheses, \n* a table with the observed frequencies (which matches what we calculated in `chi_square_assumptions` without the rows/columns of the missing values we removed), \n* an output of the frequencies you'd expect if the null hypothesis were true, \n* the result of the hypothesis test, and \n* the effect size Cramer's v.\n\nAnd it gives us a **warning message** saying that expected frequencies are too small and that the chi-squared approximation may be incorrect. This ties in with Assumption 4. Depending on your stance on Assumption 4, you may or may not want to ignore the warning.\n\nThe p-value tells us that the null hypothesis is not being rejected, since the p-value is larger than 0.05. \n\n### Task 6: The write-up\n\nThe Chi-Square test revealed that there is no statistically significant association between Gender and Student Status, $\\chi^2(8) = 13.59, p = .093, V = .079$. The strength of the association between the variables is considered small. We therefore fail to reject the null hypothesis. \n\n\n\n\n\n## Activity 5: One-sample t-test {#sec-onesample}\n\nThe one-sample t-test is used to determine whether a sample comes from a population with a specific mean. This population mean is not always known, but is sometimes hypothesized. \n\nWe will be performing a one-sample t-test using the continuous variable **wemwbs_sum**. The [official website for the Warwick-Edinburgh Mental Wellbeing Scales](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"} states that the \"WEMWBS has a mean score of 51.0 in general population samples in the UK with a standard deviation of 7 (Tennant et al., 2007)\".\n\n* Potential research question: \"Is the average mental well-being of gamers different from the general population's average well-being?\"\n* Null Hypothesis (H~0~): \"The summed-up WEMWBS score of gamers is not different to 51.0.\"\n* Alternative Hypothesis (H~1~): \"The summed-up WEMWBS score of gamers is different from 51.0.\"\n\n\n### Task 1: Preparing the dataframe\n\nWe need to select your variables of interest.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\none_sample <- data_ballou %>% \n  select(pid, wemwbs_sum)\n```\n:::\n\n\n\n### Task 2: Compute descriptives\n\nWe want to compute means and standard deviations for our variable of interest. This should be straight forward. Try it yourself and then compare your result with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescriptives <- one_sample %>% \n  summarise(mean_wemwbs = mean(wemwbs_sum),\n            sd = sd(wemwbs_sum))\n\ndescriptives\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| mean_wemwbs|       sd|\n|-----------:|--------:|\n|    45.42013| 10.88615|\n\n</div>\n:::\n:::\n\n\n:::\n\n\n### Task 3: Create an appropriate plot\n\nThis is the one you want to include in your report, so make sure everything is clearly labelled. Which plot would you choose? Start creating one first before comparing with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = \"\", y = wemwbs_sum)) +\n  geom_violin(fill = \"#FB8D61\", alpha = 0.4) + # alpha for opacity, fill for adding colour\n  geom_boxplot(fill = \"#FB8D61\", width = 0.5) + # change width of the boxes\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Total WEMWBS Scores\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n\n\n### Task 4: Check assumptions\n\n\n#### Assumption 1: Continuous DV {.unnumbered}\n\nThe dependent variable needs to be measured at interval or ratio level. We can confirm that by looking at `one_sample`. \n\n\n\n#### Assumption 2: Data are independent {.unnumbered}\n\nThere is no relationship between the observations. Whilst this is an important assumption, it's not one we can really test for. It has more to do with study design. Anyway, we assume this assumption holds for our data.\n\n\n#### Assumption 3: No significant outliers {.unnumbered}\n\nWe can check for that visually, for example in the violin-boxplot above. \n\nIt appears that there is one outlier on the lower tail, however, when inspecting the data in `one_sample`, we can see that it's one person who got a score of 14 which is a possible value. Furthermore, when sample sizes are sufficiently large, like ours with 1083 participants, removing a single outlier makes not much sense. So we have checked this assumption, consider this outlier not significant, and therefore keep this observation in the dataset.\n\n::: {.callout-important} \n\nIf you are taking any of the outliers out, you need to recalculated the descriptive stats.\n\n:::\n\n#### Assumption 4: DV should be approximately normally distributed {.unnumbered}\n\nWe can already check normality from the violin-boxplot above but you could plot a histogram, a density plot, or a qqplot as an alternative to assess normality visually.\n\nAll of these options show that **the data is normally distributed**. That means, we will conduct a parametric test, i.e. a one-sample t-test.\n\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Alternatives to visually assess normality\n\n::: {.panel-tabset}\n\n## Histogram\n\nWe've already covered histograms in @sec-dataviz2. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_histogram(binwidth = 1, fill = \"magenta\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Density plot\n\nA density plot shows a smooth distribution curve of the data. The curve represents the proportion of the data in each range rather than the frequency. This means that the height of the curve doesn’t show how many times a value appears but rather the proportion of the data that falls into that range.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_density(fill = \"magenta\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Q-Q plot\n\nQ-Q plot stands for Quantile-Quantile Plot and compare two distributions by matching a common set of quantiles. It basically means that it's comparing the distribution you have in your data with a normal distribution and plots this along a 45 degree line. \n\n**If the dots in the Q-Q plot fall roughly along that line, you can assume normality of the data. If they stray away from the line (and worse in some sort of pattern), we might not assume normality and conduct a non-parametric test instead. For the non-parametric equivalent, see @sec-alternative_one_sample.**\n\nWe can either use the package `car` or `qqplotr` to build the qqplot. \n\n* The function `qqPlot()` is a single line but uses BaseR coding (i.e., the `$` symbol) to access the column in the data object.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Version 1 with the car package\nqqPlot(one_sample$wemwbs_sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 295 394\n```\n:::\n\n::: {.cell-output-display}\n![Q-Q plot created with the car package](06-chi-square-one-sample_files/figure-html/fig-qqplot1-1.png){#fig-qqplot1 fig-align='center' width=100%}\n:::\n:::\n\n\n* If you have gotten used to ggplot by now, and prefer avoiding BaseR, you can use the package `qqplotr`. The downside is that you have to add the points, the line, and the confidence envelope yourself. On the plus, it has layers like ggplot, and is more customisable (just in case you wanted to look at something more colourful in the 2 seconds it'll take you to assess normality).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Version 2 with package qqplotr\nggplot(one_sample, aes(sample = wemwbs_sum)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n```\n\n::: {.cell-output-display}\n![Q-Q plot created with the qqplotr package](06-chi-square-one-sample_files/figure-html/fig-qqplot2-1.png){#fig-qqplot2 fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n:::\n\n\nYou can also assess normality with the **Shapiro-Wilk’s test**. The null hypothesis is that the population is distributed normally. Therefore, if the p-value of the Shapiro-Wilk’s test smaller than .05, normality is rejected. \n\n::: {.callout-important}\n\nShapiro-Wilk is a good method for small sample sizes (e.g., smaller than 50 samples). If you have large sample sizes, Shapiro-Wilk will definitely produce a significant p-value regardless of what the distribution looks like. So don't rely on its output when you have large sample sizes.\n:::\n\nThe function in R is `shapiro.test()` and it's built into BaseR, meaning, we need our data object, the `$` and the column we want to address.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshapiro.test(one_sample$wemwbs_sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  one_sample$wemwbs_sum\nW = 0.99404, p-value = 0.0002619\n```\n:::\n:::\n\nNo surprise here, the test shows p < .001 because we have more than 1000 participants. Nevertheless, if you had a smaller sample and you needed to write this result up in your report, you would report it in APA style: $W = .99, p < .001$.\n\n\n::: {.callout-tip}\n\n## Report-writing Tip\n\nEither choose visual or computational inspection for normality tests. NO NEED TO DO BOTH!!!\n\n* State what method you used and your reasons for choosing the method (visual/computational and what plot/test you used)\n* State the outcome of the test - for visual inspection just say whether normality assumption held or not (no need to include that extra plot in the results section). For computational methods, report the test result in APA style\n* State the conclusions you draw from it - parametric or non-parametric test\n\n:::\n\n\n\n\n\n### Task 5: Compute a One-sample t-test and effect size\n\n\nWe can use the `t.test()` function to compute a one-sample t-test. The `t.test()` function is part of BaseR, and yes, you guessed it, our first argument has to follow the pattern `data$column`. The second argument (`mu`) lists the population mean we are testing our sample against (here 51.0). The test is \"two.sided\" by default, so you can leave the argument out.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(one_sample$wemwbs_sum, mu = 51.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  one_sample$wemwbs_sum\nt = -16.868, df = 1082, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 51\n95 percent confidence interval:\n 44.77106 46.06920\nsample estimates:\nmean of x \n 45.42013 \n```\n:::\n:::\n\nThe output is quite informative. It gives us information about:\n\n* the variable column that was tested, \n* the t value, degrees of freedom, and p,\n* the alternative hypothesis, \n* a 95% confidence interval,\n* and the mean of the column (which matches the one we computed in the descriptive - yay)\n\nWhat it doesn't give us is an **effect size**. Meh. So we have to compute one ourselves.\n\nWe will calculate **Cohen's d** using the function `cohensD()` from the `lsr` package. Similar to the t-test we just conducted, the first argument is `data$column`, the second argument is `mu`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncohensD(one_sample$wemwbs_sum, mu = 51.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5125662\n```\n:::\n:::\n\n\n\n### Task 6: Sensitivity power analysis\n\nA **sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect** given the number of participants you have in the sample, the alpha level at 0.05, and an assumed power of 0.8. \n\nThe function we need to compute this is `pwr.t.test()` which is part of the `pwr` package. There are 4 factors - the APES (alpha, power, effect size, and sample size) - if you have 3, you can calculate the 4th. As stated above, we have 3. We also need to specify the `type`, i.e., that we are using it for a one-sample t-test, and that `alternative` is \"two.sided\" because we have a non-directional hypothesis.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npwr.t.test(n = 1083, sig.level = 0.05, power = 0.8, type = \"one.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 1083\n              d = 0.08520677\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n:::\n:::\n\n\nSo the smallest effect size we can detect with a sample size of 1083, an alpha level of 0.05, and power of 0.8 is 0.09. This is a smaller value than the actual effect size we calculated with our CohensD function above (i.e., 0.51) which means our analysis is sufficiently powered.\n\n\n### Task 7: The write-up\n\nA one-sample t-test was computed to determine whether the average mental well-being of gamers as measured by the WEMWBS was different to the population well-being mean. The average WEMWBS of the gamers $(N = 1083, M = 45.42, SD = 10.89)$ was significantly lower than the population mean well-being score of 51.0, $t(1082) = 16.87, p < .001, d = .51$. The strength of the effect is considered medium and the study was sufficiently powered. We therefore reject the null hypothesis in favour of H~1~. \n\n\n\n\n## Activity 6: Non-parametric alternative {#sec-alternative_one_sample}\n\nIf any of the assumptions are violated, you need to switch to the non-parametric alternative. For the one-sample t-test, this is a **One-sample Wilcoxon signed-rank test**. Instead of the mean, it compares the median of a sample against a single value (i.e., the population median).\n\nThat means we need to find the population median, and calculate some summary stats for our sample:\n\n* The population median is listed in a supporting document on the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"} as 53.0. \n* We can easily calculate the summary statistics using the function summary.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(one_sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     pid              wemwbs_sum   \n Length:1083        Min.   :14.00  \n Class :character   1st Qu.:38.00  \n Mode  :character   Median :46.00  \n                    Mean   :45.42  \n                    3rd Qu.:53.00  \n                    Max.   :70.00  \n```\n:::\n:::\n\n\n\nThe function to compute a one-sample Wilcoxon test test is `wilcox.test()`. It's part of BaseR and code-wise, it works very similar to the one-sample t-test.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox.test(one_sample$wemwbs_sum, mu = 53.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  one_sample$wemwbs_sum\nV = 87218, p-value < 2.2e-16\nalternative hypothesis: true location is not equal to 53\n```\n:::\n:::\n\nAs we can see, the output gives us a V value, but we need to report a Z value in the final write-up. Unfortunately, we have to calculate Z manually. According to Andy Field (2012, p. 665), we need to use the qnorm function on the halved p-value from our Wilcoxon test above.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# storing the p-value\np_wilcoxon <- wilcox.test(one_sample$wemwbs_sum, mu = 53.0)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -19.12264\n```\n:::\n:::\n\n\n\nWe also need to calculate the effect size `r`, which we can do via the `wilcoxonOneSampleR` from the `rcompanion` package. The default value will be 3 decimal places, but you can change that with the `digits` argument.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    r \n-0.59 \n```\n:::\n:::\n\n\nNow we have all the numbers we need to write up the results: \n\nA One-sample Wilcoxon signed-rank test was used to compare Gamers’ mental-wellbeing scores (Mdn = 46.0) to the population median of 53.0. The test showed a significant difference, $Z = -19.12, p < .001, r = .590$. The strength of the effect is considered medium. We therefore reject the null hypothesis in favour of H~1~. \n\n\n## [Pair-coding in the lab]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n\n\n## [Test your knowledge on Chapters 3 and 4]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n",
    "supporting": [
      "06-chi-square-one-sample_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}