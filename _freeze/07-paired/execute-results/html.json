{
  "hash": "de877f44e682263b55f13310ac34af7b",
  "result": {
    "markdown": "# NHST III: Paired t-test {#sec-within}\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n-   a\n-   b\n-   c\n\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n## Activity 1: Setup\n\nWe will still be working with the Zwaan dataset in this chapter. Have a look at @sec-independent or the SupMats document if you need a refresher about the Simon Task data.\n\n* Open last week's project\n* create a new Rmd file and save it to your project folder\n* delete everything after the setup code chunk \n\n\n\n## Activity 2: Library and data for today\n\nToday, we'll need the following packages `tidyverse`, *ETC*. Again, we also need to read in the data from `MeansSimonTask.csv` and the demographics information from `DemoSimonTask.csv`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load in the packages\n???\n\n# read in the data\nzwaan_data <- ???\nzwaan_demo <- ???\n```\n:::\n\n\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load in the packages\nlibrary(tidyverse)\n\n# read in the data\nzwaan_data <- read_csv(\"MeansSimonTask.csv\")\nzwaan_demo <- read_csv(\"DemoSimonTask.csv\")\n```\n:::\n\n\n:::\n\n\nAs usual, familiarise yourself with the data before starting on the between-subjects t-test.\n\n\n## Activity 3: Preparing the dataframe\n\njoin the files together\n\n## Activity 4: Compute descriptives\n\ncompute means and sd\n\n## Activity 5: Create an appropriate plot\n\nmake a plot\n\n\n## Activity 6: Check assumptions\n\ntest assumptions and say what it means for your test\n\n\nAssumes interval/ratio data\n continuous measurement scale\n Assumes scores are independent from each other\n one score should not have any relationship to another (e.g. each pair of values is from a separate participant)\n Assumes difference scores are approximately normally distributed\n\n\n\n**If any of the assumptions are violated, use the non-parametric equivalent to the between-subjects t-test, see @sec-alternative_two_sample.**\n\n## Activity 7: Compute a Two-sample t-test and effect size\nt-test with effect size\n\n\n## Activity 7: Compute a Two-sample t-test and effect size\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(rstatix)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'rstatix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n:::\n\n\nThe `t.test()` function we used for the one-sample t-test can be used here, however, it has been a bit buggy recently not taking in certain arguments (more so for the paired sample t-test we talk about in the next chapter). Therefore, we are switching over to the `t_test()` function from the `rstatix` package.\n\nThe output is organised slightly different to what we've seen in the `t.test()` function, and whilst it looks neater, it does provide less information at first glimpse.\n\nThe **Welch t-test is the default option** because the `var.equal`argument is set to `FALSE`. You won't be able to see it in the table output unless you know what you are looking for. Hence we would suggest adding all the default arguments into the function to be able to trace what you are doing.\n\n* The first argument is the data\n* The second argument in the formula with the pattern `DV ~ IV`\n* Next we want to specify `paired = FALSE` as we don't want a paired t-test (`paired = FALSE` is the default)\n* Then, we want to specify `var.equal = FALSE` for a Welch t-test (`var.equal = FALSE` is the default)\n* The alternative is \"two.sided\" by default\n* You can set the argument `detailed` to `TRUE` to get some more information (default is `detailed = FALSE`).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt_test(data = simon_effect, \n       formula = simon_effect ~ similarity, # DV ~ IV\n       paired = FALSE, # for an independent t-test (default)\n       var.equal = FALSE, # for a Welch t-test (default)\n       alternative = \"two.sided\", # default - the alternative hypothesis is non-directional\n       detailed = FALSE) # set this to true for more detail (FALSE is default)\n```\n:::\n\n\nSo, what can we see in the output:\n\n* The output gives you the `.y.` which is the DV and `group1` and `group2` will list the 2 levels of the IV that the test compared (in our case \"different\" and \"same\").\n* It also lists `n1` and `n2`, which are the sample sizes for groups 1 and 2 respectively\n* statistic is the t-value\n* df is the degrees of freedom, and\n* p is the p-value\n\nIf you set the `detailed` argument to `TRUE`, you get slightly more information. Let's have a look\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt_test(data = simon_effect, \n       formula = simon_effect ~ similarity, # DV ~ IV\n       paired = FALSE, # for an independent t-test (default)\n       var.equal = FALSE, # for a Welch t-test (default)\n       alternative = \"two.sided\", # default - the alternative hypothesis is tested in both directions\n       detailed = TRUE) # set this to true for more detail (FALSE is default)\n```\n:::\n\n\n<p></p>\nAdditional information that is useful:\n\n* estimate which is the difference score between the groups (here 3.14 msec = 35.99-32.86)\n* estimate1 which is the average value from group 1 (here 32.86 ms - and it matches with the value we calculated in the descriptives for the \"different\" group)\n* estimate2 which is the average value from group 2 (here 35.99 ms - and it matches with the value we calculated in the descriptives for the \"same\" group)\n* lower and higher confidence intervals might also be useful, and\n* the alternative is listed as \"two.sided\"\n\n\nNow on to the information that is a bit of a let-down: **The method is listed as T-test**. This will always be the output whether use the formula for a one-sample t-test, independent t-test, or a paired t-test. Therefore it's really not great. This is the reason why we tell you to put all the arguments in, even the default ones. If you don't you may have a tough time identifying what you just did.\n\n::: {.callout-tip}\n\nYou can see what test you conducted by looking at the df in the table. \n\n* If the df is $n1 + n2 - 2$ it's a Student t-test and equal variance are assumed (i.e., `var.equal = TRUE`). \n* If the df is approximately $n1 + n2 -2$ but some weird number with decimal places, you know `var.equal` was set to `FALSE` and it is actually a Welch t-test.\n* If the df is $n1 - 1$ or $n2 - 1$ it's a paired t-test (even though it would be more useful to only have one n displayed in that case - but ah well)\n\n:::\n\nThis `t_test()` function does not give us an **effect size** either, so we have to compute it once again. We can use the `CohensD()` function from the `lsr` package as we did for the one-sample t-test. We can use the formula approach here as well.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncohensD(simon_effect ~ similarity, data = simon_effect)\n```\n:::\n\n\n\n\n## Activity 8: Sensitivity power analysis\n\npower calculations\n\n\n## Activity 9: The write-up\n\n\n\n\n## Activity 10: Non-parametric alternative {#sec-alternative_two_sample}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox.test(x ~ group, data = xxx, paired = TRUE)\n```\n:::\n\n\nhttps://tuos-bio-data-skills.github.io/intro-stats-book/non-parametric-tests.html\nWilcoxon signed-rank test: This test is equivalent to a one-sample and paired-sample t-test. This test can be used to:\n\ncompare a sample to a single value, or\ntest for differences between paired samples.\n",
    "supporting": [
      "07-paired_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}