{
  "hash": "09ea5810abaaf22dbd70a25ce85eb9fe",
  "result": {
    "markdown": "# Data viz {#sec-dataviz}\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n-   a\n-   b\n-   Be able to create an appropriate for your data\n\n\n## [Individual Walkthrough]{style=\"color: #EBA347; text-transform: uppercase;\"} {.unnumbered}\n\n\n\n## Building pots\n\nWe are using the package `ggplot2` to create data visualisations. It's part of the tidyverse package. Actually, most people call th package `ggplot` but it's official name is `ggplot2`. \n\n::: {.grid}\n\n::: {.g-col-5}\n\n**ggplot2** uses a layered grammar of graphics, in which plots are built up in a series of layers. You would start with a base layer (opening ggplot), adding **data** and **aesthetics**, and selecting the **geometries** for plot. \n\nThese first 3 layers will give you the most simple version of a complete plot, but you could add other layers to make the plots pretty by using **scales**, **facets**, **coordinates**, **labels** and **themes**. \n\n:::\n\n::: {.g-col-7}\n\n![gg layers [(Presentation by Ryan Safner)](https://metricsf20.classes.ryansafner.com/slides/1.3-slides#20){target=\"_blank\"}](images/gglayers.png){width=70%}\n\n:::\n\n:::\n\n\nTo give you a brief overview of the layering system, let's use the package `palmerpenguins` ([https://allisonhorst.github.io/palmerpenguins/](https://allisonhorst.github.io/palmerpenguins/){target=\"_blank\"}). It contains data about bill length and depth, flipper length, and body mass, etc.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(penguins)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|species |island    | bill_length_mm| bill_depth_mm| flipper_length_mm| body_mass_g|sex    | year|\n|:-------|:---------|--------------:|-------------:|-----------------:|-----------:|:------|----:|\n|Adelie  |Torgersen |           39.1|          18.7|               181|        3750|male   | 2007|\n|Adelie  |Torgersen |           39.5|          17.4|               186|        3800|female | 2007|\n|Adelie  |Torgersen |           40.3|          18.0|               195|        3250|female | 2007|\n|Adelie  |Torgersen |             NA|            NA|                NA|          NA|NA     | 2007|\n|Adelie  |Torgersen |           36.7|          19.3|               193|        3450|female | 2007|\n|Adelie  |Torgersen |           39.3|          20.6|               190|        3650|male   | 2007|\n\n</div>\n:::\n:::\n\n\n\n\nLet's build a basic scatterplot to show the relationship between flipper_length and body_mass. We will customise plots further later on in the individual plots. This is just a quick overview of the different layers.\n\n* Layer 1 creates a plot base to built up upon. \n* Layer 2 adds the `data` and some `aesthetics`\n  * data is first argument\n  * aesthetics are added via the mapping argument. There you define your variables to be added (such as x, or x and y) and allows you specify overall properties like the colour of grouping variables etc.\n* Layer 3 adds the geometries or `geom_?` for short. This tells ggplot in which style we want to plot the data points. Remember to add these layers with a `+` rather than a pipe `%>%`. You can add multiple geoms if you wish, e.g., building a violin-boxplot\n* Layer 4 adds the `scale_?` functions which can help you customise the aesthetics, such as changing colour. You can do much more with scales, but we'll get to that later.\n* Layer 5 introduces `facets`, such as `facet_wrap()` which allows you to add another dimension to the data output by showing the relationship you are interested in for each level of a categorical variable.\n* Layer 6 - coordinates: `coord_cartesian()` controls the limits for the x- and y-axes (arguments `xlim` and `ylim`). Changing those allows you to zoom in or out of your plot.\n* Layer 7 helps you to modify axes labels.\n* Layer 8 controls the general style of a ggplot (e.g., background colour, size of text, borders, etc.). R comes with a few pre-defined ones (like `theme_classic`, `theme_bw`, `theme_minimal`, `theme_light`).\n\n::: {.panel-tabset group=\"layers\"}\n\n## Layer 1\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot()\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=100%}\n:::\n:::\n\nWe don't see much here. It's basically an empty plot layer.\n\n## Layer 2\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm))\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nYou won't see any data points yet, because we haven't specified how we want to display the data points. But we mapped in the aesthetics, that we want to plot variable body mass on the x-axis and flipper length on the y-axis. This also adds the axes titles and the values and break points of the axes.\n\n\n::: {.callout-tip}\nYou won't need to add `data = ` or `mapping = ` if you keep those arguments in exactly that order. Likewise, the first column name you enter within the `aes()` function will always be interpreted as x, and the second as y, so you could omit them if you wish.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(penguins, aes(body_mass_g, flipper_length_mm))\n```\n:::\n\n\nwill give you the same output as the code above.\n\n:::\n\n## Layer 3\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nHere we are telling ggplot that we want a scatterplot added. There is a warning displayed \n\nThe argument `colour` adds colour to the points according to a grouping variable (in this case sex). If you want all of the points to be black (i.e. only represent 2 rather than 3 dimensions of the data), leave the `colour` argument out. \n\n## Layer 4\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  # changes colour palette\n  scale_colour_brewer(palette = \"Dark2\") + \n  # add breaks from 2500 to 6500 in increasing steps of 500\n  scale_x_continuous(breaks = seq(from = 2500, to = 6500, by = 500)) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\nThe `scale_?` functions allow us to change the colour palette of the plot or the axes breaks etc. You could change the name of the axis in `scale_x_continuous()` as well or leave it for Layer 7.\n\n\n\n## Layer 5\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  # split main plot up into different subplots by species \n  facet_wrap(~ species) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\nHere we are faceting this plot out for the individual species.\n\n\n## Layer 6\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  facet_wrap(~ species) +\n  # limits the range of the y axis\n  coord_cartesian(ylim = c(0, 250)) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nChanging the limits of the y axis to zoom in or out of the plot. If you wanted to the same for the x axis, you would add an argument `xlim` to the `coord_cartesian()` function.\n\n\n## Layer 7\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  facet_wrap(~ species) +\n  labs(x = \"Body Mass (in g)\", # labels the x axis\n       y = \"Flipper length (in mm)\", # labels the y axis\n       colour = \"Sex\") # labels the grouping variable in the legend\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nYou can change the axes labels via the `labs()` function or include that step when modifying the scales (i.e. in the `scale_x_continuous()` function).\n\n## Layer 8\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  facet_wrap(~ species) +\n  labs(x = \"Body Mass (in g)\", \n       y = \"Flipper length (in mm)\",\n       colour = \"Sex\") +\n  # add a theme\n  theme_classic()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=100%}\n:::\n:::\n\n`theme_classic()` is applied to change the overall appearance of the plot.\n\n:::\n\n\n::: {.callout-important}\n\nYou need to stick to the first 3 layers to get your base plot. Everything else is optional meaning you don't have to use all 8 layers in a plot. And layers 4-8 can be added in a random order whereas layers 1-3 are fixed.\n\n:::\n\n\n\n\n\n## Activity 1: Set-up \n\nOk, let's move on to our data for today. But first, we need to set up a new project and create an Rmd:\n\n-   Create a new project and name it something meaningful (e.g., \"2A_chapter3\", or \"03_data_viz\"). See @sec-project if you need some guidance.\n-   Create a new Rmd and save it to your project folder. Name it something meaningful (e.g., \"chapter_03\", \"03_data_viz.Rmd\"). See @sec-rmd if you need some guidance.\n-   Delete everything below line 12 (keep the set-up code chunk)\n\n\n## Activity 2: Download the data\n\n-   Download the data for today: [data_ch3](data/data_ch3.zip \"download\"). There are 2 csv files contained in the zip-folder you just downloaded. One is the data file (`hp_data_modified.csv`) and the other is the `questionnaire_codebook` for the main 3 questionnaires used in the dataset.\n-   Unzip the zip folder so that all data files, the Rmd and the project are in the same folder (see image below)\n\nIf you set it up correctly, your folder should look like this:\n\n::: {#img-data-viz layout-ncol=2}\n\n![Folder on your computer (left)](images/data_viz_setup.PNG) \n\n![Files pane in RStudio (right)](images/files_plane_data_viz.PNG)\n\n:::\n\n#### Info about the data {.unnumbered}\n\n\n**citation**\n\n> Jakob, L., Garcia-Garzon, E., Jarke, H., & Dablander, F. (2019). The Science Behind the Magic? The Relation of the Harry Potter “Sorting Hat Quiz” to Personality and Human Values. *Collabra: Psychology, 5*(1), 31. [https://doi.org/10.1525/collabra.240](https://doi.org/10.1525/collabra.240){target=\"_blank\"}\n\n‌\n\n**Abstract**\n\n> The Harry Potter series describes the adventures of a boy and his peers in a fictional world at the “Hogwarts School of Witchcraft and Wizardry”. In the series, pupils get appointed to one of four groups (Houses) at the beginning of their education based on their personality traits. The author of the books has constructed an online questionnaire that allows fans to find out their House affiliation. Crysel, Cook, Schember, and Webster (2015) argued that being sorted into a particular Hogwarts House through the Sorting Hat Quiz is related to empirically established personality traits. We replicated their study while improving on sample size, methods, and analysis. Although our results are similar, effect sizes are small overall, which attenuates the claims by Crysel et al. The effect vanishes when restricting the analysis to participants who desired, but were not sorted into a particular House. On a theoretical level, we extend previous research by also analysing the relation of the Hogwarts Houses to Schwartz’s Basic Human Values but find only moderate or no relations.\n\n\n**Changes made to the dataset**\n\n* The dataset is a reduced version of the original dataset.\n* The values in the IPIP 50 were turned into character responses\n* All reverse-coded items were already corrected in the original dataset, so we reversed that process.\n* The PVQ-RR has been revised repeatedly over the years (and is somewhat confusing tbh). To keep it simple, we opted to code the 57 items into a 12-value category structure as proposed by Giménez and Tamajón (2019; [https://doi.org/10.1016/j.heliyon.2019.e01797](https://doi.org/10.1016/j.heliyon.2019.e01797){target=\"_blank\"}). This is not in line with Jakob et al. (2019), who used a 10-value categorisation approach.\n\n\n## Activity 3: Load in the libraries and read in the data\n\nGiven the codebook is also in a csv format, you might want to read in the codebook as well. It might help us speed up data wrangling process.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## packages \nlibrary(tidyverse)\n\n## data\nhp_data <- read_csv(\"hp_data_modified.csv\")\ncodebook <- read_csv(\"hp_questionnaire_codebook.csv\")\n```\n:::\n\n\n\n\n\n#### Familiarise yourself with the data structure {.unnumbered}\n\nAs we said in @sec-familiarise, it is always recommended to glimpse at the data to see how many variables and observations there are in the dataset and what kind of data type they are.\n\n\n::: {.callout-note collapse=\"true\"}\n## Using glimpse to view the data (the output is pretty long, therefore it's hidden. Click to see the output.)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(hp_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 988\nColumns: 159\n$ PP_ID                <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ books                <chr> \"Harry Potter and the Philosopher's Stone,Harry P…\n$ language_books       <chr> \"English\", \"German and English\", \"Both English an…\n$ movies               <chr> \"Harry Potter and the Philosopher's Stone,Harry P…\n$ language_movies      <chr> \"English\", \"German and English\", \"Both English an…\n$ Sorting_completed_YN <chr> \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Y…\n$ Sorting_house        <chr> \"Ravenclaw\", \"Gryffindor\", \"Gryffindor\", \"Slyther…\n$ Sorting_house_wish   <chr> \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw\", \"Slytherin…\n$ age                  <dbl> 21, 22, 27, 21, 20, 27, 26, 29, 23, 24, 25, 33, 2…\n$ country              <chr> \"Germany\", \"Germany\", \"France\", \"Norway\", \"Chile\"…\n$ language             <chr> \"german\", \"German\", \"French\", \"Norwegian\", \"Spani…\n$ occupation           <chr> \"Student\", \"Student\", \"Employed\", \"Student\", \"Stu…\n$ gender               <chr> \"Female\", \"Female\", \"Female\", \"Male\", \"Female\", \"…\n$ Bravery              <chr> \"Gryffindor\", \"Gryffindor\", \"Gryffindor\", \"Gryffi…\n$ Hardwork             <chr> \"Ravenclaw\", \"Ravenclaw\", \"Hufflepuff\", \"Hufflepu…\n$ Intelligence         <chr> \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw…\n$ Ambition             <chr> \"Slytherin\", \"Slytherin\", \"Slytherin\", \"Slytherin…\n$ Daring               <chr> \"Gryffindor\", \"Hufflepuff\", \"Gryffindor\", \"Gryffi…\n$ Dedication           <chr> \"Ravenclaw\", \"Slytherin\", \"Hufflepuff\", \"Hufflepu…\n$ Knowledge            <chr> \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw…\n$ Cunning              <chr> \"Slytherin\", \"Hufflepuff\", \"Slytherin\", \"Slytheri…\n$ Extraverted          <chr> \"Hufflepuff\", \"Hufflepuff\", \"Hufflepuff\", \"Gryffi…\n$ Agreeable            <chr> \"Hufflepuff\", \"Gryffindor\", \"Hufflepuff\", \"Huffle…\n$ Clever               <chr> \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw\", \"Ravenclaw…\n$ Manipulative         <chr> \"Slytherin\", \"Slytherin\", \"Slytherin\", \"Slytherin…\n$ IPIP_01              <chr> \"moderately accurate\", \"neither accurate nor inac…\n$ IPIP_02              <chr> \"very inaccurate\", \"moderately accurate\", \"very i…\n$ IPIP_03              <chr> \"moderately inaccurate\", \"very accurate\", \"modera…\n$ IPIP_04              <chr> \"moderately inaccurate\", \"neither accurate nor in…\n$ IPIP_05              <chr> \"very accurate\", \"moderately accurate\", \"very acc…\n$ IPIP_06              <chr> \"moderately inaccurate\", \"neither accurate nor in…\n$ IPIP_07              <chr> \"very accurate\", \"moderately inaccurate\", \"very a…\n$ IPIP_08              <chr> \"moderately accurate\", \"very inaccurate\", \"modera…\n$ IPIP_09              <chr> \"moderately accurate\", \"neither accurate nor inac…\n$ IPIP_10              <chr> \"very inaccurate\", \"very inaccurate\", \"very inacc…\n$ IPIP_11              <chr> \"moderately accurate\", \"moderately inaccurate\", \"…\n$ IPIP_12              <chr> \"very inaccurate\", \"moderately inaccurate\", \"very…\n$ IPIP_13              <chr> \"neither accurate nor inaccurate\", \"very accurate…\n$ IPIP_14              <chr> \"very inaccurate\", \"moderately accurate\", \"modera…\n$ IPIP_15              <chr> \"moderately accurate\", \"neither accurate nor inac…\n$ IPIP_16              <chr> \"neither accurate nor inaccurate\", \"moderately in…\n$ IPIP_17              <chr> \"moderately accurate\", \"neither accurate nor inac…\n$ IPIP_18              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_19              <chr> \"neither accurate nor inaccurate\", \"moderately in…\n$ IPIP_20              <chr> \"moderately inaccurate\", \"very inaccurate\", \"very…\n$ IPIP_21              <chr> \"very inaccurate\", \"moderately accurate\", \"modera…\n$ IPIP_22              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_23              <chr> \"very inaccurate\", \"moderately inaccurate\", \"very…\n$ IPIP_24              <chr> \"neither accurate nor inaccurate\", \"moderately in…\n$ IPIP_25              <chr> \"moderately accurate\", \"very accurate\", \"moderate…\n$ IPIP_26              <chr> \"very inaccurate\", \"moderately inaccurate\", \"mode…\n$ IPIP_27              <chr> \"moderately inaccurate\", \"moderately accurate\", \"…\n$ IPIP_28              <chr> \"moderately accurate\", \"moderately accurate\", \"ve…\n$ IPIP_29              <chr> \"moderately inaccurate\", \"moderately accurate\", \"…\n$ IPIP_30              <chr> \"very inaccurate\", \"moderately inaccurate\", \"very…\n$ IPIP_31              <chr> \"very inaccurate\", \"moderately accurate\", \"modera…\n$ IPIP_32              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_33              <chr> \"moderately inaccurate\", \"very accurate\", \"modera…\n$ IPIP_34              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_35              <chr> \"moderately accurate\", \"moderately accurate\", \"mo…\n$ IPIP_36              <chr> \"moderately accurate\", \"moderately inaccurate\", \"…\n$ IPIP_37              <chr> \"moderately accurate\", \"moderately accurate\", \"mo…\n$ IPIP_38              <chr> \"neither accurate nor inaccurate\", \"moderately in…\n$ IPIP_39              <chr> \"very inaccurate\", \"moderately inaccurate\", \"neit…\n$ IPIP_40              <chr> \"moderately accurate\", \"moderately accurate\", \"ve…\n$ IPIP_41              <chr> \"moderately inaccurate\", \"moderately accurate\", \"…\n$ IPIP_42              <chr> \"moderately accurate\", \"neither accurate nor inac…\n$ IPIP_43              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_44              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_45              <chr> \"very accurate\", \"moderately accurate\", \"very acc…\n$ IPIP_46              <chr> \"very accurate\", \"moderately inaccurate\", \"neithe…\n$ IPIP_47              <chr> \"moderately inaccurate\", \"moderately accurate\", \"…\n$ IPIP_48              <chr> \"moderately inaccurate\", \"moderately accurate\", \"…\n$ IPIP_49              <chr> \"moderately inaccurate\", \"moderately inaccurate\",…\n$ IPIP_50              <chr> \"moderately accurate\", \"moderately accurate\", \"ve…\n$ SD_M1                <dbl> 3, 4, 3, 4, 2, 3, 3, 3, 4, 2, 4, 3, 4, 4, 3, 4, 4…\n$ SD_M2                <dbl> 2, 3, 2, 5, 1, 2, 1, 2, 1, 2, 2, 4, 4, 4, 4, 2, 4…\n$ SD_M3                <dbl> 2, 3, 1, 4, 2, 2, 2, 3, 3, 2, 4, 1, 3, 2, 3, 3, 2…\n$ SD_M4                <dbl> 2, 2, 3, 4, 3, 3, 2, 4, 2, 2, 3, 4, 4, 4, 3, 2, 2…\n$ SD_M5                <dbl> 2, 2, 1, 4, 2, 2, 1, 1, 1, 1, 2, 1, 4, 3, 2, 2, 3…\n$ SD_M6                <dbl> 1, 3, 1, 5, 3, 3, 3, 4, 1, 2, 3, 1, 5, 1, 4, 3, 3…\n$ SD_M7                <dbl> 3, 5, 4, 5, 2, 5, 4, 4, 5, 2, 3, 1, 5, 4, 4, 5, 5…\n$ SD_M8                <dbl> 1, 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 1, 3, 1, 2…\n$ SD_M9                <dbl> 4, 4, 2, 4, 1, 4, 2, 2, 1, 3, 3, 1, 4, 5, 4, 1, 3…\n$ SD_N1                <dbl> 1, 3, 4, 4, 2, 3, 2, 1, 3, 3, 1, 1, 2, 2, 4, 3, 1…\n$ SD_N2                <dbl> 4, 1, 3, 3, 2, 3, 4, 4, 5, 3, 5, 5, 4, 2, 2, 5, 4…\n$ SD_N3                <dbl> 3, 2, 2, 2, 2, 2, 1, 3, 1, 1, 2, 1, 3, 2, 2, 1, 5…\n$ SD_N4                <dbl> 2, 2, 2, 1, 2, 2, 2, 5, 2, 1, 3, 1, 3, 1, 4, 1, 2…\n$ SD_N5                <dbl> 1, 2, 2, 4, 3, 2, 1, 4, 1, 3, 2, 1, 4, 2, 2, 1, 4…\n$ SD_N6                <dbl> 4, 1, 2, 4, 4, 4, 2, 5, 5, 3, 3, 1, 4, 1, 3, 4, 2…\n$ SD_N7                <dbl> 1, 3, 2, 3, 1, 1, 1, 4, 1, 3, 2, 1, 2, 4, 4, 1, 3…\n$ SD_N8                <dbl> 4, 3, 3, 2, 4, 3, 3, 4, 3, 4, 4, 3, 2, 2, 2, 4, 1…\n$ SD_N9                <dbl> 1, 4, 2, 4, 3, 2, 3, 2, 1, 4, 4, 1, 5, 2, 3, 3, 4…\n$ SD_P1                <dbl> 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 4, 2, 2…\n$ SD_P2                <dbl> 2, 3, 1, 4, 3, 4, 4, 4, 2, 2, 3, 3, 2, 2, 1, 3, 2…\n$ SD_P3                <dbl> 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 4, 2, 1…\n$ SD_P4                <dbl> 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 3, 1, 1…\n$ SD_P5                <dbl> 3, 4, 1, 4, 1, 2, 3, 4, 1, 3, 2, 1, 4, 4, 3, 1, 1…\n$ SD_P6                <dbl> 3, 3, 1, 4, 1, 2, 2, 2, 1, 1, 2, 1, 3, 1, 3, 2, 1…\n$ SD_P7                <dbl> 5, 5, 4, 1, 5, 5, 5, 5, 5, 2, 5, 5, 2, 5, 2, 5, 2…\n$ SD_P8                <dbl> 1, 1, 3, 2, 3, 2, 1, 3, 1, 2, 1, 1, 1, 1, 3, 3, 3…\n$ SD_P9                <dbl> 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 4…\n$ PVQ_01               <dbl> 5, 5, 5, 5, 6, 6, 4, 6, 4, 4, 5, 5, 5, 6, 6, 4, 6…\n$ PVQ_02               <dbl> 2, 6, 2, 4, 5, 2, 4, 4, 2, 3, 4, 4, 6, 4, 4, 6, 6…\n$ PVQ_03               <dbl> 4, 6, 3, 5, 6, 4, 4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 3…\n$ PVQ_04               <dbl> 2, 5, 4, 3, 3, 4, 5, 6, 5, 4, 5, 5, 4, 5, 4, 3, 2…\n$ PVQ_05               <dbl> 5, 5, 4, 3, 5, 5, 5, 6, 4, 5, 6, 6, 6, 5, 3, 5, 4…\n$ PVQ_06               <dbl> 1, 3, 2, 5, 3, 3, 2, 2, 1, 2, 2, 3, 3, 2, 3, 4, 4…\n$ PVQ_07               <dbl> 5, 5, 5, 3, 4, 5, 4, 5, 6, 4, 4, 4, 2, 5, 3, 5, 1…\n$ PVQ_08               <dbl> 3, 5, 4, 4, 6, 6, 3, 6, 2, 4, 6, 6, 3, 3, 2, 6, 3…\n$ PVQ_09               <dbl> 4, 4, 5, 2, 3, 4, 4, 3, 5, 3, 5, 2, 5, 3, 3, 6, 3…\n$ PVQ_10               <dbl> 4, 4, 6, 2, 5, 3, 4, 6, 4, 4, 5, 4, 4, 5, 6, 3, 5…\n$ PVQ_11               <dbl> 3, 6, 6, 6, 6, 6, 5, 5, 6, 5, 5, 6, 6, 6, 5, 4, 4…\n$ PVQ_12               <dbl> 1, 2, 1, 6, 2, 2, 2, 1, 1, 2, 3, 4, 3, 3, 1, 5, 3…\n$ PVQ_13               <dbl> 3, 5, 3, 5, 4, 4, 5, 5, 2, 3, 4, 4, 5, 5, 3, 6, 4…\n$ PVQ_14               <dbl> 5, 6, 5, 5, 6, 6, 6, 6, 4, 5, 6, 6, 6, 5, 6, 5, 4…\n$ PVQ_15               <dbl> 2, 3, 2, 2, 3, 4, 3, 5, 6, 4, 3, 2, 2, 2, 2, 2, 3…\n$ PVQ_16               <dbl> 4, 6, 5, 6, 6, 4, 5, 6, 5, 5, 5, 6, 6, 6, 6, 5, 5…\n$ PVQ_17               <dbl> 4, 6, 5, 6, 6, 4, 4, 6, 6, 5, 4, 5, 5, 6, 4, 4, 5…\n$ PVQ_18               <dbl> 1, 2, 2, 3, 2, 2, 2, 4, 1, 3, 2, 1, 1, 2, 2, 2, 4…\n$ PVQ_19               <dbl> 4, 4, 5, 4, 5, 6, 6, 5, 5, 3, 4, 5, 5, 6, 6, 3, 5…\n$ PVQ_20               <dbl> 1, 5, 1, 6, 2, 2, 2, 4, 1, 2, 3, 4, 5, 2, 2, 5, 4…\n$ PVQ_21               <dbl> 2, 3, 3, 0, 5, 4, 1, 0, 2, 4, 5, 0, 4, 1, 3, 6, 1…\n$ PVQ_22               <dbl> 5, 2, 3, 2, 2, 3, 3, 5, 6, 3, 4, 3, 4, 3, 2, 3, 1…\n$ PVQ_23               <dbl> 4, 5, 6, 5, 6, 5, 4, 5, 5, 5, 5, 6, 6, 6, 6, 4, 4…\n$ PVQ_24               <dbl> 2, 3, 2, 5, 2, 3, 4, 5, 4, 3, 3, 4, 5, 3, 3, 3, 4…\n$ PVQ_25               <dbl> 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 4, 6, 5, 5, 5, 5, 4…\n$ PVQ_26               <dbl> 3, 6, 3, 6, 4, 4, 5, 2, 1, 4, 5, 5, 6, 3, 5, 6, 4…\n$ PVQ_27               <dbl> 5, 6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 5, 5, 2…\n$ PVQ_28               <dbl> 3, 3, 6, 3, 5, 2, 2, 4, 4, 4, 5, 3, 4, 3, 6, 3, 2…\n$ PVQ_29               <dbl> 1, 4, 2, 5, 2, 2, 1, 1, 1, 2, 3, 3, 4, 4, 5, 4, 4…\n$ PVQ_30               <dbl> 3, 4, 5, 3, 5, 3, 4, 5, 4, 4, 5, 4, 5, 5, 4, 4, 5…\n$ PVQ_31               <dbl> 1, 3, 2, 3, 2, 4, 2, 4, 6, 2, 4, 1, 2, 2, 4, 5, 4…\n$ PVQ_32               <dbl> 4, 5, 3, 5, 5, 3, 3, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5…\n$ PVQ_33               <dbl> 1, 2, 2, 3, 4, 3, 2, 2, 2, 2, 1, 2, 1, 3, 1, 1, 3…\n$ PVQ_34               <dbl> 4, 5, 6, 4, 6, 6, 5, 6, 5, 4, 5, 6, 6, 6, 5, 5, 5…\n$ PVQ_35               <dbl> 1, 5, 2, 3, 4, 2, 2, 2, 1, 4, 3, 4, 5, 3, 2, 6, 5…\n$ PVQ_36               <dbl> 5, 6, 4, 5, 6, 4, 5, 3, 3, 4, 4, 5, 5, 4, 5, 5, 5…\n$ PVQ_37               <dbl> 5, 5, 4, 3, 6, 5, 5, 6, 4, 5, 5, 6, 6, 6, 5, 6, 6…\n$ PVQ_38               <dbl> 5, 4, 5, 2, 5, 3, 6, 4, 6, 4, 5, 4, 4, 4, 3, 5, 4…\n$ PVQ_39               <dbl> 4, 5, 5, 3, 6, 5, 4, 6, 6, 4, 5, 6, 5, 6, 6, 4, 6…\n$ PVQ_40               <dbl> 1, 2, 2, 3, 3, 3, 2, 4, 1, 2, 2, 1, 2, 3, 1, 1, 4…\n$ PVQ_41               <dbl> 2, 2, 2, 4, 2, 3, 1, 2, 1, 2, 2, 3, 4, 4, 4, 3, 3…\n$ PVQ_42               <dbl> 1, 5, 2, 2, 2, 4, 4, 3, 6, 2, 2, 1, 2, 3, 2, 5, 2…\n$ PVQ_43               <dbl> 5, 5, 5, 4, 6, 5, 4, 4, 5, 4, 3, 5, 5, 5, 5, 5, 6…\n$ PVQ_44               <dbl> 1, 2, 1, 4, 2, 2, 1, 1, 1, 2, 1, 1, 3, 2, 1, 4, 1…\n$ PVQ_45               <dbl> 2, 3, 4, 2, 5, 6, 2, 5, 2, 4, 6, 6, 5, 3, 3, 6, 3…\n$ PVQ_46               <dbl> 4, 4, 3, 3, 6, 3, 3, 2, 3, 3, 4, 1, 4, 4, 5, 2, 3…\n$ PVQ_47               <dbl> 3, 4, 5, 4, 5, 5, 4, 4, 5, 5, 4, 5, 4, 4, 5, 1, 2…\n$ PVQ_48               <dbl> 4, 3, 5, 6, 4, 2, 2, 4, 6, 4, 4, 5, 6, 5, 5, 4, 4…\n$ PVQ_49               <dbl> 4, 5, 5, 5, 3, 3, 2, 4, 6, 4, 4, 3, 5, 5, 4, 6, 3…\n$ PVQ_50               <dbl> 3, 4, 2, 3, 4, 2, 2, 3, 1, 4, 4, 3, 3, 3, 1, 6, 3…\n$ PVQ_51               <dbl> 5, 2, 2, 2, 3, 3, 3, 3, 6, 3, 4, 4, 3, 4, 3, 3, 3…\n$ PVQ_52               <dbl> 4, 5, 4, 5, 6, 5, 5, 6, 4, 5, 5, 6, 5, 6, 3, 6, 4…\n$ PVQ_53               <dbl> 2, 3, 2, 4, 3, 3, 3, 2, 2, 3, 4, 3, 3, 2, 1, 4, 4…\n$ PVQ_54               <dbl> 3, 2, 3, 2, 3, 3, 4, 5, 4, 4, 4, 3, 3, 5, 5, 2, 3…\n$ PVQ_55               <dbl> 5, 5, 5, 5, 5, 6, 5, 4, 5, 5, 4, 4, 5, 5, 4, 4, 4…\n$ PVQ_56               <dbl> 4, 6, 5, 6, 6, 5, 5, 6, 5, 4, 5, 6, 5, 6, 6, 5, 4…\n$ PVQ_57               <dbl> 4, 6, 5, 5, 5, 4, 4, 6, 4, 4, 4, 5, 5, 4, 4, 5, 4…\n```\n:::\n:::\n\n\n:::\n\n\n## Activity 4: Data wrangling\n\nBefore we can plot anything, we need to get the data into the right shape. \n\nThe data for the questionnaires looks fairly complex. It's best to split it up into separate data objects to wrangle the questionnaire data. The next sections will wrangle the data separately for the\n\n* IPIP 50 - International Personality Item Pool (Goldberg et al., 2006)\n* SD 3 - Short Dark Triad (Jones & Paulhus, 2013)\n* PVQ-RR - Portrait Values Questionnaire (Schwartz et al., 2012).\n\n### IPIP 50 \n\n**Overall goal** is to compute a score for each of the personality dimension (Agreeableness, Conscientiousness, Emotional Stability, Extraversion, Intellect) for each participant. So how do we do this?\n\n**First, check the data (data object and codebook). What is going on here?** IPIP items are in data type <select class='webex-select'><option value='blank'></option><option value='x'>numeric</option><option value='answer'>character</option><option value='x'>logical</option><option value='x'>factor</option></select> and there is <select class='webex-select'><option value='blank'></option><option value='x'>no</option><option value='answer'>some</option></select> reverse-scoring for the IPIP items.\n\n#### Step 1 {.unnumbered}\n\nSelect the Participant id and the items of the IPIP.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_ipip <- hp_data %>% \n  select(PP_ID, IPIP_01:IPIP_50)\n```\n:::\n\n\n#### Step 2 {.unnumbered}\n\nNext, items are in wide format which is not helpful. We need them in long format.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_ipip <- hp_ipip %>% \n  pivot_longer(cols = -PP_ID, # all coloumns apart from PP_ID\n               names_to = \"IPIP_items\",\n               values_to = \"IPIP_response\") \n```\n:::\n\n\n\n#### Step 3 {.unnumbered}\n\nNow, we need information which items are reverse-coded and modify how they are scored. We could code this ourselves like we did in **[LINK TO DATA SECTION IN CHAPTER 2]**, or we could take a shortcut since the information is already stored in the codebook. \n\nWe won't need all the info from codebook, so we need to select the relevant columns (`Questionnaire_Item`, `Forward- or Reverse-coded item`, `Dimension`) first before joining our `hp_ipip` with `codebook_reduced`. Retaining the Dimension will help later on with calculating scores for each subscale. \n\n\nNotice how there are spaces in the variable name `Forward- or Reverse-coded item` which R has to wrap in single backticks to be able to process. Maybe better to change that variable name to `FW_RV` during selection so that it won't give us a headache later on.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncodebook_reduced <- codebook %>% \n  select(Questionnaire_Item, FW_RV = `Forward- or Reverse-coded item`, Dimension)\n```\n:::\n\n\nNow we can join those 2 dataframes together using `left_join()` or an `inner_join()`, which means only information for the IPIP items will be considered.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_ipip_codebook <- left_join(hp_ipip, codebook_reduced)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `left_join()`:\n! `by` must be supplied when `x` and `y` have no common variables.\nℹ Use `cross_join()` to perform a cross-join.\n```\n:::\n:::\n\n\n\n\nOh, an error message. Meh. It says `x and y have no common variables`. Ohhh, because when we pivoted `hp_ipip`,  we named the column with the IPIP items `IPIP_items` whereas information in `codebook_reduced` is stored in a column called `Questionnaire_Item`. To fix that, we could either\n\n* change the column name in `hp_ipip` during pivoting, i.e., setting `names_to = \"Questionnaire_Item\"`\n* change the column name in `codebook_reduced` during selection of the variables, i.e., `select(IPIP_items = Questionnaire_Item, etc.)` but that would only help us for IPIP items, not for the SD or the PVQ later on (so not really an option)\n* use a workaround and define the different column names in the \"by\" argument\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_ipip_codebook <- left_join(hp_ipip, codebook_reduced, by = join_by(IPIP_items == Questionnaire_Item))\n\nglimpse(hp_ipip_codebook)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 49,400\nColumns: 5\n$ PP_ID         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ IPIP_items    <chr> \"IPIP_01\", \"IPIP_02\", \"IPIP_03\", \"IPIP_04\", \"IPIP_05\", \"…\n$ IPIP_response <chr> \"moderately accurate\", \"very inaccurate\", \"moderately in…\n$ FW_RV         <chr> \"Forward\", \"Reverse\", \"Forward\", \"Reverse\", \"Forward\", \"…\n$ Dimension     <chr> \"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \"E…\n```\n:::\n:::\n\n#### Step 4 {.unnumbered}\n\nNow it's getting tricky. Reverse-coding.\n\nWhat we need to do is:\n\n* turn the character values into numbers and\n* make sure that we the correct those numbers for the reverse-coded items\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_ipip_final <- hp_ipip_codebook %>% \n  # regardless of FW_RV item, we'll recode very inaccurate as 1, moderately inaccurate as 2, etc\n  mutate(IPIP_values = case_when(\n    IPIP_response == \"very inaccurate\" ~ 1,\n    IPIP_response == \"moderately inaccurate\" ~ 2,\n    IPIP_response == \"neither accurate nor inaccurate\" ~ 3,\n    IPIP_response == \"moderately accurate\" ~ 4,\n    IPIP_response == \"very accurate\" ~ 5,\n    .default = NA\n  )) %>% \n  # now we are reverse-scoring items. If it's a reverse coded item, we want the corrected score be 6 minus the IPIP_value\n  mutate(IPIP_values_corrected = case_when(\n    FW_RV == \"Reverse\" ~ 6-IPIP_values,\n    .default = IPIP_values\n  ))\n```\n:::\n\n\n\n::: {.callout-note collapse=\"true\"}\n## Check it worked\n\nAlways good to double check to see if it worked. Either look at it, or create an output with distinct values.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndistinct_values <- hp_ipip_final %>% \n  distinct(IPIP_response, FW_RV, IPIP_values_corrected) %>% \n  arrange(FW_RV, desc(IPIP_values_corrected))\n```\n:::\n\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n\n## Alternative solution\n\nWe took 2 steps above to turn character into numeric values and recode those according to whether they were reverse -scored. However, we could have done this in one step:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_ipip_final_v2 <- hp_ipip_codebook %>% \n  mutate(IPIP_values_corrected = case_when(\n    IPIP_response == \"very inaccurate\" & FW_RV == \"Forward\" ~ 1,\n    IPIP_response == \"moderately inaccurate\" & FW_RV == \"Forward\" ~ 2,\n    IPIP_response == \"moderately accurate\" & FW_RV == \"Forward\" ~ 4,\n    IPIP_response == \"very accurate\" & FW_RV == \"Forward\" ~ 5,\n    IPIP_response == \"neither accurate nor inaccurate\" ~ 3, ## doesn't need to be recoded because 3 is 3 for both FW and RV items\n    IPIP_response == \"very inaccurate\" & FW_RV == \"Reverse\" ~ 5,\n    IPIP_response == \"moderately inaccurate\" & FW_RV == \"Reverse\" ~ 4,\n    IPIP_response == \"moderately accurate\" & FW_RV == \"Reverse\" ~ 2,\n    IPIP_response == \"very accurate\" & FW_RV == \"Reverse\" ~ 1,\n    .default = NA\n  ))\n\ndistinct_values_v2 <- hp_ipip_final_v2 %>% \n  distinct(IPIP_response, FW_RV, IPIP_values_corrected) %>% \n  arrange(FW_RV, desc(IPIP_values_corrected))\n```\n:::\n\n\n:::\n\n#### Step 5 {.unnumbered}\n\nAccording to the paper, the IPIP scores are getting summed up for each of the dimensions. And we need to do this per participant.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary_IPIP <- hp_ipip_final %>% \n  group_by(PP_ID, Dimension) %>% \n  summarise(IPIP_score = sum(IPIP_values_corrected)) %>% \n  ungroup()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'PP_ID'. You can override using the\n`.groups` argument.\n```\n:::\n:::\n\n\n### SD3\n\n**Overall goal** for the SD3 questionnaire: We need to calculate an overall Score for the Dark Triad dimensions **Psychopathy** (lack of emotional warmth for others or empathy paired with sensation seeking, risk-taking behaviour, and lack of guilt), **Machiavellianism** (tendency to manipulate others for own gain), and **Narcissism** (exaggerated sense of grandiosity, importance, entitlement, and need to be admired) per participant.\n\n**First, check the data (data object and codebook). What is going on here?** SD items are in data type <select class='webex-select'><option value='blank'></option><option value='answer'>numeric</option><option value='x'>character</option><option value='x'>logical</option><option value='x'>factor</option></select> and there is <select class='webex-select'><option value='blank'></option><option value='x'>no</option><option value='answer'>some</option></select> reverse-scoring for the SD items.\n\n**So how do we achieve that? ** Actually the steps are fairly similar to what we computed for the IPIP, apart from having to recode the values as numbers before being able to reverse-code them:\n\n* Step 1: select PP_ID and all the questions related to the SD_questionnaires\n* Step 2: pivot into long format\n* Step 3: join with `codebook_reduced`\n* Step 4: reverse_code the scores\n* Step 5: calculate sums for each dimension\n\nKeep to the separate steps if this is more organised for you easier to keep track, but we are attempting this in a single pipe. Keep the solution hidden if you want to challenge yourself.\n\n::: {.callout-note collapse=\"true\"}\n\n## Data Wrangling code for SD3\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary_SD <- hp_data %>% \n  select(PP_ID, starts_with(\"SD\")) %>% # starts_with selects all column names that start with \"SD\"\n  pivot_longer(cols = -PP_ID, # all columns apart from PP_ID\n               names_to = \"Questionnaire_Item\", # smarter approach\n               values_to = \"SD_response\") %>% \n  left_join(codebook_reduced) %>% # now that the column names match across questionnaires, we don't need the by argument\n  mutate(SD_corrected = case_when(\n    FW_RV == \"Reverse\" ~ 6-SD_response,\n    .default = SD_response\n    )) %>% \n  group_by(PP_ID, Dimension) %>% \n  summarise(SD_score = sum(SD_corrected)) %>% \n  ungroup()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Questionnaire_Item)`\n`summarise()` has grouped output by 'PP_ID'. You can override using the\n`.groups` argument.\n```\n:::\n:::\n\n\n:::\n\n\n### PVQ-RR\n\n**Overall goal** for the PVQ-RR questionnaire: We need to calculate an overall score for each of the 12 dimensions per participant.\n\n**First, check the data (data object and codebook). What is going on here?** PVQ items are in data type <select class='webex-select'><option value='blank'></option><option value='answer'>numeric</option><option value='x'>character</option><option value='x'>logical</option><option value='x'>factor</option></select> and there is <select class='webex-select'><option value='blank'></option><option value='answer'>no</option><option value='x'>some</option></select> reverse-scoring for the SD items.\n\n**So how do we achieve that? ** Actually this is more straightforward than data wrangling for the IPIP and the SD. We basically have to:\n\n* Step 1: select PP_ID and all the questions related to the PVQ_questionnaires\n* Step 2: pivot into long format\n* Step 3: join with `codebook_reduced`\n* Step 4: calculate sums for each dimension\n\n\nSimilar to SD, we attempt this in a single pipe. Feel free to try first before looking at the solution below.\n\n::: {.callout-note collapse=\"true\"}\n\n## Data Wrangling code for PVQ-RR\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary_PVQ <- hp_data %>% \n  select(PP_ID, starts_with(\"PVQ\")) %>% # starts_with selects all column names that start with \"PVQ\"\n  pivot_longer(cols = -PP_ID, # all columns apart from PP_ID\n               names_to = \"Questionnaire_Item\", # smarter approach\n               values_to = \"PVQ_response\") %>% \n  left_join(codebook_reduced) %>% # now that the column names match across questionnaires, we don't need the by argument\n  group_by(PP_ID, Dimension) %>% \n  summarise(PVQ_score = mean(PVQ_response)) %>% \n  ungroup()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Questionnaire_Item)`\n`summarise()` has grouped output by 'PP_ID'. You can override using the\n`.groups` argument.\n```\n:::\n:::\n\n:::\n\nOne thing though: The Dimension column has the name of the PVQ category but also the abbreviation in brackets. We might want to tidy that up now before we start plotting. We can use the `separate()` function for that.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary_PVQ <- summary_PVQ %>% \n  separate(Dimension, into = c(\"Dimension\", NA), sep = \" \") # split column at the space character and keep Dimension and drop the second one (which would have been the abbreviation in brackets (XX))\n```\n:::\n\n\n\n## Which plot shall I build??? {#sec-appropriate-plot}\n\nAlright, let's get started with data visualisation, now that we have the data in a tidy format. Question is now, which one is the right plot for your data?\n\nDifferent types of data require different types of plots, so this comes back to how many variables are you aiming to plot and what kind of data type are they.\n\n\n### One categorical variable\n\n#### Barplot (`geom_bar()`)\n\nLet's say we want to count some demographics. To keep it simple, we want to show gender counts. We would use a **barplot** for it. This is done with `geom_bar()` in your third layer, and because the counting is done in the background, the `aes` only requires an x value (i.e. the name of your variable).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender)) +\n  geom_bar() \n```\n\n::: {.cell-output-display}\n![Base version of a barchart](03-dataviz_files/figure-html/fig-bc-base-1.png){#fig-bc-base fig-align='center' width=100%}\n:::\n:::\n\n\nThis is the base plot done. You can customise it again by adding different layers. Some examples are in the tabs below. \n\n\n::: {.panel-tabset group=\"layers\"}\n\n## Colour\n\nWe can change the colour by adding a fill argument in the `aes()`. If we want to modify these colours further, we would add a `scale_fill_?` argument. If you have specific colours in mind, you would use `scale_fill_manual()` or if you want to stick with pre-dined ones, like viridis, use `scale_fill_viridis_d()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = gender)) +\n  geom_bar() +\n  # customise colour\n  scale_fill_viridis_d()\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Axes labels & margins\n\nNothing too \"off\" in this case, but given Female and Male are capitalised, we may want to tidy the axes labels a bit. There is also this gap between bottom of the chart and the bars which seems a bit weird. We can remove that with an `expansion()` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = gender)) +\n  geom_bar() +\n  scale_fill_viridis_d() +\n  # changing labels v1 (with labs function, can add x and y)\n  labs(x = \"Gender\") + \n  scale_y_continuous(\n    # changing labels v2 (within the scale function, only deals with either x or y depending if it's scale_x or scale_y)\n    name = \"Count\",\n    # remove the space below the bars, but keep a tiny bit (5%) above\n    expand = expansion(mult = c(0, 0.05))\n  )\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Legend\n\nThe legend does not add any information because the labels are already provided on the x axis. We can remove the legend by adding the argument `guide = \"none\"` into the `scale_fill` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = gender)) +\n  geom_bar() +\n  scale_fill_viridis_d(\n    # remove the legend\n    guide = \"none\") +\n  labs(x = \"Gender\") + \n  scale_y_continuous(\n    name = \"Count\",\n    expand = expansion(mult = c(0, 0.05))\n  )\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Themes\n\nLet's experiment with the themes. For this plot we have chosen `theme_minimal()`\n  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = gender)) +\n  geom_bar() +\n  scale_fill_viridis_d(\n    guide = \"none\") +\n  labs(x = \"Gender\") + \n  scale_y_continuous(\n    name = \"Count\",\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  # pick a theme\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-30-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n\n#### Column plot (`geom_col()`)\n\nIf someone had already summarised those counts for you, you would not be able to use `geom_bar()`. In that case, you would switch to `geom_col()`. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngender_count <- hp_data %>% \n  count(gender)\n\ngender_count\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gender |   n|\n|:------|---:|\n|Female | 819|\n|Male   | 169|\n\n</div>\n:::\n:::\n\n\nThe mapping for `geom_col()` requires both an **x** and a **y** aesthetics. In our example, x would be our categorical variable (e.g., `gender`), and y would be the column name that stored the values (`n`). Note how the base version has now n as an axis title (instead of count). \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(gender_count, aes(x = gender, y = n, fill = gender)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-32-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\nThe other layers to change the colour scheme, axes labels and margins, removing the legend and altering the theme are exactly the same. Test yourself to see if you could...\n\n* [ ] change the colour scheme (e.g., viridis or [any other colour palettes](https://www.datanovia.com/en/blog/the-a-z-of-rcolorbrewer-palette/){target=\"_blank\"})\n* [ ] remove the legend\n* [ ] change the title of the x and y axes\n* [ ] make the bars start directly on the x axis\n* [ ] add a theme of your linking\n\n::: {.callout-tip collapse=\"true\"}\n\n## Code for the column plot with all other changes\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(gender_count, aes(x = gender, y = n, fill = gender)) +\n  geom_col() +\n  # replaced vidiris with the brewer palette\n  scale_fill_brewer(\n    palette = \"Set1\",\n    guide = \"none\") +\n  labs(x = \"Gender\") + \n  scale_y_continuous(\n    name = \"Count\",\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  # different theme\n  theme_light()\n```\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n\n\n\n### Two categorical variables\n\nThis time we want to know whether participants have already been sorted into their houses and what the gender splits are. To show that, we would need to produce a barchart that somehow includes multiple groups.\n\n\n#### Stacked barchart\n\nIf we are keeping to the base level plot and do not add any fancy arguments, we would create a **Stacked barchart**. As the name suggests, the subgroups are displayed on top of each other.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = Sorting_completed_YN)) +\n  geom_bar() # position = \"stack\" is the default. Adding or removing this argument would produce the same plot\n```\n\n::: {.cell-output-display}\n![Base version of a stacked barchart](03-dataviz_files/figure-html/fig-sbc-base-1.png){#fig-sbc-base fig-align='center' width=100%}\n:::\n:::\n\n\nNow, the number of males in this sample are quite a bit lower than the number of females, which might make it tough to compare. Once way to get around this is to display a **Percent stacked barchart**. \n\n#### Percent stacked barchart\n\nWe will have to add the argument `position = \"fill\"` to the `geom_bar()`. By default, the position argument is set to \"stack\" so if we leave it out, we get the stacked barchart we produced above.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = Sorting_completed_YN)) +\n  geom_bar(position = \"fill\")\n```\n\n::: {.cell-output-display}\n![Base version of a percent stacked barchart](03-dataviz_files/figure-html/fig-psbc-base-1.png){#fig-psbc-base fig-align='center' width=100%}\n:::\n:::\n\n\nNow we would be able to draw conclusions that a higher proportion of females in this sample have already completed the sorting compared to males.\n\n#### Grouped barchart\n\nOne more option would be to display the the bars next to each other rather than stacked in a **Grouped barchart**. We would achieve that by changing the position argument to **\"dogde\"**.\n\nWe could also move the legend to a different place by including the line `theme(legend.position = \"bottom\")` if you want it placed at the bottom of the plot (left, right (default), top, and bottom are possible).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = Sorting_completed_YN)) +\n  geom_bar(position = \"dodge\") +\n  # legend moved below the plot\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![Simple grouped barchart with legend position altered](03-dataviz_files/figure-html/fig-gbc-base-1.png){#fig-gbc-base fig-align='center' width=100%}\n:::\n:::\n\n\n\nAgain, all other layers to change the colour of the bars, axes labels and margins, and altering the theme are exactly the same as we used in the barchart with one categorical variable. However, here the legend is meaningful, so we need to keep it. \n\nThe response labels \"Yes\" and \"No\" for variable \"Sorting Completed\" are pretty clear here, but if we wanted to change them, we can do that via the `scale_fill_` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = gender, fill = Sorting_completed_YN)) +\n  geom_bar(position = \"dodge\") +\n  # changing colour scheme to viridis\n  scale_fill_viridis_d(\n    # changing fill variable responses\n    labels = c(\"Not Yet Sorted\", \"Sorted\")\n  ) +\n  # changing labels for x, y, and fill\n  labs(x = \"Gender\", y = \"Count\", fill = \"Sorting Completed\") + \n  scale_y_continuous(\n    # remove the space below the bars, but keep a tiny bit (5%) above\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  # pick a theme\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Grouped barchart with a few more layers added](03-dataviz_files/figure-html/fig-gbc-adv-1.png){#fig-gbc-adv fig-align='center' width=100%}\n:::\n:::\n\n\n### One continuous variable\n\n#### Histogram `geom_histogram()`\n\nIf you wanted to show the distribution of a continuous variable, you can use a histogram. As with every plot, you need at least 3 layers to create a base version of the plot. Similar to `geom_bar()`, `geom_histogram()` only requires an `x` variable.\n\nA histogram splits the data into “bins” (i.e., groupings displayed in a single bar). These values are plotted along the x-axis and shows the count of how many observations are in each bin along the y-axis. It's basically a bar chart for continuous variables.\n\nLet's have a look at the age distribution in our dataset.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(hp_data, aes(x = age)) +\n  geom_histogram(binwidth = 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-dataviz_files/figure-html/unnamed-chunk-34-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-important}\n\n## warning message\n\nThe warning message tell us that 2 rows were removed because they contained non-finite values outside the scale range. If you have a closer look at the data, you can spot those 2 rows as missing values.\n\n:::\n\nThe default bin number is 30. Changing the number of bins (argument `bins`) can help to show more or less fine tuning in the data. Bigger numbers of bins means more finetuning. Perhaps it's more intuitive to modify the width of each bin instead via the argument (`binwidth`). The plots below show both.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#less finetuning\nggplot(hp_data, aes(x = age)) +\n  geom_histogram(bins = 10) \n\n# more fineturning\nggplot(hp_data, aes(x = age)) +\n  geom_histogram(binwidth = 1) \n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_bin()`).\nRemoved 2 rows containing non-finite outside the scale range (`stat_bin()`).\n```\n:::\n\n::: {.cell-output-display}\n![Bins vs binwidth arguments](03-dataviz_files/figure-html/fig-bins-1.png){#fig-bins fig-align='center' width=100%}\n:::\n:::\n\n\n**add some colour and a few layers**\n\n### One continuous and one categorical grouping variable\n\n####\n\nHave one with char and one with numbers\nfactors are important\n\ndodged histogram or better facet\n\nviolin plot\n\nboxplot\n\nviolin-boxplot\n\nFor ordinal rating scale: overplotting with geom_point. Use geom_jitter instead - tab you can also change the size of the dot and the transparency\n\n### Two continuous\n\nscatterplot\n\ntrendlines straight line vs loess\n\nshow them next to each other like Lisa has\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_plot <- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = lm, formula = y~x) +\n  ggtitle(\"method = lm\")\n\nloess_plot <- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = loess, formula = y~x) +\n  ggtitle(\"method = loess\")\n\nlm_plot + loess_plot\n```\n:::\n\n\n## Activity X: Saving the figure\n",
    "supporting": [
      "03-dataviz_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}