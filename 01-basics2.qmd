# Projects, R Markdown, and Data Wrangling

## Intended Learning Outcomes {.unnumbered}

By the end of this chapter you should be able to:

-   Re-familiarise yourself with setting up projects
-   Re-familiarise yourself with RMarkdown documents
-   Recap and apply data wrangling procedures to analyse data

## [Individual Walkthrough]{style="color: #EBA347; text-transform: uppercase;"} {.unnumbered}

## R and R Studio

Remember, R is a programming language that you will write code in and RStudio is an Integrated Development Environment (IDE) which makes working with R easier as it's more user friendly. You need both components for this course.

If this is not ringing any bells yet, have a quick browse through the [materials from year 1](https://psyteachr.github.io/data-skills-v2/sec-intro.html?q=RMark#sec-intro-r){target="_blank"}to refresh yopur memory.

### R server

R and RStudio are already installed on the *R server*. We recommend using the server if your computer does not allow installation (e.g., a Chromebook), or if you have problems with installing R on your computer. Otherwise, you should consider installing R and RStudio on your own computer.

You will find the link to the server on Moodle.

### Installing R and RStudio on your computer

@sec-installing-r has detailed instructions on how to install R and RStudio on your own computer. There are also some links to a series of walkthroughs for installing R on different types of computers/ operating systems.

If you had R and RStudio installed on your own computer last year, we recommend updating to the latest versions. In fact, it might be good to do that at the start of each academic year. Detailed guidance can be found in @sec-updating-r.

Once you have installed/updated R and RStudio, come back to this chapter.

### Settings for Reproducibility

*--> mention the replication crisis, findings are not reproducible. Hence it's super important that we do things in a reproducible way*

*Wikipedia: The replication crisis[a] is an ongoing methodological crisis in which the results of many scientific studies are difficult or impossible to reproduce. Because the reproducibility of empirical results is an essential part of the scientific method,[2] such failures undermine the credibility of theories building on them and potentially call into question substantial parts of scientific knowledge.*


You should be doing things reproducibly, so that others (and your future self) can understand and check your work. That also allows you to reuse your work more easily.

You should always start with a clear workspace. Keeping anything in your Environment from a previous session means you can never be sure whether your current code is working or if your code is accessing a previously created object.

Hence, there are a few settings you should fix immediately after installing/updating RStudio, in <if>Tools \> Global Options... General tab</if>

-   uncheck the box that says <if>Restore .RData into workspace at startup</if> to make sure no data from a previous session is loaded into the environment
-   set <if>Save workspace to .RData on exit</if> to <if>Never</if> so that your workspace is not saved when you exit RStudio.

```{r img-reprod, echo=FALSE, fig.cap="Reproducibility settings"}

knitr::include_graphics("images/rstudio_settings_reproducibility.png")

```

### RStudio panes

RStudio has four main panes each in a quadrant of your screen:

-   Source pane
-   Environment pane
-   Console pane
-   Output pane

**Do you remember what their purpose is?**

**The Source pane...** `r longmcq(c(answer = "allows users to view and edit various code-related files, such as .Rmd files", "contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs", "includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function", "provides an area to interactively execute code"))`

**The Environment pane...** `r longmcq(c("allows users to view and edit various code-related files, such as .Rmd files", "contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs", answer = "includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function", "provides an area to interactively execute code"))`

**The Console pane...** `r longmcq(c("allows users to view and edit various code-related files, such as .Rmd files", "contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs", "includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function", answer = "provides an area to interactively execute code"))`

**The Output pane...** `r longmcq(c("allows users to view and edit various code-related files, such as .Rmd files", answer = "contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs", "includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function", "provides an area to interactively execute code"))`

**Where are these panes located by default?**

-   The Source pane is located? `r mcq(sample(c(answer = "top left", "bottom left", "top right", "bottom right")))`
-   The Environment pane is located? `r mcq(sample(c("top left", "bottom left", answer = "top right", "bottom right")))`
-   The Console pane is located? `r mcq(sample(c("top left", answer = "bottom left", "top right", "bottom right")))`
-   The Output pane is located? `r mcq(sample(c("top left", "bottom left", "top right", answer = "bottom right")))`

If you were not quite sure about one/any of the panes, check out the [materials from Level 1](https://psyteachr.github.io/data-skills-v2/sec-intro.html?q=RMark#rstudio-panes){target="_blank"}. If you want to know more about them, there is the [RStudio guide on posit](https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html){target="_blank"}







## Activity 1: Creating a new project

It's important that we create a new RStudio project every time we start a new project. It makes life easier to work in multiple contexts, for example when analysing different datasets at the same time. Every RStudio project has their folder location, workspace, and working directories, basically keeping all the data and the RMarkdown documents in one location.

Last year, you learnt how to create projects on the server, so you already know the steps. If cannot quite recall how that was done, go back to the [Level 1 materials](https://psyteachr.github.io/data-skills-v2/sec-intro.html?q=RMark#new-project){target="_blank"}.

On your own computer, open RStudio, and complete the following steps in this order:

-   Click on <if>File \> New Project...</if>
-   Then, click on "New Directory"
-   Then, click on "New Project"
-   Name the directory something useful (e.g., "2A_chapter1"), and save it in a location that makes sense, for example a dedicated folder you have for your level 2 Psychology labs - you can either select a folder you have already in place, or create a new one (e.g., I named my new folder "Level 2 labs")
-   Click "Create Project". RStudio will restart itself and open with this new project directory as the working directory.
-   You can also check in your folder structure that everything was created as intended

```{r img-projectsetup, echo=FALSE, fig.cap="Creating a new project"}

knitr::include_graphics("images/project_setup.gif")

```

::: {.callout-tip title="Why is the Colour scheme in the gif different?" collapse="true"}
In case anyone is wondering why my colour scheme in the gif above looks different to yours, I've set mine to "Pastel On Dark" in <if>Tools \> Global Options... \> Appearances</if>. And my computer lives in "dark mode".
:::

::: callout-important
## Don't nest projects

Don't ever save a new project **inside** another project directory. This can cause some hard-to-resolve problems.
:::




## Activity 2: The data for this chapter


In this chapter, we are going to brush up on our data wrangling skills, and given we have been talking about reproducibility, we'll use an open dataset on gender beliefs and subject choices to do so. The paper was published earlier this year, and the original data can be found on OSF ([https://osf.io/4jac7/](https://osf.io/4jac7/){target="_blank"}). However, for the purpose of this chapter, I have modified the data slightly (for example, using a file format you can work with). 

**citation**
Pownall, M., & Heflick, N. (2024). Male psychologists and female mathematicians: Gender beliefs and undergraduate degree choices. *Journal of Community & Applied Social Psychology, 34*(2), e2784. [https://doi.org/10.1002/casp.2784](https://doi.org/10.1002/casp.2784){target="_blank"}


**Abstract**
Globally, men and women are numerically dominant in undergraduate degrees in math and psychology, respectively. A variety of theoretical perspectives predict that individuals who adhere more to gender stereotypes will be more represented in gender-dominant fields. Using a pre-registered methodology, we recruited men and women enrolled in psychology and math degree programmes in the United Kingdom and assessed a variety of gender beliefs and identities. Overall, femininity was (marginally) higher in psychology, and higher amongst women generally. Moderated regression analyses revealed that women who were low in masculinity and high in femininity (the stereotypical pattern) were most likely to be in psychology degrees, whilst women who were low in both were most likely to be enrolled onto math programmes. For men, no component of gender identity or beliefs predicted degree programmes. Overall, these results demonstrate how dimensions of gender identity may account for gender differences in undergraduate representation. Specifically, women in STEM fields tend to not describe themselves in stereotypical masculine or feminine traits. We discuss implications for efforts to increase uptake of gender stereotype incongruent career paths (e.g., women in STEM) with a particular focus on how femininity may be rejected in counter-stereotypical domains.



## R Markdown basics

### Creating an R Markdown file

delete everything after the knitting part from line 12

and save it in the project. All of the data files you need, should go into the same project folder too

### Code Chunks vs Text

### Knitting

## Data Wrangling

The basic ones are the **Wickham 6** that you've encountered already last year

table of the Wickham 6 refer them back to the different chapters where they encountered it in level 1

| Function    | Description                            | First introduced in Level 1 Chapter                        |
|:-----------------|:----------------------------------|:------------------|
| select()    | Include or exclude certain variables (columns)             | [Chapter 6.5](https://psyteachr.github.io/data-skills-v2/corsi-blocks-2.html#activity-3-selecting-variables){target="_blank"} |
| filter()    | Include or exclude certain observations/data (rows)        | [Chapter 6.6](https://psyteachr.github.io/data-skills-v2/corsi-blocks-2.html#activity-4-filtering-observations){target="_blank"} |
| mutate()    | Creates new variables (columns)                            | [Chapter 8.8](https://psyteachr.github.io/data-skills-v2/belonging-2.html?q=mutate#activity-5-mutate-and-recode){target="_blank"} |
| arrange()   | Changes the order of observations (rows)                   | not yet introduced |
| group_by()  | Organises the observations (rows) into groups              | [Chapter 3.5.3](https://psyteachr.github.io/data-skills-v2/stroop-2.html#summarising-by-groups){target="_blank"} |
| summarise() | Create summary variables for groups of observations (rows) | [Chapter 3.5.2](https://psyteachr.github.io/data-skills-v2/stroop-2.html#calculating-summary-statistics){target="_blank"} |





### Brief recap of the Wickham 6

#### select

Massive dataframes use a lot of computing power - to reduce that, it would be worth focussing on the columns you need

selecting variables - you can rename them too if you don't like the column name as is

if you wanna rename something at a later stage, use rename. Works in the same manner as select as in new name = old name. --\> This could be in an information box

deselecting deselecting multiple variables

#### filter

text - one condition vs more than one condition numbers - smaller/ larger

#### arrange

ascending, descending - NAs will always listed at the end regardless

#### mutate

Allison's drawing

#### group_by & summarise

## Other useful functions

### count

### joining things together from separate datasets

**inner_join**

**full_join**

Use the 2 chopped up tables earlier and merge them. They have no values overlapping, so it's difficult

## Tidy data

### pivoting data

pivot_wider and pivot_longer

### recode

### case_when

Allison's drawing

## [Pair-coding in the lab]{style="color: #EBA347; text-transform: uppercase;"} {.unnumbered}

## [Test your knowledge and challenge yourself]{style="color: #EBA347; text-transform: uppercase;"} {.unnumbered}

or for the Wickham 6 part, we could just go here is some data, lets apply them all.

Activity 1: selecting specific columns First of all, we want to select the relevant columns


### Tidy data

Data is messy, especially in a raw format (i.e., when you download it straight from your testing software). R prefers the data to be tidy, which means each row is an **observation**, each column is a **variable**, and the information in each cell is a single **value**.

I've modified the data for today slightly, to build in some challenges that you would experience when dealing with raw data, but tbh, the data we are looking at today is pretty tidy.

Getting an understanding of what your data currently looks like and being aware of what your data structure needs to be (e.g., for calculating descriptives, running inferential stats or plotting) is the first step of thinking about the processing steps of how to get your data from A to B.




:::{.quiz}

::::{.quiz-header}
:::::{.quiz-icon}
:::::
This is my test solution
::::

::::{.quiz-body}
And some content inside of it
::::

:::



:::{.goals collapse="true"}
::::{.goals-header}
:::::{.goals-icon}
:::::
Learning Goals
::::
::::{.goals-container}
* Know how to make your own callouts.
* Be able to mess with some SCSS/CSS styling.
::::
:::



:::{.quiz}

::::{.quiz-header}
:::::{.quiz-icon}
:::::
Quiz
::::

::::{.quiz-body}
* Know how to make your own callouts.
* Be able to mess with some SCSS/CSS styling.
::::

:::


::: {.callout-note icon=false appearance="simple" collapse="true"}
## heading simple

text

:::


::: {.callout-note icon=false appearance="minimal" collapse="true"}
## heading minimal

text

:::

::: {.callout-note icon="false" collapse="true"}
## heading default

text

:::



str_detect(Items, "_R") ~ 8-Scores,



## Activity 7: Compute a paired t-test and effect size

The paired t-test compares two sample means to each other, but the two groups are related to each other, i.e. “paired”, e.g., the same mice before and after treatment. The paired t-test simply calculates the difference between paired groups and then performs the one-sample t-test on the differences.

```{r}
library(rstatix)
```

The `t.test()` function we used for the one-sample t-test can be used here, however, it has been a bit buggy recently not taking in certain arguments (more so for the paired sample t-test we talk about in the next chapter). Therefore, we are switching over to the `t_test()` function from the `rstatix` package.

The output is organised slightly different to what we've seen in the `t.test()` function, and whilst it looks neater, it does provide less information at first glimpse.

The **Welch t-test is the default option** because the `var.equal`argument is set to `FALSE`. You won't be able to see it in the table output unless you know what you are looking for. Hence we would suggest adding all the default arguments into the function to be able to trace what you are doing.

* The first argument is the data
* The second argument in the formula with the pattern `DV ~ IV`
* Next we want to specify `paired = FALSE` as we don't want a paired t-test (`paired = FALSE` is the default)
* Then, we want to specify `var.equal = FALSE` for a Welch t-test (`var.equal = FALSE` is the default)
* The alternative is "two.sided" by default
* You can set the argument `detailed` to `TRUE` to get some more information (default is `detailed = FALSE`).



```{r eval=FALSE}
t_test(data = simon_effect, 
       formula = simon_effect ~ similarity, # DV ~ IV
       paired = FALSE, # for an independent t-test (default)
       var.equal = FALSE, # for a Welch t-test (default)
       alternative = "two.sided", # default - the alternative hypothesis is non-directional
       detailed = FALSE) # set this to true for more detail (FALSE is default)
```

So, what can we see in the output:

* The output gives you the `.y.` which is the DV and `group1` and `group2` will list the 2 levels of the IV that the test compared (in our case "different" and "same").
* It also lists `n1` and `n2`, which are the sample sizes for groups 1 and 2 respectively
* statistic is the t-value
* df is the degrees of freedom, and
* p is the p-value

If you set the `detailed` argument to `TRUE`, you get slightly more information. Let's have a look

```{r eval=FALSE}
t_test(data = simon_effect, 
       formula = simon_effect ~ similarity, # DV ~ IV
       paired = FALSE, # for an independent t-test (default)
       var.equal = FALSE, # for a Welch t-test (default)
       alternative = "two.sided", # default - the alternative hypothesis is tested in both directions
       detailed = TRUE) # set this to true for more detail (FALSE is default)
```

<p></p>
Additional information that is useful:

* estimate which is the difference score between the groups (here 3.14 msec = 35.99-32.86)
* estimate1 which is the average value from group 1 (here 32.86 ms - and it matches with the value we calculated in the descriptives for the "different" group)
* estimate2 which is the average value from group 2 (here 35.99 ms - and it matches with the value we calculated in the descriptives for the "same" group)
* lower and higher confidence intervals might also be useful, and
* the alternative is listed as "two.sided"


Now on to the information that is a bit of a let-down: **The method is listed as T-test**. This will always be the output whether use the formula for a one-sample t-test, independent t-test, or a paired t-test. Therefore it's really not great. This is the reason why we tell you to put all the arguments in, even the default ones. If you don't you may have a tough time identifying what you just did.

::: {.callout-tip}

You can see what test you conducted by looking at the df in the table. 

* If the df is $n1 + n2 - 2$ it's a Student t-test and equal variance are assumed (i.e., `var.equal = TRUE`). 
* If the df is approximately $n1 + n2 -2$ but some weird number with decimal places, you know `var.equal` was set to `FALSE` and it is actually a Welch t-test.
* If the df is $n1 - 1$ or $n2 - 1$ it's a paired t-test (even though it would be more useful to only have one n displayed in that case - but ah well)

:::



You have two options to tackle this task:

**Option 1**: Follow the three steps below to code along with the hints.

**Option 2**: Copy the code from Activity 4 in the individual walkthrough (@sec-ch2_act4) and replace the parameters/values in the functions based on the hints to fit the new data. 


#### Option 2: if you have yet to complete the individual walkthrough {.unnumbered}

Copy the code from Activity 4 and replace the arguments accordingly.

```{r eval=FALSE}
# Code from Activity 4

qrp_t1 <- data_prp %>% 
  #Step 1
  select(Code, QRPs_1_Time1:QRPs_11_Time1) %>%
  # Step 2
  pivot_longer(cols = -Code, names_to = "Items", values_to = "Scores") %>% 
  # Step 3
  group_by(Code) %>% # grouping by participant id
  summarise(QRPs_Acceptance_Time1_mean = mean(Scores)) %>% # calculating the average Score
  ungroup() # just make it a habit
```

Things you need to modify:

* [ ] The data object should be named `data_flourishing` and the data we are using as a starting point should be `dog_data_raw` 
* [ ] Step 1: Check the codebook and `dog_data_raw` what the participant id column is called, and which columns refer to the Flourishing data at time point 1 (pre-intervention).
* [ ] Step 2: Think about which columns you need to pivot, what you want to name the column that will store all the original column heading names, and what you want to name the column that will store all the values.
* [ ] Step 3a: Think about the column to group by if you want to calculate the average score **per participant**.
* [ ] Step 3b: To match with the final outcome table above, the column that has all the mean scores should be called `Flourishing_pre`. Think about which column we want to calculate the mean from.

