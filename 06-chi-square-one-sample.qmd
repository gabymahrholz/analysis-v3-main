---
lightbox: true
---

# Chi-square and one-sample t-test  {#sec-nhstI}

```{r include=FALSE}
library(patchwork)
```

## Intended Learning Outcomes {.unnumbered}

By the end of this chapter you should be able to:

-   compute a Cross-tabulation Chi-square test and report the results
-   compute a one-sample t-test and report the results
-   understand when to use a non-parametric equivalent for the one-sample t-test, compute it, and report the results

## [Individual Walkthrough]{style="color: #F39C12; text-transform: uppercase;"} {.unnumbered}


## Overview

Which test to use depends on what type of variable(s) you have and what your research question is about.


* 2 categorical: Cross-Tabulation Chi-Square Test (@sec-chi_square)
* 1 continuous: One-sample t-test (@sec-onesample)
* 1 continuous DV and 1 categorical IV (with 2 levels): 
  * Independent (between-subjects design, @sec-independent) 
  * Paired t-test (within-subjects design, @sec-within)
* 1 continuous DV and 1 categorical IV (with more than 2 levels): One-way ANOVA (@sec-oneway)
* 1 continuous DV and more than 1 categorical IVs: Factorial ANOVA (@sec-factorial)
* 2 continuous measured variables (testing association): Correlation (@sec-cor)
* 1 continuous DV and 1 continuous IV (testing predictions): Regression (@sec-reg)
* 1 continuous DV and multiple continuous predictors: regression for predictions (@sec-reg_mult)

Maybe in a flow chart


![Simplified flowchart to help select the most appropriate test (created with drawio)](images/Flowchart_tests_drawio.png){.lightbox}

To view the high-res version of the image: <if>right mouse click \> Open image in new tab</if>

## Activity 1: Setup & download the data

* create a new project and name it something meaningful (e.g., "2A_chapter5", or "05_chi_square_one_sample_t"). See @sec-project if you need some guidance.
* create a new Rmd file and save it to your project folder. See @sec-rmd if you get stuck. 
* delete everything after the setup code chunk (e.g., line 12 and below)
* download a reduced dataset here: [data_ch5.zip](data/data_ch5.zip "download"). You'll see one csv file with demographic information and questionnaire data as well as the codebook.
* Extract the data files from the zip folder and place them in your project folder. If you need help, see @sec-download_data_ch1.


**Citation**

> Ballou, N., Vuorre, M., Hakman, T., Magnusson, K., & Przybylski, A. K. (2024, July 12). Perceived value of video games, but not hours played, predicts mental well-being in adult Nintendo players. [https://doi.org/10.31234/osf.io/3srcw](https://doi.org/10.31234/osf.io/3srcw){target="_blank"}


As you can see, the study is a pre-print published on PsyArXiv Preprints. The data and supplementary materials are available on OSF: [https://osf.io/6xkdg/](https://osf.io/6xkdg/){target="_blank"}


**Abstract**

> Studies on video games and well-being often rely on self-report measures or data from a single game. Here, we study how 703 US adults’ time spent playing for over 140,000 hours across 150 Nintendo Switch games relates to their life satisfaction, affect, depressive symptoms, and general mental well-being. We replicate previous findings that playtime over the past two weeks does not predict well-being, and extend these findings to a wider range of timescales (one hour to one year). Results suggest that relationships, if present, dissipate within two hours of gameplay. Our non-causal findings suggest substantial confounding would be needed to shift a meaningful true effect to the observed null. Although playtime was not related to well-being, players’ assessments of the value of game time—so called gaming life fit—was. Results emphasise the importance of defining the gaming population of interest, collecting data from more than one game, and focusing on how players integrate gaming into their lives rather than the amount of time spent.






**Changes made to the dataset**

* We selected demographic variables, such as age, gender, ethnicity, employment, education level, and the Warwick-Edinburgh Mental Wellbeing Scale from the rich dataset.
* We removed rows with missing values and categorical groupings for which observed frequencies were considered too small for the purpose of this chapter.
* We won't be looking into any game-related associations, but feel free to download the full dataset to explore further.
* The original authors had quite strict inclusion criteria for their analysis. We did not, hence we ended up with more participants than the original study


## Activity 2: Load in the library, read in the data, and familiarise yourself with the data

Today, we'll need the following packages `tidyverse`, `lsr`, `scales`, `qqplotr`, `car`, `pwr`, and `rcompanion` as well as the data `data_ballou_reduced`.


```{r eval=FALSE}
# load in the packages
???

# read in the data
data_ballou <- ???

```


```{r include=FALSE, message=TRUE}
## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path
library(tidyverse)
library(lsr)
library(scales)
library(qqplotr)
library(car)
library(pwr)
library(rcompanion)
data_ballou <- read_csv("data/data_ballou_reduced.csv")
```


::: {.callout-caution collapse="true" icon="false"} 

## Solution 

```{r eval=FALSE}
# load in the packages
library(tidyverse)
library(lsr)
library(scales)
library(qqplotr)
library(car)
library(pwr)
library(rcompanion)

# read in the data
data_ballou <- read_csv("data_ballou_reduced.csv")
```

:::




## Activity 3: Data wrangling

The categorical variables look quite tidy, but we need to **convert gender and education level into factors**. Our statistical test requires factors and categories might be sorted more easily when plotting.

We also have to **calculate the overall score for the Warwick-Edinburgh Mental Wellbeing Scale**. According to the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target="_blank"}, the scores of the individual items are summed up.

* create a new data object `data_wemwbs` to calculate the summed up scores for the wemwbs.
* convert gender and education level into factors in the original `data_ballou` object. Feel free to sort them in a meaningful order. 
* join this `data_ballou` with `data_wembs`.

::: {.callout-note collapse="true" icon="false"} 

## Hints

* We converted categorical variables into factors in @sec-dataviz if you need a refresher 
* Check the `QRPs` questionnaire in @sec-wrangling to see how we approached aggregating scores 


::: {.callout-caution collapse="true" icon="false"} 

## Solution

```{r}
data_wemwbs <- data_ballou %>% 
  pivot_longer(cols = wemwbs_1:wemwbs_14, names_to = "Questions", values_to = "Scores") %>% 
  group_by(pid) %>% 
  summarise(wemwbs_sum = sum(Scores))

data_ballou <- data_ballou %>% 
  mutate(gender = factor(gender,
                         levels = c("Woman", "Man", "Non-binary")),
         eduLevel = factor(eduLevel,
                           levels = c("Completed Secondary School", "Some University but no degree", "University Bachelors Degree", "Vocational or Similar", "Graduate or professional degree (MA, MS, MBA, PhD, etc)"))) %>% 
  left_join(data_wemwbs)
```

:::

:::


## Activity 4: Cross-tabulation Chi-square test {#sec-chi_square}

A Cross-Tabulation Chi-Square Test, also known as a Chi-square test of association/independence, tests how one variable is associated with the distribution of outcomes in another variable.


We will be performing a Chi-Square test using the categorical variables **gender** and **eduLevel**:

* Potential research question: "Is there an association between gender and level of education in the population?"
* Null Hypothesis (H~0~): "Gender and student status are independent; there is no association between gender and level of education."
* Alternative Hypothesis (H~1~): "Gender and student status are not independent; there is an association between gender and level of education."



### Task 1: Preparing the dataframe

We need to select your variables of interest. We don't have missing values in this dataset, but if your future dataframe might contain some, use `drop_na()` before you turn categorical variables into factors.

```{r}
chi_square <- data_ballou %>% 
  select(pid, gender, eduLevel)
```


### Task 2: Compute descriptives

We need to calculate counts for each combination of the variables. This is best done in a frequency table. This also allows us to check that we don't have missing values in the cells. The function we are using does not work with missing values.


```{r}
chi_square_frequency <- chi_square %>% 
  count(gender, eduLevel) %>% 
  pivot_wider(names_from = eduLevel, values_from = n)


chi_square_frequency
```

We should be ok here, even though the count for non-binary/vocational is quite low.


### Task 3: Check assumptions


#### Assumption 1: categorical data {.unnumbered}

The two variables should be categorical data measured either at an ordinal or nominal level.

We can confirm that for our dataset. Gender is `r mcq(c(x = "ordinal", answer = "nominal"))`, and level of education is `r mcq(c(answer = "ordinal", x = "nominal"))`.


#### Assumption 2: Independent observartions {.unnumbered}

The value of one observation in the dataset does not affect the value of any other observation. 

And we assume as much for our data.


#### Assumption 3: Cells in the contingency table are mutually exclusive {.unnumbered}

Individuals can only belong to one cell in the contingency table. 

We can confirm that by looking at the data and the contingency table.


#### Assumption 4: Expected frequencies are sufficiently large {.unnumbered}

Not an assumption that is listed consistently across various sources. When it is, it suggests that expected frequencies are larger than 5 or at least 80% of the the expected frequencies are above 5 and none of them are below 1. However, Danielle Navarro points out that this seems to be a "somewhat conservative" criterion and should be taken as "rough guidelines" only (see [https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions](https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions){target="_blank"}.

This is information, we can either compute manually (see lecture slides) or wait till we get the output from the inferential statistics later.


### Task 4: Create an appropriate plot

Now we can create the appropriate plot. Which plot would you choose when building one from object `chi_square`? A `r mcq(c(answer = "Barchart", x = "Histogram", x = "Scatterplot", x = "Violin-Boxplot"))` with geom layer `r mcq(c(x = "geom_col", answer = "geom_bar", x = "geom_histogram", x = "geom_point", x = "geom_boxplot and geom_violin"))`

Try first before looking at the solution. Feel free to practice adding other layers to make the plot pretty.

::: {.callout-caution collapse="true" icon="false"}

## One possible solution

... is a grouped bar chart.

I played about with the labels of the x-axis categories since the graduate label is super long. Google was my friend in this instance and showed me a nifty function called `label_wrap()` from the `scales` package which automatically adds line breaks after X characters. Here we chose 12; looked best. (See other options for long labels at [https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/](https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/){target="_blank"}).


```{r}
ggplot(chi_square, aes(x = eduLevel, fill = gender)) +
  geom_bar(position = "dodge") + 
  scale_fill_viridis_d(name = "Gender") +
  scale_x_discrete(name = "Level of Education",
                   labels = label_wrap(12)) +
  scale_y_continuous(name = "Count") +
  theme_classic()
```
:::




### Task 5: Compute a chi-square test


Before we can do that, we need to turn our tibble into a dataframe - the `associationTest()` function we are using to compute the Chi-square test does not like tibbles.[*you have nooooo clue how long that took to figure out - let's say the error message was not entirely useful*]

```{r}
chi_square_df <- as.data.frame(chi_square)
```


Now we can run the `associationTest()` function from the `lsr` package. The first argument is a formula. It starts with a `~` and then expects the 2 variables we want to associate connected with a `+`. The second argument is the dataframe.


```{r}
associationTest(formula = ~ eduLevel + gender, data = chi_square_df)
```


The output is quite informative. It gives information about:

* the variables that were tested, 
* the null and alternative hypotheses, 
* a table with the observed frequencies (which matches what we calculated in `chi_square_assumptions` without the rows/columns of the missing values we removed), 
* an output of the frequencies you'd expect if the null hypothesis were true, 
* the result of the hypothesis test, and 
* the effect size Cramer's v.

And it gives us a **warning message** saying that expected frequencies are too small and that the chi-squared approximation may be incorrect. This ties in with Assumption 4. Depending on your stance on Assumption 4, you may or may not want to ignore the warning.

The p-value tells us that the null hypothesis is not being rejected, since the p-value is larger than 0.05. 

### Task 6: The write-up

The Chi-Square test revealed that there is no statistically significant association between Gender and Student Status, $\chi^2(8) = 13.59, p = .093, V = .079$. The strength of the association between the variables is considered small. We therefore fail to reject the null hypothesis. 





## Activity 5: One-sample t-test {#sec-onesample}

The one-sample t-test is used to determine whether a sample comes from a population with a specific mean. This population mean is not always known, but is sometimes hypothesized. 

We will be performing a one-sample t-test using the continuous variable **wemwbs_sum**. The [official website for the Warwick-Edinburgh Mental Wellbeing Scales](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target="_blank"} states that the "WEMWBS has a mean score of 51.0 in general population samples in the UK with a standard deviation of 7 (Tennant et al., 2007)".

* Potential research question: "Is the average mental well-being of gamers different from the general population's average well-being?"
* Null Hypothesis (H~0~): "The summed-up WEMWBS score of gamers is not different to 51.0."
* Alternative Hypothesis (H~1~): "The summed-up WEMWBS score of gamers is different from 51.0."


### Task 1: Preparing the dataframe

We need to select your variables of interest.

```{r}
one_sample <- data_ballou %>% 
  select(pid, wemwbs_sum)
```


### Task 2: Compute descriptives

We want to compute means and standard deviations for our variable of interest. This should be straight forward. Try it yourself and then compare your result with the solution below.

::: {.callout-caution collapse="true" icon="false"} 

## Solution 

```{r}
descriptives <- one_sample %>% 
  summarise(mean_wemwbs = mean(wemwbs_sum),
            sd = sd(wemwbs_sum))

descriptives
```

:::


### Task 3: Create an appropriate plot

This is the one you want to include in your report, so make sure everything is clearly labelled. Which plot would you choose? Start creating one first before comparing with the solution below.

::: {.callout-caution collapse="true" icon="false"} 

## Solution 

```{r}
ggplot(one_sample, aes(x = "", y = wemwbs_sum)) +
  geom_violin(fill = "#FB8D61", alpha = 0.4) + # alpha for opacity, fill for adding colour
  geom_boxplot(fill = "#FB8D61", width = 0.5) + # change width of the boxes
  theme_classic() +
  labs(x = "",
       y = "Total WEMWBS Scores")
```
:::



### Task 4: Check assumptions


#### Assumption 1: Continuous DV {.unnumbered}

The dependent variable needs to be measured at interval or ratio level. We can confirm that by looking at `one_sample`. 



#### Assumption 2: Data are independent {.unnumbered}

There is no relationship between the observations. Whilst this is an important assumption, it's not one we can really test for. It has more to do with study design. Anyway, we assume this assumption holds for our data.


#### Assumption 3: No significant outliers {.unnumbered}

We can check for that visually, for example in the violin-boxplot above. 

It appears that there is one outlier on the lower tail, however, when inspecting the data in `one_sample`, we can see that it's one person who got a score of 14 which is a possible value. Furthermore, when sample sizes are sufficiently large, like ours with 1083 participants, removing a single outlier makes not much sense. So we have checked this assumption, consider this outlier not significant, and therefore keep this observation in the dataset.

::: {.callout-important} 

If you are taking any of the outliers out, you need to recalculated the descriptive stats.

:::

#### Assumption 4: DV should be approximately normally distributed {.unnumbered}

We can already check normality from the violin-boxplot above but you could plot a histogram, a density plot, or a qqplot as an alternative to assess normality visually.

All of these options show that **the data is normally distributed**. That means, we will conduct a parametric test, i.e. a one-sample t-test.


::: {.callout-note collapse="true" icon="false"}

## Alternatives to visually assess normality

::: {.panel-tabset}

## Histogram

We've already covered histograms in @sec-dataviz2. 

```{r}
ggplot(one_sample, aes(x = wemwbs_sum)) +
  geom_histogram(binwidth = 1, fill = "magenta")
```

## Density plot

A density plot shows a smooth distribution curve of the data. The curve represents the proportion of the data in each range rather than the frequency. This means that the height of the curve doesn’t show how many times a value appears but rather the proportion of the data that falls into that range.

```{r}
ggplot(one_sample, aes(x = wemwbs_sum)) +
  geom_density(fill = "magenta")
```


## Q-Q plot

Q-Q plot stands for Quantile-Quantile Plot and compare two distributions by matching a common set of quantiles. It basically means that it's comparing the distribution you have in your data with a normal distribution and plots this along a 45 degree line. 

**If the dots in the Q-Q plot fall roughly along that line, you can assume normality of the data. If they stray away from the line (and worse in some sort of pattern), we might not assume normality and conduct a non-parametric test instead. For the non-parametric equivalent, see @sec-alternative_one_sample.**

We can either use the package `car` or `qqplotr` to build the qqplot. 

* The function `qqPlot()` is a single line but uses BaseR coding (i.e., the `$` symbol) to access the column in the data object.


```{r fig-qqplot1, fig.cap="Q-Q plot created with the car package"}

# Version 1 with the car package
qqPlot(one_sample$wemwbs_sum)
```

* If you have gotten used to ggplot by now, and prefer avoiding BaseR, you can use the package `qqplotr`. The downside is that you have to add the points, the line, and the confidence envelope yourself. On the plus, it has layers like ggplot, and is more customisable (just in case you wanted to look at something more colourful in the 2 seconds it'll take you to assess normality).

```{r fig-qqplot2, fig.cap="Q-Q plot created with the qqplotr package"}

# Version 2 with package qqplotr
ggplot(one_sample, aes(sample = wemwbs_sum)) +
  stat_qq_band(fill = "#FB8D61", alpha = 0.4) +
  stat_qq_line(colour = "#FB8D61") +
  stat_qq_point()

```

:::

:::


You can also assess normality with the **Shapiro-Wilk’s test**. The null hypothesis is that the population is distributed normally. Therefore, if the p-value of the Shapiro-Wilk’s test smaller than .05, normality is rejected. 

::: {.callout-important}

Shapiro-Wilk is a good method for small sample sizes (e.g., smaller than 50 samples). If you have large sample sizes, Shapiro-Wilk will definitely produce a significant p-value regardless of what the distribution looks like. So don't rely on its output when you have large sample sizes.
:::

The function in R is `shapiro.test()` and it's built into BaseR, meaning, we need our data object, the `$` and the column we want to address.


```{r}
shapiro.test(one_sample$wemwbs_sum)
```
No surprise here, the test shows p < .001 because we have more than 1000 participants. Nevertheless, if you had a smaller sample and you needed to write this result up in your report, you would report it in APA style: $W = .99, p < .001$.


::: {.callout-tip}

## Report-writing Tip

Either choose visual or computational inspection for normality tests. NO NEED TO DO BOTH!!!

* State what method you used and your reasons for choosing the method (visual/computational and what plot/test you used)
* state the outcome of the test - for visual inspection just say whether normality assumption held or not (no need to include that extra plot in the results section). For computational methods, report the test result in APA style
* State the conclusions you draw from it - parametric or non-parametric test

:::





### Task 5: Compute a One-sample t-test and effect size


We can use the `t.test()` function to compute a one-sample t-test. The `t.test()` function is part of BaseR, and yes, you guessed it, our first argument has to follow the pattern `data$column`. The second argument (`mu`) lists the population mean we are testing our sample against (here 51.0). The test is "two.sided" by default, so you can leave the argument out.

```{r}
t.test(one_sample$wemwbs_sum, mu = 51.0)
```
The output is quite informative. It gives us information about:

* the variable column that was tested, 
* the t value, degrees of freedom, and p,
* the alternative hypothesis, 
* a 95% confidence interval,
* and the mean of the column (which matches the one we computed in the descriptive - yay)

What it doesn't give us is an **effect size**. Meh. So we have to compute one ourselves.

We will calculate **Cohen's d** using the function `cohensD()` from the `lsr` package. Similar to the t-test we just conducted, the first argument is `data$column`, the second argument is `mu`.

```{r}
cohensD(one_sample$wemwbs_sum, mu = 51.0)
```


### Task 6: Sensitivity power analysis

A **sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect** given the number of participants you have in the sample, the alpha level at 0.05, and an assumed power of 0.8. 

The function we need to compute this is `pwr.t.test()` which is part of the `pwr` package. There are 4 factors - the APES (alpha, power, effect size, and sample size) - if you have 3, you can calculate the 4th. As stated above, we have 3. We also need to specify the `type`, i.e., that we are using it for a one-sample t-test, and that `alternative` is "two.sided" because we have a non-directional hypothesis.

```{r}
pwr.t.test(n = 1083, sig.level = 0.05, power = 0.8, type = "one.sample")
```

So the smallest effect size we can detect with a sample size of 1083, an alpha level of 0.05, and power of 0.8 is 0.09. This is a smaller value than the actual effect size we calculated with our CohensD function above (i.e., 0.51) which means our analysis is sufficiently powered.


### Task 7: The write-up

A one-sample t-test was computed to determine whether the average mental well-being of gamers as measured by the WEMWBS was different to the population well-being mean. The average WEMWBS of the gamers $(N = 1083, M = 45.42, SD = 10.89)$ was significantly lower than the population mean well-being score of 51.0, $t(1082) = 16.87, p < .001, d = .51$. The strength of the effect is considered medium and the study was sufficiently powered. We therefore reject the null hypothesis in favour of H~1~. 




## Activity 6: Non-parametric alternative {#sec-alternative_one_sample}

If any of the assumptions are violated, you need to switch to the non-parametric alternative. For the one-sample t-test, this is a **One-sample Wilcoxon signed-rank test**. Instead of the mean, it compares the median of a sample against a single value (i.e., the population median).

That means we need to find the population median, and calculate some summary stats for our sample:

* The population median is listed in a supporting document on the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target="_blank"} as 53.0. 
* we can easily calculate the summary statistics using the function summary

```{r}
summary(one_sample)
```


The function to compute a one-sample Wilcoxon test test is `wilcox.test()`. It's part of BaseR and code-wise, it works very similar to the one-sample t-test.

```{r}
wilcox.test(one_sample$wemwbs_sum, mu = 53.0)
```
As we can see, the output gives us a V value, but we need to report a z value in the final write-up. Unfortunately, we have to calculate z manually. According to Andy Field (2012, p. 665), we need to use the qnorm function on the halved p-value from our Wilcoxon test above.

```{r}
# storing the p-value
p_wilcoxon <- wilcox.test(one_sample$wemwbs_sum, mu = 53.0)$p.value

# calculate the z value from half the p-value
z = qnorm(p_wilcoxon/2)
z

```


We also need to calculate the effect size `r`, which we can do via the `wilcoxonOneSampleR` from the `rcompanion` package. The default value will be 3 decimal places, but you can change that with the `digits` argument.

```{r}
wilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)
```

Now we have all the numbers we need to write up the results: 

A One-sample Wilcoxon signed-rank test was used to compare Gamers’ mental-wellbeing scores (Mdn = 46.0) to the population median of 53.0. The test showed a significant difference, $Z = -19.12, p < .001, r = .590$. The strength of the effect is considered medium. We therefore reject the null hypothesis in favour of H~1~. 


## [Pair-coding in the lab]{style="color: #F39C12; text-transform: uppercase;"} {.unnumbered}




## [Test your knowledge on Chapters 3 and 4]{style="color: #F39C12; text-transform: uppercase;"} {.unnumbered}


